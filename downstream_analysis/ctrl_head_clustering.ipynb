{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn as skl\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "from tqdm.auto import trange, tqdm\n",
    "from Bio import SeqIO\n",
    "import re\n",
    "import seaborn as sns\n",
    "from pyhere import here\n",
    "\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.metrics import silhouette_samples, silhouette_score\n",
    "\n",
    "from tqdm.auto import trange\n",
    "\n",
    "import PyComplexHeatmap as pch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FPATH = here('data', 'attributions', '241001_RDHPLG_int.h5')\n",
    "FA_FPATH = here('data', 'ensembl.cds.fa')\n",
    "GC_FPATH = here('data', 'genetic_code.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trans_to_seq = []\n",
    "with open(FA_FPATH, mode=\"r\") as handle:\n",
    "    for record in SeqIO.parse(handle, \"fasta\"):\n",
    "        df_trans_to_seq.append([record.id, str(record.seq), record.description.split(\"gene_symbol:\")[1].split()[0]])\n",
    "\n",
    "df_trans_to_seq = pd.DataFrame(df_trans_to_seq, columns=[\"transcript\", \"sequence\", \"symbol\"])\n",
    "df_trans_to_seq.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "radius = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "radius = 20\n",
    "windows_attr = []\n",
    "windows_counts = []\n",
    "windows_seq = []\n",
    "with h5py.File(DATA_FPATH, 'r') as f:\n",
    "    transcripts = f['transcript'][:].astype('U') \n",
    "    conditions = f['condition'][:].astype('U') \n",
    "    ctrl_mask = np.nonzero(conditions == 'CTRL')[0]\n",
    "    for transc_idx in tqdm(ctrl_mask):\n",
    "        y_true = f['y_true_ctrl'][transc_idx]\n",
    "        trasc_attr = f['lig_ctrl'][transc_idx]\n",
    "        transcript = transcripts[transc_idx]\n",
    "\n",
    "        sequence = df_trans_to_seq.query('transcript == @transcript').sequence.values[0]\n",
    "        n_codons = int(np.sqrt(trasc_attr.shape[0]))\n",
    "        trasc_attr = trasc_attr.reshape(n_codons, n_codons)\n",
    "\n",
    "        topk_peaks = np.argsort(y_true)\n",
    "        topk_peaks = topk_peaks[(topk_peaks >= radius) & (topk_peaks < n_codons - radius - 1)]\n",
    "        topk_peaks = topk_peaks[-10:]\n",
    "        #windows.append(np.array([trasc_attr[i,i - radius :i + radius + 1] for i in range(radius, n_codons - radius)]))\n",
    "\n",
    "        # Generate list of attribution windows\n",
    "        windows_attr.append(np.array([trasc_attr[i,i - radius :i + radius + 1] for i in topk_peaks]))\n",
    "\n",
    "        # Generate list of counts windows\n",
    "        windows_counts.append(np.array([y_true[i - radius :i + radius + 1] for i in topk_peaks]))\n",
    "\n",
    "        # Generate list of codon windows\n",
    "        windows_seq.append(np.array([sequence[i*3 - (radius)*3 :i*3 + (radius + 1)*3] for i in topk_peaks]))\n",
    "\n",
    "# Normalize counts\n",
    "windows_counts = np.concatenate(windows_counts)\n",
    "windows_counts = windows_counts / np.nansum(windows_counts, 1)[:,None]\n",
    "\n",
    "# Normalize sequence\n",
    "windows_attr = np.abs(np.concatenate(windows_attr))\n",
    "windows_attr = windows_attr / np.sum(windows_attr, 1)[:,None]\n",
    "\n",
    "windows_seq = np.concatenate(windows_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ATTR_PEAK_THRESHOLD = .15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract peaks positions\n",
    "peaks_data = [tuple(np.where(wa > ATTR_PEAK_THRESHOLD)[0]) for wa in windows_attr]\n",
    "\n",
    "# Create a cluster_id for each set of peaks\n",
    "peaks_to_cluster_id = {p: idx for idx, p in enumerate(set(peaks_data))}\n",
    "\n",
    "# Assign cluster_id to each attribution window\n",
    "clusters = np.array([peaks_to_cluster_id[p] for p in peaks_data])\n",
    "print(\"N clusters = \", len(peaks_to_cluster_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for peaks, cluster in peaks_to_cluster_id.items():\n",
    "#     plt.figure(figsize=(5,5))\n",
    "#     cluster_attr = windows_attr[clusters == cluster].mean(0)\n",
    "#     plt.plot(cluster_attr)\n",
    "#     for p in peaks:\n",
    "#         plt.plot(p, cluster_attr[p], \"x\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "cluster_codons = defaultdict(list)\n",
    "for peaks, cluster_id in tqdm(peaks_to_cluster_id.items()):\n",
    "    if len(peaks) == 0:\n",
    "        continue\n",
    "    for p in peaks:\n",
    "        cluster_codons[cluster_id].append((\n",
    "            np.sum(clusters == cluster_id),  # Count elements of given cluster\n",
    "            p-radius, # Make peak location relative to A-site\n",
    "            [seq[p*3:3*(p+1)] for seq in windows_seq[clusters == cluster_id]] # Find codons appearing at the peak position for a given cluster\n",
    "        ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genetic_code = pd.read_csv(GC_FPATH, index_col=0).set_index('Codon')\n",
    "genetic_code.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nunique = []\n",
    "for cluster_id, v in cluster_codons.items():\n",
    "    for n_seq, idx, pos in v:\n",
    "        codons, codon_counts = np.unique(pos, return_counts=True) # Find unique codons and relative counts occurring at a given position\n",
    "        codon_counts = codon_counts / np.sum(codon_counts) # Normalize the counts\n",
    "        nunique.append(\n",
    "            pd.DataFrame(np.stack([codons, codon_counts]).T, columns=['codon', 'freq']).set_index('codon').reindex(genetic_code.index, fill_value=0).reset_index().assign(position=idx, cluster=cluster_id, n_samples=n_seq))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLUSTER_MIN_SIZE = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat(nunique).assign(peak_id=lambda df: df.cluster.astype(str) + \"_\" + df.position.astype(str))#.set_index('peak_id')#.pivot(columns='Codon', values='freq').astype(float).fillna(0.)\n",
    "data = data.astype(dict(freq='float', Codon='str', peak_id='str'))\n",
    "data = data.query(f\"n_samples > {CLUSTER_MIN_SIZE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.cluster.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import marsilea as ma\n",
    "\n",
    "AA = ['Val', 'Ile', 'Leu', 'Lys', 'Asn', 'Thr', 'Arg', 'Ser', 'Met', 'Gln', 'His', 'Pro', 'Glu', 'Asp', 'Ala', 'Gly', 'Tyr', 'Cys', 'Trp', 'Phe', 'Stp']\n",
    "DEPR_NAMES = {'ILE':'ILE (I)', 'LEU':'LEU (L)', 'VAL':'VAL (V)', 'LEU_ILE':'(L, I)', 'LEU_ILE_VAL':'(L,I,V)'}\n",
    "\n",
    "cmap = plt.get_cmap('tab20c')\n",
    "colors = np.array(cmap.colors).repeat(2,0)\n",
    "np.random.seed(42)\n",
    "np.random.shuffle(colors)\n",
    "\n",
    "heatmap_data = data.sort_values(['n_samples', 'cluster', 'position'], ascending=False).pivot_table(index=['peak_id'],columns='Codon', values='freq', sort=False)\n",
    "row_data = data.groupby(['position', 'cluster']).agg(dict(peak_id='first', n_samples='first')).sort_values(['n_samples', 'position'], ascending=False).reset_index()\n",
    "h = ma.Heatmap(\n",
    "    heatmap_data, \n",
    "    width=17,\n",
    "    height=7)\n",
    "h.group_cols(genetic_code.AminoAcid, spacing=0.002, order=AA)\n",
    "h.add_top(\n",
    "        ma.plotter.Chunk(\n",
    "            AA,\n",
    "            colors[:len(AA)],\n",
    "            padding=10,\n",
    "            fontsize=12\n",
    "        ),\n",
    "        pad=0.025\n",
    "    )\n",
    "h.add_bottom(ma.plotter.Labels(heatmap_data.columns, rotation=45,fontsize=12), name='Codon')\n",
    "h.add_left(\n",
    "        ma.plotter.Labels(\n",
    "            row_data.position,\n",
    "            #fill_colors=colors[:len(row_data)],\n",
    "            #padding=10,\n",
    "            fontsize=12,\n",
    "            label=\"Position\",\n",
    "            label_props=dict(fontsize=12)\n",
    "        ),\n",
    "        pad=0.025\n",
    "    )\n",
    "h.group_rows(row_data.cluster.values, spacing=0.01, order=row_data.cluster.unique())\n",
    "h.add_right(\n",
    "        ma.plotter.Numbers(\n",
    "            row_data.n_samples.values,\n",
    "            label=\"Cluster Size\",\n",
    "            label_props=dict(fontsize=12)\n",
    "            #fill_colors=colors[:len(row_data)],\n",
    "            #padding=10,\n",
    "            #label_props=dict(rotation=90)\n",
    "        ),\n",
    "        pad=0.1\n",
    "    )\n",
    "h.add_legends()\n",
    "h.add_title(\"CTRL Head Codon Frequency by Peak Cluster (window size = 20, attr threshold = .15, min clust size = 50)\", fontsize=16)\n",
    "h.render()\n",
    "plt.savefig('../results/plots/window_ctrl_head.pdf', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_data.n_samples.va"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(30, data.cluster.nunique() // 2))\n",
    "\n",
    "cmap = plt.get_cmap('tab20c')\n",
    "colors = np.array(cmap.colors)\n",
    "np.random.seed(42)\n",
    "np.random.shuffle(colors)\n",
    "randomized_cmap = plt.matplotlib.colors.ListedColormap(colors)\n",
    "\n",
    "col_ha = pch.HeatmapAnnotation(aminoacid=pch.anno_simple(genetic_code, add_text=True,legend=False,text_kws={'fontsize':10, 'color':'black'},cmap=randomized_cmap, height=5),axis=1)\n",
    "row_ha = pch.HeatmapAnnotation(\n",
    "    cluster=pch.anno_simple(data.groupby(['peak_id'])[['cluster']].first(), add_text=True, legend=False,text_kws={'fontsize':10, 'color':'black','rotation':0}, height=7,cmap=randomized_cmap),\n",
    "    position=pch.anno_simple(data.groupby(['peak_id'])[['position']].first(), add_text=True, legend=False,text_kws={'fontsize':10, 'color':'black','rotation':0}, height=7, majority=False,cmap='coolwarm'),\n",
    "    n_samples=pch.anno_simple(data.groupby(['peak_id'])[['n_samples']].first(), add_text=True, legend=True, text_kws={'fontsize':10, 'color':'black','rotation':0}, height=10,cmap='coolwarm'),\n",
    "    axis=0)\n",
    "pch.ClusterMapPlotter(\n",
    "    data=data.sort_values(['n_samples', 'cluster', 'position'], ascending=False).pivot_table(index=['peak_id'],columns='Codon', values='freq', sort=False),\n",
    "    col_split=genetic_code, col_split_gap=1,\n",
    "    top_annotation=col_ha,\n",
    "    left_annotation=row_ha,\n",
    "    annot=True, \n",
    "    fmt='.2f',\n",
    "    cmap='coolwarm',\n",
    "    show_rownames=False,show_colnames=True,\n",
    "    col_cluster=False,row_cluster=False,\n",
    "    col_cluster_metric='euclidean',\n",
    "    xticklabels_kws=dict(labelrotation=-45))\n",
    "plt.suptitle('Distribution of TOP5 attributions in the deprivation head, by condition')\n",
    "plt.savefig('results/plots/ctrl_head_clusters.png', dpi=400, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
