{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"/nfs_home/nallapar/final/riboclette/riboclette/models/preds_h5s\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import matplotlib.gridspec as gridspec\n",
    "from matplotlib.transforms import Affine2D\n",
    "from matplotlib.transforms import ScaledTranslation\n",
    "import seaborn as sns\n",
    "import scienceplots\n",
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "from permetrics import RegressionMetric\n",
    "import h5py\n",
    "from collections import defaultdict\n",
    "from tqdm.auto import tqdm\n",
    "from itertools import product\n",
    "import matplotlib.patches as patches\n",
    "import cairosvg\n",
    "import skunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir(DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BRIGHT_PALETTE = ['#4477AA', '#EE6677', '#228833', '#CCBB44', '#66CCEE', '#AA3377', '#BBBBBB', '#BBBBBB']\n",
    "MODELS_PROP=[\n",
    "    ('RiboMIMO', 'RiboMIMO', 'RM', False, BRIGHT_PALETTE[0]),\n",
    "    ('BiLSTM-CSH', 'BiLSTM [SH]', 'BLSH', False, BRIGHT_PALETTE[1]),\n",
    "    ('BiLSTM-DH', 'BiLSTM [DH]', 'BLDH', True, BRIGHT_PALETTE[2]),\n",
    "    ('XLNet-CSH', 'Riboclette [SH]', 'RSH', False, BRIGHT_PALETTE[3]),\n",
    "    ('XLNet-DH', 'Riboclette [DH]', 'RDH', True,BRIGHT_PALETTE[4]),\n",
    "    ('XLNet-PLabelDH_exp1', 'Riboclette [DH] + PL [T]', 'RDHPLT', True,BRIGHT_PALETTE[5]),\n",
    "    ('XLNet-PLabelDH_exp2', 'Riboclette [DH] + PL [G]', 'RDHPLG', True,BRIGHT_PALETTE[6]),\n",
    "]\n",
    "MODELS_PROP = pd.DataFrame(MODELS_PROP).rename(columns={0:'fname', 1:'model', 2:'abbr',3:'is_dh',4:'color'})\n",
    "MODELS_PROP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "\n",
    "class Metric(ABC):\n",
    "    @abstractmethod\n",
    "    def compute(self, y_true, y_pred):\n",
    "        pass\n",
    "\n",
    "    def masked_compute(self, y_true, y_pred):\n",
    "        nan_mask = ~np.isnan(y_true)\n",
    "        y_true = y_true[nan_mask]\n",
    "        y_pred = y_pred[nan_mask]\n",
    "        return self.compute(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PCC(Metric):\n",
    "    def compute(self, y_true, y_pred):\n",
    "        evaluator = RegressionMetric(y_true, y_pred)\n",
    "        return evaluator.pearson_correlation_coefficient()\n",
    "    \n",
    "class MAE(Metric):\n",
    "    def compute(self, y_true, y_pred):\n",
    "        evaluator = RegressionMetric(y_true, y_pred)\n",
    "        return evaluator.mean_absolute_error()\n",
    "\n",
    "class MAAPE(Metric):\n",
    "    def compute(self, y_true, y_pred, eps=1e-10):\n",
    "        evaluator = RegressionMetric(y_true+eps, y_pred)\n",
    "        return evaluator.mean_arctangent_absolute_percentage_error()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_to_func = dict(\n",
    "    PCC=PCC(),\n",
    "    MAE=MAE(),\n",
    "    MAAPE=MAAPE()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_performance_metrics(fpath, abbr, is_dh, seed):\n",
    "    sample_perf = defaultdict(list)\n",
    "    with h5py.File(fpath, 'r') as f:\n",
    "        if is_dh:\n",
    "            ctrl_pred = f['y_pred_ctrl'][:]\n",
    "            depr_pred = f['y_pred_depr_diff'][:]\n",
    "            ctrl_true = f['y_true_ctrl'][:]\n",
    "            depr_true = f['y_true_dd'][:]\n",
    "\n",
    "        cond_pred = f['y_pred_full'][:]\n",
    "        cond_true = f['y_true_full'][:]\n",
    "\n",
    "        conditions = f['condition'][:].astype('U')\n",
    "        conditions = np.char.replace(conditions, '-', '_')\n",
    "\n",
    "        transcripts = [re.sub(r'[^A-Za-z0-9.]', '', t) for t in f['transcript'][:].astype('U')]\n",
    "\n",
    "        for sample_idx in range(cond_true.shape[0]):\n",
    "            condition = conditions[sample_idx]\n",
    "            for m, f in metric_to_func.items():\n",
    "                \n",
    "                if is_dh and condition != 'CTRL':\n",
    "                    depr_val = f.masked_compute(y_true=depr_true[sample_idx], y_pred=depr_pred[sample_idx])\n",
    "                else:\n",
    "                    depr_val = None\n",
    "                sample_perf[f\"depr_{m}\"].append(depr_val)\n",
    "\n",
    "                if is_dh:\n",
    "                    ctrl_val = f.masked_compute(y_true=ctrl_true[sample_idx], y_pred=ctrl_pred[sample_idx])\n",
    "                else:\n",
    "                    ctrl_val = None\n",
    "                sample_perf[f\"ctrl_{m}\"].append(ctrl_val)\n",
    "\n",
    "                sample_perf[f\"cond_{m}\"].append(\n",
    "                   f.masked_compute(y_true=cond_true[sample_idx], y_pred=cond_pred[sample_idx]))\n",
    "\n",
    "            sample_perf[\"condition\"].append(condition)\n",
    "            sample_perf[\"n_codons\"].append(len(cond_true[sample_idx]))\n",
    "\n",
    "            sample_perf[\"transcript\"].append(transcripts[sample_idx])\n",
    "\n",
    "            # sample_perf[\"depr_skew\"].append(skew(depr_true[sample_idx], nan_policy=\"omit\"))\n",
    "            # sample_perf[\"depr_kurtosis\"].append(kurtosis(depr_true[sample_idx], nan_policy=\"omit\"))\n",
    "            # sample_perf[\"depr_var\"].append(np.nanvar(depr_true[sample_idx]))\n",
    "            # sample_perf[\"depr_std\"].append(np.nanstd(depr_true[sample_idx]))\n",
    "            # sample_perf[\"depr_mean\"].append(np.nanmean(np.abs(depr_true[sample_idx])))\n",
    "            # sample_perf[\"depr_max\"].append(np.nanmax(depr_true[sample_idx]))\n",
    "\n",
    "            # sample_perf[\"ctrl_skew\"].append(skew(ctrl_true[sample_idx], nan_policy=\"omit\"))\n",
    "            # sample_perf[\"ctrl_kurtosis\"].append(kurtosis(ctrl_true[sample_idx], nan_policy=\"omit\"))\n",
    "            # sample_perf[\"ctrl_var\"].append(np.nanvar(ctrl_true[sample_idx]))\n",
    "            # sample_perf[\"ctrl_std\"].append(np.nanstd(ctrl_true[sample_idx]))\n",
    "            # sample_perf[\"ctrl_mean\"].append(np.nanmean(ctrl_true[sample_idx]))\n",
    "\n",
    "            # sample_perf[\"cond_mean\"].append(np.nanmean(cond_true[sample_idx]))\n",
    "\n",
    "    return pd.DataFrame(sample_perf).assign(abbr=abbr, seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product \n",
    "\n",
    "data=pd.concat([\n",
    "    compute_performance_metrics(os.path.join(DATA_PATH, f'{fname}_S{seed}.h5'), abbr, is_dh, seed)\n",
    "    for (_, (fname, _, abbr, is_dh, _)), seed in tqdm(list(product(MODELS_PROP.iterrows(), [1,2,3,4,42])))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.replace({\n",
    "    'condition': {\n",
    "        'VAL': 'VAL (V)',\n",
    "        'ILE': 'ILE (I)',\n",
    "        'LEU': 'LEU (L)',\n",
    "        'LEU_ILE': '(L, I)', \n",
    "        'LEU_ILE_VAL': '(L, I, V)'}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.query('(abbr == \"RDHPLT\" and seed == 1) or (abbr == \"RM\" and seed == 1)').pivot(index=['transcript', 'condition'], columns=['abbr'], values='cond_PCC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXTWIDTH_CM = 18.3\n",
    "CM_TO_INCH = 1/2.54  # centimeters in inches\n",
    "CONDITION_ORDER = ['CTRL', 'ILE (I)', 'LEU (L)', 'VAL (V)', '(L, I)', '(L, I, V)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_condition_pcc = (pd.read_csv('Performance.csv')\n",
    " .melt(id_vars='Condition', var_name='Model', value_name='PCC')\n",
    " .assign(\n",
    "     Seed=lambda df: [[el for el in re.findall(r\"S\\d+\", x)] for x in df.PCC],\n",
    "     PCC=lambda df: [[float(el) for el in re.findall(r\"\\d+\\.\\d+\", x)] for x in df.PCC])\n",
    " .explode(['Seed','PCC'])\n",
    " .replace({\n",
    "     'Model': {\n",
    "      ' XL-Net 1 (64+6) DH Seed Best': 'XLNet DH',\n",
    "      'XL-Net 1 DH (PLabel)': 'XLNet DH+PL',\n",
    "      'XL-Net 1 SH (L: MAE+PCC)': 'XLNet SH', \n",
    "      'LSTM DH (L: MAE+PCC)': 'LSTM DH',\n",
    "      'LSTM SH (L: MAE+PCC)': 'LSTM SH'}, \n",
    "    'Condition': {\n",
    "        'CTRL + Liver': 'CTRL', \n",
    "        'LEU_ILE': '(LEU, ILE)', \n",
    "        'LEU_ILE_VAL': '(LEU, ILE, VAL)'\n",
    "    }}\n",
    "))\n",
    "df_condition_pcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "palette_df = pd.DataFrame.from_dict(dict(\n",
    "    Model = ['Riboclette DH+IM', 'Riboclette DH', 'LSTM DH', 'RiboMIMO'],\n",
    "    Palette = np.array(['#4477AA', '#EE6677', '#228833', '#CCBB44', '#66CCEE', '#AA3377', '#BBBBBB'])[[0,1,4,5]]\n",
    "))\n",
    "palette_dict = dict(zip(palette_df['Model'], palette_df['Palette']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_condition_pcc = (\n",
    "    pd.DataFrame.from_dict({\n",
    "        'Order': [1, 3, 2, 5, 6, 4],\n",
    "        'Condition': ['CTRL', 'LEU', 'ILE', '(LEU, ILE)', '(LEU, ILE, VAL)', 'VAL'],\n",
    "        'Riboclette DH': [0.5979, 0.6893, 0.6382, 0.6798, 0.689, 0.6997],\n",
    "        'LSTM DH': [0.525, 0.6092, 0.5163, 0.6005, 0.656, 0.6602],\n",
    "        'RiboMIMO': [0.3898, 0.5958, 0.5421, 0.5899, 0.5888, 0.6129]\n",
    "    })\n",
    "    .melt(id_vars=['Condition', 'Order'], var_name='Model', value_name='PCC')\n",
    "    .assign(Model=lambda df: pd.Categorical(df.Model, ['RiboMIMO', 'LSTM DH', 'Riboclette DH']))\n",
    "    .sort_values('Model'))\n",
    "df_condition_pcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PCCs =[0.6816, 0.6759, 0.68, 0.6788, 0.6789] + [0.659, 0.6438, 0.6557, 0.6209, 0.6531] + [0.5831, 0.58, 0.5808, 0.5806, 0.5811] + [0.5532]\n",
    "MAEs = [.218, .2213, .2176, .2168, .2198] + [0.2231, 0.231, 0.2242, 0.2328, 0.2232] + [np.nan] * 6\n",
    "Models = ['Riboclette DH+IM'] * 5 + ['Riboclette DH'] * 5 + ['LSTM DH'] * 5 + ['RiboMIMO']\n",
    "\n",
    "df_overall_pcc = (\n",
    "    pd.DataFrame(np.array([PCCs, MAEs]).T, columns=['PCC', 'MAE']).assign(Model=Models)\n",
    "    .assign(Model=lambda df: pd.Categorical(df.Model, ['RiboMIMO', 'LSTM DH', 'Riboclette DH', 'Riboclette DH+IM']))\n",
    "    .sort_values('Model'))\n",
    "df_overall_pcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_imputation = (\n",
    "    pd.DataFrame.from_dict({\n",
    "        'Trainset Size': [17897] * 5 + [17897] * 5 + [92700] * 5 + [128808] * 5,\n",
    "        'PCC': [0.659, 0.6438, 0.6557, 0.6209, 0.6531] + [0.6644, 0.6301, 0.6605, 0.6303, 0.6338] + [0.6793, 0.6768, 0.6795, 0.6795, 0.6817] + [0.6757, 0.6754, 0.6802, 0.6732, 0.6797],\n",
    "        'MAE': [0.2231, 0.231, 0.2242, 0.2328, 0.2232] + [0.2198, 0.2273, 0.2226, 0.2198, 0.2198] + [0.2236, 0.2243, 0.2209, 0.2253, 0.2217] + [0.2198, 0.2271, 0.2197, 0.2269, 0.2264],\n",
    "        'Imputed': ['None'] * 5 + ['T'] * 5 + ['(T, D)'] * 5 + ['(T, D, M)'] * 5,\n",
    "        'Color': [PALETTE_TO_MODEL[\"Riboclette DH\"]] * 5 + [BRIGHT_PALETTE[6]] * 5 + [PALETTE_TO_MODEL[\"Riboclette DH+IM\"]] * 5 + [BRIGHT_PALETTE[5]] * 5\n",
    "    }))\n",
    "df_imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_condition_pcc.groupby('Condition').Order.first().sort_values().index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df_condition_pcc\n",
    "     .groupby(['Model', 'Seed'])\n",
    "     .PCC\n",
    "     .agg('mean')\n",
    "     .reset_index()\n",
    "     .groupby('Model')\n",
    "     .PCC\n",
    "     .agg(['mean', 'std'])\n",
    "     .reset_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# https://github.com/Kozea/CairoSVG/issues/392\n",
    "os.environ['DYLD_LIBRARY_PATH']=\"/opt/homebrew/opt/cairo/lib\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_cond_mean=(data.groupby(['abbr', 'condition', 'seed'])\n",
    " .cond_PCC\n",
    " .mean()\n",
    " .reset_index())\n",
    "(seed_cond_mean\n",
    "    .query('abbr == \"RM\"')\n",
    "    .groupby('condition')\n",
    "    .cond_PCC\n",
    "    .agg(['mean', 'std'])\n",
    "    .reset_index()\n",
    "    .set_index('condition')\n",
    "    .loc[CONDITION_ORDER]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(data\n",
    "        .groupby(['abbr', 'condition', 'seed'])\n",
    "        .cond_PCC\n",
    "        .mean()\n",
    "        .groupby(['abbr', 'seed'])\n",
    "        .mean()\n",
    "        .groupby('abbr')\n",
    "        .agg(['mean', 'std'])\n",
    "        .reset_index()\n",
    "        .merge(MODELS_PROP, on='abbr'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for a in MODELS_PROP[['abbr', 'color']].values:\n",
    "    print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.query('abbr == \"RM\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with plt.style.context(['science','nature','grid','bright','no-latex']):\n",
    "    fig = plt.figure(figsize=(TEXTWIDTH_CM*CM_TO_INCH, 13*CM_TO_INCH))\n",
    "    gs = fig.add_gridspec(nrows=3, ncols=4, wspace=.6, hspace=.6)\n",
    "    ax0 = fig.add_subplot(gs[0,:-1])\n",
    "    ax1 = fig.add_subplot(gs[0,-1])\n",
    "    \n",
    "    inner_grid = gs[1,:].subgridspec(ncols=2, nrows=1, wspace=0.1, width_ratios=[3,1])\n",
    "    (ax2, ax3) = inner_grid.subplots(sharey=True)\n",
    "\n",
    "    ax4 = fig.add_subplot(gs[2,:-2])\n",
    "\n",
    "    inner_grid = gs[2,-2:].subgridspec(ncols=3, nrows=1, wspace=0.1)\n",
    "    (ax5, ax6, ax7) = inner_grid.subplots(sharey=True)\n",
    "    \n",
    "    # ax0.grid(False)\n",
    "    # ax0.spines['top'].set_visible(False)\n",
    "    # ax0.spines['right'].set_visible(False)\n",
    "    # ax0.spines['bottom'].set_visible(False)\n",
    "    # ax0.spines['left'].set_visible(False)\n",
    "    # ax0.get_xaxis().set_ticks([])\n",
    "    # ax0.get_yaxis().set_ticks([])\n",
    "    # ax0.tick_params(bottom=False, top=False, left=False, right=False, labelbottom=False, labeltop=False, labelleft=False, labelright=False)\n",
    "    # ax0.text(x=-0.05, y=1.1, s=\"A.\", fontweight='bold', fontsize=12, ha='right', va='center', transform=ax0.transAxes)\n",
    "    # skunk.connect(ax0, 'sk') \n",
    "\n",
    "    # data = (\n",
    "    #     df_imputation.groupby('Imputed').agg({'PCC': ['mean', 'std'], 'Trainset Size': 'mean', 'Color': 'first'})\n",
    "    #     .reset_index())\n",
    "    # data.columns = ['Imputed', 'PCC_mean', 'PCC_std', 'Trainset Size', 'Color']\n",
    "    # for idx, row in data.sort_values('Trainset Size').iterrows():\n",
    "    #     if 'GC' in row.Imputed:\n",
    "    #         print(row.Imputed)\n",
    "    #         sign = 1 if 'IM' in row.Imputed else -1\n",
    "    #         trans = Affine2D().translate(sign*1e3, 0.0) + ax3.transData\n",
    "    #         ax1.errorbar(x=row['Trainset Size'], y=row['PCC_mean'], yerr=row['PCC_std'], fmt=\"o\", markersize=2, capsize=2, label=row.Imputed, color=row.Color)\n",
    "    #     else:\n",
    "    #         ax1.errorbar(x=row['Trainset Size'], y=row['PCC_mean'], yerr=row['PCC_std'], fmt=\"o\", markersize=2, capsize=2, label=row.Imputed, color=row.Color)\n",
    "    # ax1.legend(title='Imputed')\n",
    "    # ax1.set_xticks([v*1000 for v in [0, 25, 50, 75, 100, 125, 150]])\n",
    "    # ax1.set_title(\"Pseudo-Labeling Performance\")\n",
    "    # ax1.set_xlabel(\"Trainset Size\")\n",
    "    # ax1.set_ylabel(\"PCC\")\n",
    "    # ax1.set_ylim((.6, .7))\n",
    "    # ax1.ticklabel_format(style='sci',scilimits=(3,3),axis='x')\n",
    "    # ax1.text(x=-0.05, y=1.1, s=\"B.\", fontweight='bold', fontsize=12, ha='right', va='center', transform=ax1.transAxes)\n",
    "\n",
    "    width = .1\n",
    "    multiplier = -2.5\n",
    "    x_ticks = np.arange(data.condition.nunique())\n",
    "    seed_cond_mean = data.groupby(['abbr', 'condition', 'seed']).cond_PCC.mean().reset_index()\n",
    "    for abbr, color in MODELS_PROP[['abbr', 'color']].values:\n",
    "        group = (seed_cond_mean\n",
    "                 .query('abbr == @abbr')\n",
    "                 .groupby('condition')\n",
    "                 .cond_PCC\n",
    "                 .agg(['mean', 'std'])\n",
    "                 .reset_index()\n",
    "                 .set_index('condition')\n",
    "                 .loc[CONDITION_ORDER]\n",
    "        )\n",
    "        model=MODELS_PROP.query('abbr == @abbr').model.values[0]\n",
    "        #group=group.sort_values('Order')\n",
    "        offset = width * multiplier\n",
    "        rects = ax2.bar(height=group['mean'], yerr=group['std'],  x=x_ticks+offset, width=width, color=color, label=model)\n",
    "        multiplier += 1\n",
    "\n",
    "    #f1 = sns.barplot(x='Condition', y='PCC', hue='Model', palette=palette_dict, data=df_condition_pcc, ax=ax1)\n",
    "    ax2.set_xticks(x_ticks, CONDITION_ORDER)\n",
    "    ax2.set_ylim(0.3,.8)\n",
    "    ax2.xaxis.grid(False)\n",
    "    ax2.xaxis.set_ticks_position('none')\n",
    "\n",
    "    ax2.set_ylabel('PCC')\n",
    "    ax2.set_xlabel('Condition')\n",
    "    ax2.set_title(\"Condition-wise Model Performance\")\n",
    "    ax2.text(x=-0.05, y=1.1, s=\"C.\", fontweight='bold', fontsize=12, ha='right', va='center', transform=ax2.transAxes)\n",
    "\n",
    "    width = .6\n",
    "    df_overall_pcc = (data\n",
    "        .groupby(['abbr', 'condition', 'seed'])\n",
    "        .cond_PCC\n",
    "        .mean()\n",
    "        .groupby(['abbr', 'seed'])\n",
    "        .mean()\n",
    "        .groupby('abbr')\n",
    "        .agg(['mean', 'std'])\n",
    "        .reset_index()\n",
    "        .merge(MODELS_PROP, on='abbr', how='right'))\n",
    "    x_ticks = np.arange(df_overall_pcc.shape[0])\n",
    "    ax3.bar(height=df_overall_pcc['mean'], yerr=df_overall_pcc['std'], x=x_ticks, color=df_overall_pcc.color, width=width)\n",
    "    #ax3.set_xticks(x_ticks, [n for n, _ in df_overall_pcc.groupby('Model')], ha='center')\n",
    "    ax3.set_xticks([])\n",
    "    ax3.xaxis.set_ticks_position('none')\n",
    "    ax3.xaxis.grid(False)\n",
    "    ax3.set_ylim(.3,.8)\n",
    "    #ax2.set_xticklabels(ax2.get_xticklabels(), rotation=30)\n",
    "    ax3.set_title(\"Model-wise Macro-Average\")\n",
    "    ax3.text(x=-0.03, y=1.1, s=\"D.\", fontweight='bold', fontsize=12, ha='right', va='center', transform=ax3.transAxes)\n",
    "\n",
    "    DEPR_CONDITION_ORDER = CONDITION_ORDER[1:] \n",
    "    width = .1\n",
    "    multiplier = -2.5\n",
    "    x_ticks = np.arange(data.condition.nunique() - 1)\n",
    "    seed_cond_mean = data.groupby(['abbr', 'condition', 'seed']).depr_PCC.mean().reset_index().dropna()\n",
    "    for abbr in seed_cond_mean.abbr.unique():\n",
    "        group = (seed_cond_mean\n",
    "                 .query('abbr == @abbr')\n",
    "                 .groupby('condition')\n",
    "                 .depr_PCC\n",
    "                 .agg(['mean', 'std'])\n",
    "                 .reset_index()\n",
    "                 .set_index('condition')\n",
    "        )\n",
    "        group = group.loc[DEPR_CONDITION_ORDER]\n",
    "        color=MODELS_PROP.query('abbr == @abbr').color\n",
    "        model=MODELS_PROP.query('abbr == @abbr').model.values[0]\n",
    "        #group=group.sort_values('Order')\n",
    "        offset = width * multiplier\n",
    "        rects = ax4.bar(height=group['mean'], yerr=group['std'],  x=x_ticks+offset, width=width, color=color, label=model)\n",
    "        multiplier += 1\n",
    "\n",
    "    #f1 = sns.barplot(x='Condition', y='PCC', hue='Model', palette=palette_dict, data=df_condition_pcc, ax=ax1)\n",
    "    ax4.set_xticks(x_ticks, DEPR_CONDITION_ORDER)\n",
    "    ax4.set_ylim(0,.8)\n",
    "    ax4.xaxis.grid(False)\n",
    "    ax4.xaxis.set_ticks_position('none')\n",
    "    ax4.set_ylabel('PCC')\n",
    "    ax4.set_xlabel('Condition')\n",
    "    ax4.set_title(\"Condition-wise Depr Performance\")\n",
    "    ax4.text(x=-0.05, y=1.1, s=\"E.\", fontweight='bold', fontsize=12, ha='right', va='center', transform=ax4.transAxes)\n",
    "\n",
    "    trans_wise_data = (\n",
    "        data\n",
    "        .query('(abbr == \"RDHPLT\" and seed == 1) or (abbr == \"RM\" and seed == 1)')\n",
    "        .pivot(index=['transcript', 'condition'], columns=['abbr'], values='cond_PCC'))\n",
    "    ax5.scatter(y=trans_wise_data['RDHPLT'], x=trans_wise_data['RM'], s=1, color='#332288', alpha=.4)\n",
    "    ax5.set_xlim(0,1)\n",
    "    ax5.set_ylim(0,1)\n",
    "    ax5.set_xlabel('RiboMIMO')\n",
    "    ax5.set_ylabel('Riboclette')\n",
    "    ax5.set_xticks([.25,.5,.75], [.25,.5,.75])\n",
    "    #ax5.set_aspect('equal')\n",
    "    #ax5.set_title(\"Model-wise Macro-Average\")\n",
    "    #ax5.text(x=-0.03, y=1.1, s=\"F.\", fontweight='bold', fontsize=12, ha='right', va='center', transform=ax5.transAxes)\n",
    "\n",
    "    trans_wise_data = (\n",
    "        data\n",
    "        .query('(abbr == \"RDHPLT\" and seed == 1) or (abbr == \"BLDH\" and seed == 1)')\n",
    "        .pivot(index=['transcript', 'condition'], columns=['abbr'], values='cond_PCC'))\n",
    "    ax6.scatter(y=trans_wise_data['RDHPLT'], x=trans_wise_data['BLDH'], s=1, color='#332288', alpha=.4)\n",
    "    ax6.set_xlim(0,1)\n",
    "    ax6.set_ylim(0,1)\n",
    "    ax6.set_xlabel('BiLSTM [DH]')\n",
    "    ax6.set_xticks([.25,.5,.75], [.25,.5,.75])\n",
    "    #ax6.set_aspect('equal')\n",
    "    #ax6.set_title(\"Model-wise Macro-Average\")\n",
    "    #plt.tick_params('y', labelleft=False)\n",
    "    #ax6.text(x=-0.03, y=1.1, s=\"F.\", fontweight='bold', fontsize=12, ha='right', va='center', transform=ax6.transAxes)\n",
    "    \n",
    "    trans_wise_data = (\n",
    "        data\n",
    "        .query('(abbr == \"RDHPLT\" and seed == 1) or (abbr == \"RDH\" and seed == 1)')\n",
    "        .pivot(index=['transcript', 'condition'], columns=['abbr'], values='cond_PCC'))\n",
    "    ax7.scatter(y=trans_wise_data['RDHPLT'], x=trans_wise_data['RDH'], s=1, color='#332288', alpha=.4)\n",
    "    ax7.set_xlim(0,1)\n",
    "    ax7.set_ylim(0,1)\n",
    "    ax7.set_xticks([.25,.5,.75], [.25,.5,.75])\n",
    "    ax7.set_xlabel('Riboclette [DH]')\n",
    "    #ax7.set_aspect('equal')\n",
    "    #ax7.set_title(\"Model-wise Macro-Average\")\n",
    "    #plt.tick_params('y', labelleft=False)\n",
    "    #ax7.text(x=-0.03, y=1.1, s=\"F.\", fontweight='bold', fontsize=12, ha='right', va='center', transform=ax7.transAxes)\n",
    "\n",
    "    ax_title = fig.add_subplot(gs[2,-2:])\n",
    "    ax_title.axis('off')\n",
    "    ax_title.set_title('Correlation Plots')\n",
    "\n",
    "    fig.legend(*ax2.get_legend_handles_labels(), bbox_transform=fig.transFigure, loc='center', bbox_to_anchor=(0.5, 0), borderaxespad=0., frameon=False, ncols=4)\n",
    "    \n",
    "    #sns.scatterplot(x=\"Trainset Size\", y=\"PCC\", hue='Experiment', data=df_imputation.groupby('Experiment').mean().reset_index(), ax=ax3)\n",
    "\n",
    "    #data = df_imputation.groupby('Experiment').mean()\n",
    "    #sns.scatterplot(x='MAE', y='PCC', hue='Experiment', data=data, ax=ax4)\n",
    "    #err_df = (\n",
    "    #    df_overall_pcc\n",
    "    #    .groupby('Model')\n",
    "    #    .agg({'PCC': ['mean', 'std'], 'MAE': ['mean', 'std']})\n",
    "    #    .reset_index())\n",
    "    #err_df.columns= err_df.columns.map('_'.join)\n",
    "    #err_df = (\n",
    "    #    err_df\n",
    "    #    .rename(columns={'Model_': 'Model'})\n",
    "    #    .dropna()\n",
    "    #)\n",
    "\n",
    "    #for _, row in err_df.iterrows():\n",
    "    #    ax4.errorbar(x=row['MAE_mean'], y=row['PCC_mean'], xerr=row['MAE_std'], yerr=row['PCC_std'], color=palette_dict[row['Model']],fmt=\"o\")\n",
    "    #ax4.legend(bbox_to_anchor=(-.25, 1.15), loc=2, borderaxespad=0., frameon=False, ncols=2)\n",
    "    \n",
    "\n",
    "    # svg = skunk.insert(\n",
    "    # {\n",
    "    #     'sk': 'output/pseudolabel_diagram.svg'\n",
    "    # })\n",
    "\n",
    "    # cairosvg.svg2pdf(bytestring=svg, write_to='output/performance_panel.pdf')\n",
    "    plt.savefig('../results/plots/performance_panel.pdf', dpi=600, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = (\n",
    "        df_imputation.groupby('Experiment').agg({'PCC': ['mean', 'std'], 'Trainset Size': 'mean'})\n",
    "        .reset_index())\n",
    "data.columns = ['Experiment', 'PCC_mean', 'PCC_std', 'Trainset Size']\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with plt.style.context(['science','nature','grid','bright']):\n",
    "    ax = plt.figure(constrained_layout=True, figsize=(TEXTWIDTH_CM*CM_TO_INCH, 6*CM_TO_INCH))\n",
    "    \n",
    "    data = (\n",
    "        df_imputation.groupby('Experiment').agg({'PCC': ['mean', 'std'], 'Trainset Size': 'mean'})\n",
    "        .reset_index())\n",
    "    data.columns = data.columns.map(lambda x: '_'.join([str(i) for i in x]) if x[0] == 'PCC' else x[0])\n",
    "    for idx, row in data.sort_values('Trainset Size').iterrows():\n",
    "        if 'GC' in row.Experiment:\n",
    "            sign = 1 if 'IM' in row.Experiment else -1\n",
    "            trans = Affine2D().translate(sign*1e3, 0.0) + ax3.transData\n",
    "            ax1.errorbar(x=row['Trainset Size'], y=row['PCC_mean'], yerr=row['PCC_std'], fmt=\"o\", markersize=4, transform=trans, capsize=3, label=row.Experiment)\n",
    "        else:\n",
    "            ax1.errorbar(x=row['Trainset Size'], y=row['PCC_mean'], yerr=row['PCC_std'], fmt=\"o\", markersize=4, capsize=3, label=row.Experiment)\n",
    "    ax1.legend()\n",
    "    #sns.pointplot(x=\"Trainset Size\", y=\"PCC\", hue='Experiment', capsize=.1, err_kws={'linewidth': 1.5}, markersize=3, errorbar=\"sd\", alpha=.8, dodge=True, data=df_imputation, ax=ax3)\n",
    "    ax1.set_xticks([0, 50e3, 100e3, 150e3])\n",
    "    ax1.text(x=0.05, y=.45, s=\"c.\", fontweight='bold', fontsize=12, ha='center', va='center', transform=fig.transFigure)\n",
    "    ax1.set_title(\"Imputation\")\n",
    "    ax1.set_xlabel(\"Trainset Size\")\n",
    "    ax1.set_ylabel(\"PCC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.sort_values('Trainset Size_mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_imputation.groupby('Experiment').PCC.agg(['Mean', 'Std']).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_imputation.groupby('Experiment').std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_imputation.groupby('Experiment').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_imputation['Trainset Size'] = df_imputation['Trainset Size'].astype('float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_overall_pcc.groupby('Model').mean().dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpl.rcParams.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
