{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FPATH = '/nfs_home/craigher/scratch/riboclette/results/interpretability/241001_RDHPLG_int.h5'\n",
    "FA_FPATH = '/net/lts2gdk0/mnt/scratch/lts2/nallapar/rb-prof/data/Jan_2024/Lina/reference/ensembl.cds.fa'\n",
    "GC_FPATH = '../data/genetic_code.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn as skl\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "from tqdm.auto import trange, tqdm\n",
    "from Bio import SeqIO\n",
    "import re\n",
    "import seaborn as sns\n",
    "import PyComplexHeatmap as pch\n",
    "from numba import njit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Genetic Code DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genetic_code = pd.read_csv(GC_FPATH, index_col=0).set_index('Codon')\n",
    "genetic_code.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Gene to Sequence DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trans_to_seq = []\n",
    "with open(FA_FPATH, mode=\"r\") as handle:\n",
    "    for record in SeqIO.parse(handle, \"fasta\"):\n",
    "        df_trans_to_seq.append([record.id, str(record.seq), record.description.split(\"gene_symbol:\")[1].split()[0]])\n",
    "\n",
    "df_trans_to_seq = pd.DataFrame(df_trans_to_seq, columns=[\"transcript\", \"sequence\", \"symbol\"])\n",
    "df_trans_to_seq.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conditions = ['ILE', 'LEU', 'LEU_ILE', 'LEU_ILE_VAL', 'VAL', 'CTRL']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Print h5 Keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(DATA_FPATH, 'r') as f:\n",
    "    print(f.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Weldford algorithm to compute running mean and std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from numba import jit\n",
    "\n",
    "class Welford(object):\n",
    "    \"\"\" Implements Welford's algorithm for computing a running mean\n",
    "    and standard deviation as described at: \n",
    "        http://www.johndcook.com/standard_deviation.html\n",
    "\n",
    "    can take single values or iterables\n",
    "\n",
    "    Properties:\n",
    "        mean    - returns the mean\n",
    "        std     - returns the std\n",
    "        meanfull- returns the mean and std of the mean\n",
    "\n",
    "    Usage:\n",
    "        >>> foo = Welford()\n",
    "        >>> foo(range(100))\n",
    "        >>> foo\n",
    "        <Welford: 49.5 +- 29.0114919759>\n",
    "        >>> foo([1]*1000)\n",
    "        >>> foo\n",
    "        <Welford: 5.40909090909 +- 16.4437417146>\n",
    "        >>> foo.mean\n",
    "        5.409090909090906\n",
    "        >>> foo.std\n",
    "        16.44374171455467\n",
    "        >>> foo.meanfull\n",
    "        (5.409090909090906, 0.4957974674244838)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, lst=None):\n",
    "        self.k = 0\n",
    "        self.M = 0\n",
    "        self.S = 0\n",
    "        \n",
    "        self.__call__(lst)\n",
    "    \n",
    "    @staticmethod\n",
    "    @jit(nopython=True)\n",
    "    def update_numba(k, M, S, x):\n",
    "        k += 1\n",
    "        newM = M + (x - M) * 1.0 / k\n",
    "        newS = S + (x - M) * (x - newM)\n",
    "        return k, newM, newS\n",
    "\n",
    "    def update(self, x):\n",
    "        if x is None:\n",
    "            return\n",
    "        self.k, self.M, self.S = self.update_numba(self.k, self.M, self.S, x)\n",
    "\n",
    "    def consume(self, lst):\n",
    "        for x in lst:\n",
    "            self.update(x)\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        if hasattr(x, \"__iter__\"):\n",
    "            self.consume(x)\n",
    "        else:\n",
    "            self.update(x)\n",
    "            \n",
    "    @property\n",
    "    def mean(self):\n",
    "        return self.M\n",
    "\n",
    "    @property\n",
    "    def meanfull(self):\n",
    "        return self.mean, self.std / math.sqrt(self.k)\n",
    "\n",
    "    @property\n",
    "    def std(self):\n",
    "        if self.k == 1:\n",
    "            return 0\n",
    "        return math.sqrt(self.S / (self.k - 1))\n",
    "\n",
    "    def __repr__(self):\n",
    "        return \"<Welford: {} +- {}>\".format(self.mean, self.std)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute Statistics for CTRL Head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# topk = 5\n",
    "# attr_type = 'lig'\n",
    "# condition_freq_ctrl_head = {cond: {cod: 0 for cod in genetic_code.index} for cond in conditions}\n",
    "# with h5py.File(DATA_FPATH, 'r') as f:\n",
    "#     transcripts = f['transcript'][:].astype('U') \n",
    "#     conditions = f['condition'][:].astype('U') \n",
    "#     for transc_idx in trange(transcripts.shape[0]):\n",
    "#         transcript = transcripts[transc_idx]\n",
    "#         condition = conditions[transc_idx]\n",
    "#         trasc_attr = f[f'{attr_type}_ctrl'][transc_idx]\n",
    "#         n_codons = int(np.sqrt(trasc_attr.shape[0]))\n",
    "#         trasc_attr = trasc_attr.reshape(n_codons, n_codons)\n",
    "#         sequence = df_trans_to_seq.query('transcript == @transcript').sequence.values[0]\n",
    "#         sequence = np.array(re.findall('...', sequence))\n",
    "#         for top_codon in np.argsort(trasc_attr, 1)[:,-topk:].flatten():\n",
    "#             condition_freq_ctrl_head[condition][sequence[top_codon]] += 1\n",
    "\n",
    "# condition_freq_ctrl_head = pd.DataFrame(condition_freq_ctrl_head)\n",
    "# condition_freq_ctrl_head = condition_freq_ctrl_head / condition_freq_ctrl_head.sum(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wsize = 20\n",
    "# condition_attr_ctrl_head = {cond: {cod: Welford() for cod in genetic_code.index} for cond in conditions}\n",
    "# with h5py.File(DATA_FPATH, 'r') as f:\n",
    "#     transcripts = f['transcript'][:].astype('U') \n",
    "#     depr_true = f['y'][:].astype('U') \n",
    "#     conditions = f['condition'][:].astype('U') \n",
    "#     for transc_idx in trange(transcripts.shape[0]):\n",
    "#         transcript = transcripts[transc_idx]\n",
    "#         condition = conditions[transc_idx]\n",
    "#         trasc_attr = f['attributions_ctrl'][transc_idx]\n",
    "#         n_codons = int(np.sqrt(trasc_attr.shape[0]))\n",
    "#         trasc_attr = trasc_attr.reshape(n_codons, n_codons)     \n",
    "#         sequence = df_trans_to_seq.query('transcript == @transcript').sequence.values[0]\n",
    "#         sequence = np.array(re.findall('...', sequence))\n",
    "#         for idx in np.arange(wsize, n_codons-wsize):\n",
    "#             wattr = trasc_attr[idx,idx-wsize:idx+wsize+1]\n",
    "#             wattr = np.abs(wattr)\n",
    "#             wattr = wattr / wattr.sum()\n",
    "#             for attr_idx, codon_idx in enumerate(np.arange(idx-wsize, idx+wsize+1)):\n",
    "#                 condition_attr_ctrl_head[condition][sequence[codon_idx]](wattr[attr_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# condition_attr_ctrl_head_comp = {cond: {cod: w.mean for cod, w in cod_wise.items()} for cond, cod_wise in condition_attr_ctrl_head.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.DataFrame(condition_attr_ctrl_head_comp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(30, 3))\n",
    "\n",
    "# cmap = plt.get_cmap('tab20c')\n",
    "# colors = np.array(cmap.colors)\n",
    "# np.random.seed(42)\n",
    "# np.random.shuffle(colors)\n",
    "# randomized_cmap = plt.matplotlib.colors.ListedColormap(colors)\n",
    "\n",
    "# col_ha = pch.HeatmapAnnotation(aminoacid=pch.anno_simple(genetic_code, add_text=True,legend=False,text_kws={'fontsize':10, 'color':'black'},cmap=randomized_cmap, height=5),axis=1)\n",
    "# pch.ClusterMapPlotter(\n",
    "#     data=pd.DataFrame(condition_attr_ctrl_head_comp).T,\n",
    "#     col_split=genetic_code, col_split_gap=1,\n",
    "#     top_annotation=col_ha,\n",
    "#     annot=True, \n",
    "#     fmt='.2f',\n",
    "#     cmap='coolwarm',\n",
    "#     show_rownames=True,show_colnames=True,\n",
    "#     col_cluster=False,row_cluster=False,\n",
    "#     xticklabels_kws=dict(labelrotation=-45))\n",
    "# plt.suptitle('Distribution of TOP5 attributions in the ctrl head, by condition')\n",
    "# #plt.savefig('plots/top5_attr_ctrl_head.png', dpi=400, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# topk = 5\n",
    "# condition_freq_depr_head = {cond: {cod: 0 for cod in genetic_code.index} for cond in conditions if cond != 'CTRL'}\n",
    "# with h5py.File(DATA_FPATH, 'r') as f:\n",
    "#     transcripts = f['transcript'][:].astype('U') \n",
    "#     conditions = f['condition'][:].astype('U') \n",
    "#     for transc_idx in trange(transcripts.shape[0]):\n",
    "#         condition = conditions[transc_idx]\n",
    "#         if condition == 'CTRL':\n",
    "#             continue\n",
    "#         transcript = transcripts[transc_idx]\n",
    "#         trasc_attr = f[f'{attr_type}_dd'][transc_idx]\n",
    "#         n_codons = int(np.sqrt(trasc_attr.shape[0]))\n",
    "#         trasc_attr = trasc_attr.reshape(n_codons, n_codons)\n",
    "#         sequence = df_trans_to_seq.query('transcript == @transcript').sequence.values[0]\n",
    "#         sequence = np.array(re.findall('...', sequence))\n",
    "#         for top_codon in np.argsort(trasc_attr, 1)[:,-topk:].flatten():\n",
    "#             condition_freq_depr_head[condition][sequence[top_codon]] += 1\n",
    "\n",
    "# condition_freq_depr_head = pd.DataFrame(condition_freq_depr_head)\n",
    "# condition_freq_depr_head = condition_freq_depr_head / condition_freq_depr_head.sum(0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute Statistics for Deprivation Head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wsize = 20\n",
    "attr_type = 'lig'\n",
    "ensembl_to_remove = ('145167.7')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store Weldford datastructure for each combination of codon and condition\n",
    "condition_freq_depr_head = {cond: {cod: Welford() for cod in genetic_code.index} for cond in conditions if cond != 'CTRL'}\n",
    "# Store count statistics for each combination of codon and condition\n",
    "condition_count_depr_head = {cond: {cod: 0 for cod in genetic_code.index} for cond in conditions if cond != 'CTRL'}\n",
    "\n",
    "with h5py.File(DATA_FPATH, 'r') as f:\n",
    "    transcripts = f['transcript'][:].astype('U') \n",
    "    conditions = f['condition'][:].astype('U') \n",
    "\n",
    "    # Loop throught transcripts\n",
    "    for transc_idx in trange(transcripts.shape[0]):\n",
    "        condition = conditions[transc_idx]\n",
    "\n",
    "        # Exclude control condition\n",
    "        if condition == 'CTRL':\n",
    "            continue\n",
    "\n",
    "        transcript = transcripts[transc_idx]\n",
    "\n",
    "        # Remove bad samples\n",
    "        if df_trans_to_seq.query('transcript == @transcript').transcript.str.endswith(ensembl_to_remove).values[0]:\n",
    "            continue\n",
    "\n",
    "        # Get attribution vector and reshape to matrix\n",
    "        trasc_attr = f[f'{attr_type}_dd'][transc_idx]\n",
    "        n_codons = int(np.sqrt(trasc_attr.shape[0]))\n",
    "        trasc_attr = trasc_attr.reshape(n_codons, n_codons)\n",
    "\n",
    "        # Get sequence\n",
    "        sequence = df_trans_to_seq.query('transcript == @transcript').sequence.values[0]\n",
    "        sequence = np.array(re.findall('...', sequence))\n",
    "\n",
    "        #depr_true = f['y_true_dd'][transc_idx]\n",
    "        #threshold = np.nanquantile(np.abs(depr_true), .9)\n",
    "        #good_idxs = np.nonzero(np.abs(depr_true) > threshold)[0]\n",
    "        #good_idxs = good_idxs[(good_idxs>=wsize) & (good_idxs < n_codons-wsize-1)]\n",
    "\n",
    "        # Loop through the sequence, excluding a prefix and suffix of wsize and wsize+1, respectively\n",
    "        for idx in np.arange(wsize, n_codons-wsize-1):\n",
    "        #for idx in np.arange(n_codons-1):\n",
    "            #wattr = trasc_attr[idx]\n",
    "            wattr = trasc_attr[idx,idx-wsize:idx+wsize+1]\n",
    "            wattr = np.abs(wattr)\n",
    "            wattr = wattr / wattr.sum()\n",
    "            for attr_idx, codon_idx in enumerate(np.arange(idx-wsize, idx+wsize+1)):\n",
    "            #for attr_idx, codon_idx in enumerate(np.arange(n_codons-1)):\n",
    "                condition_freq_depr_head[condition][sequence[codon_idx]](wattr[attr_idx])\n",
    "                condition_count_depr_head[condition][sequence[codon_idx]] += 1\n",
    "\n",
    "condition_freq_depr_head = {cond: {cod: w.mean for cod, w in cod_wise.items()} for cond, cod_wise in condition_freq_depr_head.items()}\n",
    "condition_freq_depr_head = pd.DataFrame(condition_freq_depr_head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(30, 3))\n",
    "\n",
    "# cmap = plt.get_cmap('tab20c')\n",
    "# colors = np.array(cmap.colors)\n",
    "# np.random.seed(42)\n",
    "# np.random.shuffle(colors)\n",
    "# randomized_cmap = plt.matplotlib.colors.ListedColormap(colors)\n",
    "\n",
    "# col_ha = pch.HeatmapAnnotation(aminoacid=pch.anno_simple(genetic_code, add_text=True,legend=False,text_kws={'fontsize':10, 'color':'black'},cmap=randomized_cmap, height=5),axis=1)\n",
    "# pch.ClusterMapPlotter(\n",
    "#     data=condition_freq_depr_head.T,\n",
    "#     col_split=genetic_code, col_split_gap=1,\n",
    "#     top_annotation=col_ha,\n",
    "#     annot=True, \n",
    "#     fmt='.2f',\n",
    "#     cmap='coolwarm',\n",
    "#     show_rownames=True,show_colnames=True,\n",
    "#     col_cluster=False,row_cluster=False,\n",
    "#     xticklabels_kws=dict(labelrotation=-45),\n",
    "#     row_cluster_metric='euclidean', col_cluster_metric='euclidean')\n",
    "# plt.suptitle('Distribution of TOP5 attributions in the deprivation head, by condition')\n",
    "# plt.savefig('../results/plots/top5_attr_depr_head.pdf', dpi=400, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import marsilea as ma\n",
    "\n",
    "AA = ['Val', 'Ile', 'Leu', 'Lys', 'Asn', 'Thr', 'Arg', 'Ser', 'Met', 'Gln', 'His', 'Pro', 'Glu', 'Asp', 'Ala', 'Gly', 'Tyr', 'Cys', 'Trp', 'Phe', 'Stp']\n",
    "DEPR_NAMES = {'ILE':'ILE (I)', 'LEU':'LEU (L)', 'VAL':'VAL (V)', 'LEU_ILE':'(L, I)', 'LEU_ILE_VAL':'(L,I,V)'}\n",
    "data = condition_freq_depr_head.rename(columns=DEPR_NAMES).reindex(columns=DEPR_NAMES.values())\n",
    "h = ma.Heatmap(data.T, width=17, height=1.5)\n",
    "\n",
    "cmap = plt.get_cmap('tab20c')\n",
    "colors = np.array(cmap.colors).repeat(2,0)\n",
    "np.random.seed(42)\n",
    "np.random.shuffle(colors)\n",
    "\n",
    "h.group_cols(genetic_code.AminoAcid, spacing=0.002, order=AA)\n",
    "h.add_top(\n",
    "        ma.plotter.Chunk(\n",
    "            AA,\n",
    "            colors[:len(AA)],\n",
    "            padding=10,\n",
    "            fontsize=12\n",
    "        ),\n",
    "        pad=0.025\n",
    "    )\n",
    "h.add_bottom(ma.plotter.Labels(data.index, rotation=45,fontsize=12), name='Codon')\n",
    "h.add_left(ma.plotter.Labels(data.columns,align='center',fontsize=12), name='Deprivation')\n",
    "h.add_legends()\n",
    "h.add_title(\"Deprivation Head Average Attribution (-20/+20 A-site window)\",fontsize=16)\n",
    "h.render()\n",
    "plt.savefig('../results/plots/window_depr_head.pdf', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
