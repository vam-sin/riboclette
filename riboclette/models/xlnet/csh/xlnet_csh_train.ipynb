{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# libraries\n",
    "import torch\n",
    "from transformers import XLNetConfig, XLNetForTokenClassification, EarlyStoppingCallback\n",
    "from xlnet_csh_utils import RegressionTrainer, RiboDatasetGWSDepr, GWSDatasetFromPandas  # custom dataset and trainer\n",
    "from transformers import TrainingArguments\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torchmetrics.functional import pearson_corrcoef\n",
    "from torchmetrics import Metric\n",
    "import wandb \n",
    "import pytorch_lightning as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CorrCoef(Metric):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.add_state(\"corrcoefs\", default=torch.tensor(0.0), dist_reduce_fx=\"sum\")\n",
    "        self.add_state(\"total\", default=torch.tensor(0.0), dist_reduce_fx=\"sum\")\n",
    "    def update(self, preds, target, mask):\n",
    "        # # sum preds in dim 2\n",
    "        # preds = torch.sum(preds, dim=2)\n",
    "        preds = preds[:, 1:]\n",
    "        # print(preds.shape, target.shape, mask.shape)\n",
    "        assert preds.shape == target.shape\n",
    "        assert preds.shape == mask.shape\n",
    "        coeffs = []\n",
    "        for p, t, m in zip(preds, target, mask):\n",
    "            mp, mt = torch.masked_select(p, m), torch.masked_select(t, m)\n",
    "            temp_pearson = pearson_corrcoef(mp, mt)\n",
    "            coeffs.append(temp_pearson)\n",
    "        coeffs = torch.stack(coeffs)\n",
    "        self.corrcoefs += torch.sum(coeffs)\n",
    "        self.total += len(coeffs)\n",
    "    def compute(self):\n",
    "        return self.corrcoefs / self.total\n",
    "\n",
    "# collate function\n",
    "def collate_fn(batch):\n",
    "    # batch is a list of tuples (x, y)\n",
    "    x, y, gene, transcript = zip(*batch)\n",
    "\n",
    "    # sequence lenghts \n",
    "    lengths = torch.tensor([len(x) for x in x])\n",
    "    x = pad_sequence(x, batch_first=True, padding_value=64) \n",
    "    y = pad_sequence(y, batch_first=True, padding_value=-1)\n",
    "\n",
    "    out_batch = {}\n",
    "\n",
    "    out_batch[\"input_ids\"] = x\n",
    "    out_batch[\"labels\"] = y\n",
    "    out_batch[\"lengths\"] = lengths\n",
    "\n",
    "    return out_batch\n",
    "\n",
    "# compute metrics\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids \n",
    "    preds = pred.predictions\n",
    "    mask = labels != -100.0\n",
    "    labels = torch.tensor(labels)\n",
    "    preds = torch.tensor(preds)\n",
    "    preds = torch.squeeze(preds, dim=2)\n",
    "    mask = torch.tensor(mask)\n",
    "    mask = torch.logical_and(mask, torch.logical_not(torch.isnan(labels)))\n",
    "    corr_coef = CorrCoef()\n",
    "    corr_coef.update(preds, labels, mask)\n",
    "\n",
    "    return {\"r\": corr_coef.compute()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "seed = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reproducibility\n",
    "pl.seed_everything(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = '/net/lts2gdk0/mnt/scratch/lts2/nallapar/rb-prof/data/Jan_2024/Lina/processed/'\n",
    "annot_thresh = 0.3\n",
    "loss_fun_name = 'MAE_PCC'\n",
    "longZerosThresh_val = 20\n",
    "percNansThresh_val = 0.05\n",
    "\n",
    "# GWS dataset\n",
    "train_dataset, val_dataset, test_dataset = RiboDatasetGWSDepr(threshold = annot_thresh, longZerosThresh = longZerosThresh_val, percNansThresh = percNansThresh_val)\n",
    "\n",
    "# convert to torch dataset\n",
    "train_dataset = GWSDatasetFromPandas(train_dataset)\n",
    "val_dataset = GWSDatasetFromPandas(val_dataset)\n",
    "test_dataset = GWSDatasetFromPandas(test_dataset)\n",
    "\n",
    "print(\"samples in train dataset: \", len(train_dataset))\n",
    "print(\"samples in val dataset: \", len(val_dataset))\n",
    "print(\"samples in test dataset: \", len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "tot_epochs = 100\n",
    "n_layers_val = 5\n",
    "batch_size_val = 4\n",
    "lr_val = 1e-3\n",
    "dropout_val = 0.1\n",
    "d_model_val = 128\n",
    "n_heads_val = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load xlnet to train from scratch\n",
    "# training arguments\n",
    "model_name = 'XLNet-CSH ' + '[NL: ' + str(n_layers_val) + ', NH: ' + str(n_heads_val) + ', D: ' + str(d_model_val) + ', LR: ' + str(lr_val) + ', BS: ' + str(batch_size_val) + ', LF: ' + loss_fun_name + ', Dr: ' + str(dropout_val) + ', S: ' + str(seed) + ']'\n",
    "output_loc = \"saved_models/\" + model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xlnet_config = XLNetConfig(vocab_size=71, pad_token_id=70, d_model = d_model_val, n_layer = n_layers_val, n_head = n_heads_val, d_inner = d_model_val, num_labels = 1, dropout=dropout_val) # 4^3 + 1 for padding\n",
    "model = XLNetForTokenClassification(xlnet_config)\n",
    "\n",
    "model.classifier = torch.nn.Linear(d_model_val, 1, bias=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.init(project=\"Riboclette\", name=model_name)\n",
    "\n",
    "output_loc = \"saved_models/\" + model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train xlnet\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=output_loc,\n",
    "    learning_rate=lr_val,\n",
    "    per_device_train_batch_size=1,\n",
    "    gradient_accumulation_steps=batch_size_val,\n",
    "    per_device_eval_batch_size=1,\n",
    "    eval_accumulation_steps=4,\n",
    "    num_train_epochs=tot_epochs,\n",
    "    weight_decay=0.01,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    push_to_hub=False,\n",
    "    dataloader_pin_memory=True,\n",
    "    dataloader_num_workers=4,\n",
    "    report_to=\"wandb\"\n",
    ")\n",
    "\n",
    "trainer = RegressionTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    data_collator=collate_fn,\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks = [EarlyStoppingCallback(early_stopping_patience=10)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()\n",
    "\n",
    "# save best model\n",
    "trainer.save_model(output_loc + \"/best_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = trainer.evaluate(eval_dataset=test_dataset)\n",
    "\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "riboclette",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
