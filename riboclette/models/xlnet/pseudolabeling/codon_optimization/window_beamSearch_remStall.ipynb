{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# libraries\n",
    "import torch\n",
    "from transformers import XLNetConfig, XLNetForTokenClassification\n",
    "from xlnet_plabel_utils import GWSDatasetFromPandas \n",
    "import itertools\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "# suppress warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_codons = ['TAA', 'TAG', 'TGA']\n",
    "\n",
    "# global variables\n",
    "id_to_codon = {idx:''.join(el) for idx, el in enumerate(itertools.product(['A', 'T', 'C', 'G'], repeat=3))}\n",
    "codon_to_id = {v:k for k,v in id_to_codon.items()}\n",
    "\n",
    "codonid_list = []\n",
    "\n",
    "for i in range(64):\n",
    "    codon = id_to_codon[i]\n",
    "    if codon not in stop_codons:\n",
    "        codonid_list.append(i)\n",
    "\n",
    "print('Number of codons:', len(codonid_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model parameters\n",
    "annot_thresh = 0.3\n",
    "longZerosThresh_val = 20\n",
    "percNansThresh_val = 0.05\n",
    "d_model_val = 512\n",
    "n_layers_val = 6\n",
    "n_heads_val = 4\n",
    "dropout_val = 0.1\n",
    "lr_val = 1e-4\n",
    "batch_size_val = 2\n",
    "loss_fun_name = '4L' # 5L\n",
    "\n",
    "# model name and output folder path\n",
    "# output_loc = '/nfs_home/nallapar/final/riboclette/riboclette/models/xlnet/pseudolabeling/saved_models/XLNet-PLabelDH  Exp: exp1 [NL: 6, NH: 4, D: 512, LR: 0.0001, BS: 2, LF: 4L, Dr: 0.1, S: 2]' \n",
    "output_loc = 'saved_models/XLNet-PLabelDH  Exp: exp1 [NL: 6, NH: 4, D: 512, LR: 0.0001, BS: 2, LF: 4L, Dr: 0.1, S: 2]' \n",
    "\n",
    "condition_dict_values = {64: 'CTRL', 65: 'ILE', 66: 'LEU', 67: 'LEU_ILE', 68: 'LEU_ILE_VAL', 69: 'VAL'}\n",
    "condition_dict = {v: k for k, v in condition_dict_values.items()}\n",
    "\n",
    "class XLNetDH(XLNetForTokenClassification):\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "        self.classifier = torch.nn.Linear(d_model_val, 2, bias=True)\n",
    "\n",
    "config = XLNetConfig(vocab_size=71, pad_token_id=70, d_model = d_model_val, n_layer = n_layers_val, n_head = n_heads_val, d_inner = d_model_val, num_labels = 1, dropout=dropout_val) # 64*6 tokens + 1 for padding\n",
    "model = XLNetDH(config)\n",
    "\n",
    "# load model from the saved model\n",
    "model = model.from_pretrained(output_loc + \"/best_model\")\n",
    "model.to(device)\n",
    "# set model to evaluation mode\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert pandas dataframes into torch datasets\n",
    "test_dataset = pd.read_csv('data/orig/test_0.3_NZ_20_PercNan_0.05.csv')\n",
    "train_dataset = pd.read_csv('data/orig/train_0.3_NZ_20_PercNan_0.05.csv')\n",
    "val_dataset = pd.read_csv('data/orig/val_0.3_NZ_20_PercNan_0.05.csv')\n",
    "\n",
    "# test_dataset = pd.read_csv('../../../data/orig/test_0.3_NZ_20_PercNan_0.05.csv')\n",
    "# train_dataset = pd.read_csv('../../../data/orig/train_0.3_NZ_20_PercNan_0.05.csv')\n",
    "# val_dataset = pd.read_csv('../../../data/orig/val_0.3_NZ_20_PercNan_0.05.csv')\n",
    "\n",
    "# merge the datasets\n",
    "merged_dataset = pd.concat([train_dataset, val_dataset, test_dataset], ignore_index=True)\n",
    "\n",
    "# create the datasets\n",
    "merged_dataset = GWSDatasetFromPandas(merged_dataset)\n",
    "# val_dataset = GWSDatasetFromPandas(val_dataset)\n",
    "\n",
    "print(\"samples in merged dataset: \", len(merged_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "num_windows = 1000\n",
    "model_bs = 256\n",
    "include_A_site = 'Yes' # 'Yes' or 'No'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 21 # for potential disome\n",
    "conditions_windows = {'CTRL': [], 'ILE': [], 'LEU': [], 'LEU_ILE': [], 'LEU_ILE_VAL': [], 'VAL': []}\n",
    "conditions_windows_fin = {'CTRL': [], 'ILE': [], 'LEU': [], 'LEU_ILE': [], 'LEU_ILE_VAL': [], 'VAL': []}\n",
    "\n",
    "# get num_windows random samples per condition from the merged dataset\n",
    "for i in tqdm(range(len(merged_dataset))): \n",
    "    sample_condition = merged_dataset[i][0][0].item()\n",
    "    g = merged_dataset[i][3]\n",
    "    t = merged_dataset[i][4]\n",
    "    y_true_sample = merged_dataset[i][1].numpy()\n",
    "    x_input_sample = merged_dataset[i][0].numpy()\n",
    "    if len(y_true_sample) > 500:\n",
    "        continue\n",
    "    peak = np.nanmean(y_true_sample) + np.nanstd(y_true_sample)\n",
    "    for j in range(window_size, len(y_true_sample)-window_size):\n",
    "        sample_window = x_input_sample[j:j+window_size]\n",
    "        if len(sample_window) == window_size:\n",
    "            if sample_window[10] > peak:\n",
    "                conditions_windows[condition_dict_values[sample_condition]].append((g, t, x_input_sample, j))\n",
    "    \n",
    "# print len of each condition\n",
    "for k, v in conditions_windows.items():\n",
    "    print(k, len(v))\n",
    "\n",
    "# save the windows\n",
    "np.savez('bms/windows_remStall.npz', conditions_windows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conditions_windows = np.load('bms/windows_remStall.npz', allow_pickle=True)['arr_0'].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose at random num_windows windows from each condition\n",
    "for condition in conditions_windows:\n",
    "    np.random.shuffle(conditions_windows[condition])\n",
    "    conditions_windows_fin[condition] = conditions_windows[condition][:num_windows]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AsiteDensity(window, condition, start):\n",
    "    # prepend condition value to the window\n",
    "    condition_val = condition_dict[condition]\n",
    "    window = np.insert(window, 0, condition_val)\n",
    "    window = torch.tensor(window).unsqueeze(0).to(device)\n",
    "    # get the model prediction\n",
    "    with torch.no_grad():\n",
    "        pred = model(window)\n",
    "    pred = pred[\"logits\"][:, 1:, :]\n",
    "    # relu on the first dimension\n",
    "    ctrl = torch.relu(pred[:, :, 0])\n",
    "    dd = pred[:, :, 1]\n",
    "    # get the density at the A-site only\n",
    "    dd_out = dd[:, 10+start]\n",
    "    ctrl_out = ctrl[:, 10+start]\n",
    "\n",
    "    if condition_val == 64:\n",
    "        return ctrl_out\n",
    "    else:\n",
    "        return dd_out\n",
    "    \n",
    "def AsiteDensityBatch(windows, condition, start):\n",
    "    # prepend condition value to the window\n",
    "    condition_val = condition_dict[condition]\n",
    "    windows = np.insert(windows, 0, condition_val, axis=1)\n",
    "    windows = torch.tensor(windows).to(device)\n",
    "    # get the model prediction\n",
    "    with torch.no_grad():\n",
    "        for i in range(0, windows.shape[0], model_bs):\n",
    "            pred = model(windows[i:i+model_bs])\n",
    "            if i == 0:\n",
    "                pred_out = pred[\"logits\"][:, 1:, :]\n",
    "            else:\n",
    "                pred_out = torch.cat((pred_out, pred[\"logits\"][:, 1:, :]), 0)\n",
    "    # relu on the first dimension\n",
    "    ctrl = torch.relu(pred_out[:, :, 0])\n",
    "    dd = pred_out[:, :, 1]\n",
    "    # get the density at the A-site only\n",
    "    dd_out = dd[:, start+10]\n",
    "    ctrl_out = ctrl[:, start+10]\n",
    "\n",
    "    if condition_val == 64:\n",
    "        return ctrl_out\n",
    "    else:\n",
    "        return dd_out\n",
    "\n",
    "def getTopXMutants(full_inp, start, condition, X, mutant_pos1=-1, c_pos1=None, mutant_pos2=-1, c_pos2=None):\n",
    "    # start+10 is the A-site\n",
    "    window_density = {}\n",
    "    if mutant_pos1 == -1 and mutant_pos2 == -1:\n",
    "        inputs_all = []\n",
    "        substs_all = []\n",
    "        for k in range(window_size):\n",
    "            if k == 10:\n",
    "                continue\n",
    "            for c in codonid_list:\n",
    "                input_copy = full_inp.copy()\n",
    "                input_copy[start+k] = c\n",
    "                inputs_all.append(input_copy)\n",
    "                substs_all.append((start+k, c))\n",
    "        inputs_all = np.array(inputs_all)\n",
    "        preds = AsiteDensityBatch(inputs_all, condition, start)\n",
    "        for l in range(len(substs_all)): \n",
    "            window_density[(substs_all[l][0], substs_all[l][1])] = preds[l].item()\n",
    "    elif mutant_pos1 != -1 and mutant_pos2 == -1:\n",
    "        inputs_all = []\n",
    "        substs_all = []\n",
    "        for k in range(window_size):\n",
    "            if k == 10 or k+start == mutant_pos1:\n",
    "                continue\n",
    "            for c in codonid_list:\n",
    "                input_copy = full_inp.copy()\n",
    "                input_copy[start+k] = c\n",
    "                input_copy[mutant_pos1] = c_pos1\n",
    "                inputs_all.append(input_copy)\n",
    "                substs_all.append((start+k, c))\n",
    "        inputs_all = np.array(inputs_all)\n",
    "        preds = AsiteDensityBatch(inputs_all, condition, start)\n",
    "        for l in range(len(substs_all)): \n",
    "            window_density[(mutant_pos1, c_pos1, substs_all[l][0], substs_all[l][1])] = preds[l].item()\n",
    "    elif mutant_pos1 != -1 and mutant_pos2 != -1:\n",
    "        inputs_all = []\n",
    "        substs_all = []\n",
    "        for k in range(window_size):\n",
    "            if k == 10 or k+start == mutant_pos1 or k+start == mutant_pos2:\n",
    "                continue\n",
    "            for c in codonid_list:\n",
    "                input_copy = full_inp.copy()\n",
    "                input_copy[start+k] = c\n",
    "                input_copy[mutant_pos1] = c_pos1\n",
    "                input_copy[mutant_pos2] = c_pos2\n",
    "                inputs_all.append(input_copy)\n",
    "                substs_all.append((start+k, c))\n",
    "        inputs_all = np.array(inputs_all)\n",
    "        preds = AsiteDensityBatch(inputs_all, condition, start)\n",
    "        for l in range(len(substs_all)): \n",
    "            window_density[(mutant_pos2, c_pos2, mutant_pos1, c_pos1, substs_all[l][0], substs_all[l][1])] = preds[l].item()\n",
    "\n",
    "    # sort the dictionary by values\n",
    "    window_density = dict(sorted(window_density.items(), key=lambda item: item[1], reverse=False))\n",
    "\n",
    "    # choose only top k\n",
    "    window_density = dict(itertools.islice(window_density.items(), X))\n",
    "\n",
    "    return window_density\n",
    "\n",
    "def getTopXMutantsWA(full_inp, start, condition, X, mutant_pos1=-1, c_pos1=None, mutant_pos2=-1, c_pos2=None):\n",
    "    # start+10 is the A-site\n",
    "    window_density = {}\n",
    "    if mutant_pos1 == -1 and mutant_pos2 == -1:\n",
    "        inputs_all = []\n",
    "        substs_all = []\n",
    "        for k in range(window_size):\n",
    "            # if k == 10:\n",
    "            #     continue\n",
    "            for c in codonid_list:\n",
    "                input_copy = full_inp.copy()\n",
    "                input_copy[start+k] = c\n",
    "                inputs_all.append(input_copy)\n",
    "                substs_all.append((start+k, c))\n",
    "        inputs_all = np.array(inputs_all)\n",
    "        preds = AsiteDensityBatch(inputs_all, condition, start)\n",
    "        for l in range(len(substs_all)): \n",
    "            window_density[(substs_all[l][0], substs_all[l][1])] = preds[l].item()\n",
    "    elif mutant_pos1 != -1 and mutant_pos2 == -1:\n",
    "        inputs_all = []\n",
    "        substs_all = []\n",
    "        for k in range(window_size):\n",
    "            if k+start == mutant_pos1:\n",
    "                continue\n",
    "            for c in codonid_list:\n",
    "                input_copy = full_inp.copy()\n",
    "                input_copy[start+k] = c\n",
    "                input_copy[mutant_pos1] = c_pos1\n",
    "                inputs_all.append(input_copy)\n",
    "                substs_all.append((start+k, c))\n",
    "        inputs_all = np.array(inputs_all)\n",
    "        preds = AsiteDensityBatch(inputs_all, condition, start)\n",
    "        for l in range(len(substs_all)): \n",
    "            window_density[(mutant_pos1, c_pos1, substs_all[l][0], substs_all[l][1])] = preds[l].item()\n",
    "    elif mutant_pos1 != -1 and mutant_pos2 != -1:\n",
    "        inputs_all = []\n",
    "        substs_all = []\n",
    "        for k in range(window_size):\n",
    "            if k+start == mutant_pos1 or k+start == mutant_pos2:\n",
    "                continue\n",
    "            for c in codonid_list:\n",
    "                input_copy = full_inp.copy()\n",
    "                input_copy[start+k] = c\n",
    "                input_copy[mutant_pos1] = c_pos1\n",
    "                input_copy[mutant_pos2] = c_pos2\n",
    "                inputs_all.append(input_copy)\n",
    "                substs_all.append((start+k, c))\n",
    "        inputs_all = np.array(inputs_all)\n",
    "        preds = AsiteDensityBatch(inputs_all, condition, start)\n",
    "        for l in range(len(substs_all)): \n",
    "            window_density[(mutant_pos2, c_pos2, mutant_pos1, c_pos1, substs_all[l][0], substs_all[l][1])] = preds[l].item()\n",
    "\n",
    "    # sort the dictionary by values\n",
    "    window_density = dict(sorted(window_density.items(), key=lambda item: item[1], reverse=False))\n",
    "\n",
    "    # choose only top k\n",
    "    window_density = dict(itertools.islice(window_density.items(), X))\n",
    "\n",
    "    return window_density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each of the conditions and each of the windows, mutate one codon at a time and check the value at the A site, and choose the top 5 mutations that decrease the value\n",
    "mutations_everything = {}\n",
    "num_mutants = 5\n",
    "for condition in conditions_windows_fin:\n",
    "    for sample in tqdm(conditions_windows_fin[condition]):\n",
    "        sample_mutations = {}\n",
    "        window = sample[2][sample[3]:sample[3]+window_size]\n",
    "        original_density = AsiteDensity(sample[2], condition, sample[3]).item()\n",
    "        if include_A_site == 'Yes':\n",
    "            mutants_one = getTopXMutantsWA(sample[2], sample[3], condition, num_mutants)\n",
    "        else:\n",
    "            mutants_one = getTopXMutants(sample[2], sample[3], condition, num_mutants)\n",
    "        # print(\"Gen 1:\", mutants_one)\n",
    "        # add all the mutants to the list\n",
    "        for x in mutants_one:\n",
    "            sample_mutations[x] = mutants_one[x]\n",
    "        for mutant in mutants_one:\n",
    "            mutant_pos1 = mutant[0]\n",
    "            c_pos1 = mutant[1]\n",
    "            if include_A_site == 'Yes':\n",
    "                mutants_two = getTopXMutantsWA(sample[2], sample[3], condition, num_mutants, mutant_pos1, c_pos1)\n",
    "            else:\n",
    "                mutants_two = getTopXMutants(sample[2], sample[3], condition, num_mutants, mutant_pos1, c_pos1)\n",
    "            # print(\"Gen 2:\", mutants_two)\n",
    "            # add all the mutants to the list\n",
    "            for x in mutants_two:\n",
    "                sample_mutations[x] = mutants_two[x]\n",
    "            for mutant2 in mutants_two:\n",
    "                mutant_pos2 = mutant2[2]\n",
    "                c_pos2 = mutant2[3]\n",
    "                if include_A_site == 'Yes':\n",
    "                    mutants_three = getTopXMutantsWA(sample[2], sample[3], condition, num_mutants, mutant_pos1, c_pos1, mutant_pos2, c_pos2)\n",
    "                else:\n",
    "                    mutants_three = getTopXMutants(sample[2], sample[3], condition, num_mutants, mutant_pos1, c_pos1, mutant_pos2, c_pos2)\n",
    "                # print(\"Gen 3:\", mutants_three)\n",
    "                # add all the mutants to the list\n",
    "                for x in mutants_three:\n",
    "                    sample_mutations[x] = mutants_three[x]\n",
    "\n",
    "        mutations_everything[(sample[0], sample[1], sample[3], str(window), condition, original_density)] = sample_mutations\n",
    "    \n",
    "    # save the mutations to a file\n",
    "    if include_A_site == 'Yes':\n",
    "        out_file_name = 'bms/motifswA_remStall_' + str(num_windows) + '_' + condition + '.npz'\n",
    "    else:\n",
    "        out_file_name = 'bms/motifs_remStall_' + str(num_windows) + '_' + condition + '.npz'\n",
    "    np.savez(out_file_name, mutations_everything)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the mutations to a file\n",
    "if include_A_site == 'Yes':\n",
    "    np.savez('bms/motifswAF_remStall_' + str(num_windows) + '.npz', mutations_everything=mutations_everything)\n",
    "else:\n",
    "    np.savez('bms/motifsF_remStall_' + str(num_windows) + '.npz', mutations_everything=mutations_everything)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
