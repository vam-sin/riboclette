{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from captum.attr import LayerIntegratedGradients, LayerGradientXActivation\n",
    "from transformers import XLNetConfig, XLNetForTokenClassification\n",
    "from xlnet_plabel_utils import GWSDatasetFromPandas  # custom dataset and trainer, CorrCoef, collate_fn, compute_metrics, compute_metrics_saved  # custom dataset and trainer\n",
    "import pytorch_lightning as pl\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "# suppress warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "part = 0\n",
    "tot_parts = 16\n",
    "ibs = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class model_CTRL(torch.nn.Module):\n",
    "    def __init__(self, model):\n",
    "        super().__init__()\n",
    "        self.model = model \n",
    "    \n",
    "    def forward(self, x, index_val):\n",
    "        # input dict\n",
    "        out_batch = {}\n",
    "\n",
    "        out_batch[\"input_ids\"] = x.unsqueeze(0)\n",
    "        for k, v in out_batch.items():\n",
    "            out_batch[k] = v.to(device)\n",
    "\n",
    "        out_batch[\"input_ids\"] = torch.tensor(out_batch[\"input_ids\"]).to(device).to(torch.int32)\n",
    "        pred = self.model(out_batch[\"input_ids\"])\n",
    "\n",
    "        # get dim 0\n",
    "        pred_fin = torch.relu(pred[\"logits\"][:, :, 0])\n",
    "\n",
    "        pred_fin = pred_fin.squeeze(0)\n",
    "\n",
    "        out = pred_fin[index_val].unsqueeze(0)\n",
    "\n",
    "        return out \n",
    "    \n",
    "class model_DD(torch.nn.Module):\n",
    "    def __init__(self, model):\n",
    "        super().__init__()\n",
    "        self.model = model \n",
    "    \n",
    "    def forward(self, x, index_val):\n",
    "        # input dict\n",
    "        out_batch = {}\n",
    "\n",
    "        out_batch[\"input_ids\"] = x.unsqueeze(0)\n",
    "        for k, v in out_batch.items():\n",
    "            out_batch[k] = v.to(device)\n",
    "\n",
    "        out_batch[\"input_ids\"] = torch.tensor(out_batch[\"input_ids\"]).to(device).to(torch.int32)\n",
    "\n",
    "        pred = self.model(out_batch[\"input_ids\"])\n",
    "\n",
    "        # get dim 1\n",
    "        pred_fin = pred[\"logits\"][:, :, 1]\n",
    "\n",
    "        pred_fin = pred_fin.squeeze(0)\n",
    "\n",
    "        out = pred_fin[index_val].unsqueeze(0)\n",
    "\n",
    "        return out \n",
    "\n",
    "def lig_output(model, x, y, mode='ctrl'):\n",
    "    if mode == 'ctrl':\n",
    "        model_fin = model_CTRL(model)\n",
    "    elif mode == 'dd':\n",
    "        model_fin = model_DD(model)\n",
    "        \n",
    "    lig = LayerIntegratedGradients(model_fin, model_fin.model.transformer.word_embedding)\n",
    "\n",
    "    # set torch graph to allow unused tensors\n",
    "    with torch.autograd.set_detect_anomaly(True):\n",
    "\n",
    "        out_batch = {}\n",
    "\n",
    "        out_batch[\"input_ids\"] = x\n",
    "        \n",
    "        out_batch[\"input_ids\"] = torch.tensor(out_batch[\"input_ids\"]).to(device).to(torch.int32)\n",
    "\n",
    "        baseline_inp = torch.ones(out_batch[\"input_ids\"].shape) * 70 # 70 is the padding token\n",
    "        baseline_inp = baseline_inp.to(device).to(torch.int32)\n",
    "    \n",
    "        # get all indices\n",
    "\n",
    "        len_sample = len(x)\n",
    "        attributions_sample = np.zeros((len_sample, len_sample))\n",
    "\n",
    "        for j in tqdm(range(len_sample)):\n",
    "            index_val = j\n",
    "\n",
    "            index_val = torch.tensor(index_val).to(device)\n",
    "\n",
    "            attributions = lig.attribute((out_batch[\"input_ids\"]), baselines=baseline_inp, \n",
    "                                                    method = 'gausslegendre', return_convergence_delta = False, additional_forward_args=index_val, n_steps=10, internal_batch_size=ibs)\n",
    "\n",
    "            \n",
    "            attributions = attributions.squeeze(1)\n",
    "            print(attributions.shape)\n",
    "            attributions = torch.sum(attributions, dim=1)\n",
    "            attributions = attributions / torch.norm(attributions)\n",
    "            attributions = attributions.detach().cpu().numpy()\n",
    "            attributions_sample[j] = attributions\n",
    "        \n",
    "        attributions_sample = np.array(attributions_sample)\n",
    "\n",
    "        # remove first column which is padding token\n",
    "        attributions_sample = attributions_sample[1:, 1:]\n",
    "\n",
    "        # flatten the attributions\n",
    "        attributions_sample = attributions_sample.flatten()\n",
    "\n",
    "    return attributions_sample\n",
    "\n",
    "def lxg_output(model, x, y, mode='ctrl'):\n",
    "    if mode == 'ctrl':\n",
    "        model_fin = model_CTRL(model)\n",
    "    elif mode == 'dd':\n",
    "        model_fin = model_DD(model)\n",
    "        \n",
    "    lxg = LayerGradientXActivation(model_fin, model_fin.model.transformer.word_embedding)\n",
    "\n",
    "    # set torch graph to allow unused tensors\n",
    "    with torch.autograd.set_detect_anomaly(True):\n",
    "\n",
    "        out_batch = {}\n",
    "\n",
    "        out_batch[\"input_ids\"] = x\n",
    "        \n",
    "        out_batch[\"input_ids\"] = torch.tensor(out_batch[\"input_ids\"]).to(device).to(torch.int32)\n",
    "\n",
    "        baseline_inp = torch.ones(out_batch[\"input_ids\"].shape) * 70 # 70 is the padding token\n",
    "        baseline_inp = baseline_inp.to(device).to(torch.int32)\n",
    "    \n",
    "        # get all indices\n",
    "\n",
    "        len_sample = len(x)\n",
    "        attributions_sample = np.zeros((len_sample, len_sample))\n",
    "\n",
    "        for j in tqdm(range(len_sample)):\n",
    "            index_val = j\n",
    "\n",
    "            index_val = torch.tensor(index_val).to(device)\n",
    "\n",
    "            attributions = lxg.attribute((out_batch[\"input_ids\"]), additional_forward_args=index_val)\n",
    "            \n",
    "            attributions = attributions.squeeze(1)\n",
    "            print(attributions.shape)\n",
    "            attributions = torch.sum(attributions, dim=1)\n",
    "            attributions = attributions / torch.norm(attributions)\n",
    "            attributions = attributions.detach().cpu().numpy()\n",
    "            attributions_sample[j] = attributions\n",
    "        \n",
    "        attributions_sample = np.array(attributions_sample)\n",
    "\n",
    "        # remove first column which is padding token\n",
    "        attributions_sample = attributions_sample[1:, 1:]\n",
    "\n",
    "        # flatten the attributions\n",
    "        attributions_sample = attributions_sample.flatten()\n",
    "\n",
    "    return attributions_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reproducibility\n",
    "seed_val = 2\n",
    "pl.seed_everything(seed_val) \n",
    "\n",
    "# add argument for part\n",
    "print(\"part: \", part)\n",
    "\n",
    "# model parameters\n",
    "annot_thresh = 0.3\n",
    "longZerosThresh_val = 20\n",
    "percNansThresh_val = 0.05\n",
    "d_model_val = 512\n",
    "n_layers_val = 6\n",
    "n_heads_val = 4\n",
    "dropout_val = 0.1\n",
    "lr_val = 1e-4\n",
    "batch_size_val = 2\n",
    "loss_fun_name = '4L' # 5L\n",
    "\n",
    "# dataset paths \n",
    "data_folder = '/net/lts2gdk0/mnt/scratch/lts2/nallapar/rb-prof/data/Jan_2024/Lina/processed/'\n",
    "\n",
    "# model name and output folder path\n",
    "model_name = 'XLNet-PLabelDH  Exp: exp1 [NL: 6, NH: 4, D: 512, LR: 0.0001, BS: 2, LF: 4L, Dr: 0.1, S: 2]' ## CHANGE to the model with the highest performance\n",
    "output_loc = 'saved_models/' + model_name \n",
    "\n",
    "condition_dict_values = {64: 'CTRL', 65: 'ILE', 66: 'LEU', 67: 'LEU_ILE', 68: 'LEU_ILE_VAL', 69: 'VAL'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class XLNetDH(XLNetForTokenClassification):\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "        self.classifier = torch.nn.Linear(d_model_val, 2, bias=True)\n",
    "\n",
    "config = XLNetConfig(vocab_size=71, pad_token_id=70, d_model = d_model_val, n_layer = n_layers_val, n_head = n_heads_val, d_inner = d_model_val, num_labels = 1, dropout=dropout_val) # 64*6 tokens + 1 for padding\n",
    "model = XLNetDH(config)\n",
    "\n",
    "# generate dataset\n",
    "test_dataset = pd.read_csv('../../data/orig/val_0.3_NZ_20_PercNan_0.05.csv')\n",
    "\n",
    "output_folder = 'val/'\n",
    "# # check files in the output folder\n",
    "files = os.listdir(output_folder)\n",
    "\n",
    "# dataset split into 64 parts, get start and stop of the part\n",
    "start = int(part * len(test_dataset) / tot_parts)\n",
    "stop = int((part + 1) * len(test_dataset) / tot_parts)\n",
    "\n",
    "# change start point depending on what files are already present\n",
    "for i in range(start, stop):\n",
    "    if 'sample_' + str(i) + '.npz' in files:\n",
    "        start = i\n",
    "    else:\n",
    "        break\n",
    "\n",
    "print(\"start: \", start)\n",
    "print(\"stop: \", stop)\n",
    "\n",
    "test_dataset = test_dataset[start:stop]\n",
    "\n",
    "# convert pandas dataframes into torch datasets\n",
    "test_dataset = GWSDatasetFromPandas(test_dataset)\n",
    "print(\"samples in test dataset: \", len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model from the saved model\n",
    "model = model.from_pretrained(output_loc + \"/best_model\")\n",
    "model.to(device)\n",
    "\n",
    "# set model to evaluation mode\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.autograd.set_detect_anomaly(True):\n",
    "    for i, (x_input, y_true_full, y_true_ctrl, gene, transcript) in tqdm(enumerate(test_dataset)):\n",
    "        x = torch.tensor(x_input)\n",
    "        # remove first token which is condition token\n",
    "        y = torch.tensor(y_true_full)\n",
    "\n",
    "        condition_token = condition_dict_values[int(x[0].item())]\n",
    "\n",
    "        # get LIG attributions\n",
    "        lig_sample_ctrl = lig_output(model, x, y, mode='ctrl')\n",
    "        lig_sample_dd = lig_output(model, x, y, mode='dd')\n",
    "\n",
    "        # get LXG attributions\n",
    "        lxg_sample_ctrl = lxg_output(model, x, y, mode='ctrl')\n",
    "        lxg_sample_dd = lxg_output(model, x, y, mode='dd')\n",
    "\n",
    "        x_input_dev = torch.unsqueeze(x_input, 0).to('cuda')\n",
    "        y_pred_full = model(x_input_dev).logits[0]\n",
    "        y_pred_ctrl = torch.relu(y_pred_full[1:, 0]).cpu().detach().numpy()\n",
    "        y_pred_depr_diff = y_pred_full[1:, 1].cpu().detach().numpy()\n",
    "\n",
    "        y_pred_full_sample = y_pred_ctrl + y_pred_depr_diff\n",
    "        y_true_dd_sample = y_true_full - y_true_ctrl\n",
    "\n",
    "        # make dict out of everything\n",
    "        out_dict = {\n",
    "            'x_input': x_input,\n",
    "            'y_true_full': y_true_full,\n",
    "            'y_pred_full': y_pred_full_sample,\n",
    "            'y_true_ctrl': y_true_ctrl,\n",
    "            'gene': gene,\n",
    "            'transcript': transcript,\n",
    "            'lig_ctrl': lig_sample_ctrl,\n",
    "            'lig_dd': lig_sample_dd,\n",
    "            'lxg_ctrl': lxg_sample_ctrl,\n",
    "            'lxg_dd': lxg_sample_dd,\n",
    "            'y_pred_ctrl': y_pred_ctrl,\n",
    "            'y_pred_depr_diff': y_pred_depr_diff,\n",
    "            'y_true_dd': y_true_dd_sample,\n",
    "            'condition': condition_token\n",
    "        }\n",
    "\n",
    "        # save dict\n",
    "        np.savez_compressed(output_folder + 'sample_' + str(start+i) + '.npz', out_dict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dlbind",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
