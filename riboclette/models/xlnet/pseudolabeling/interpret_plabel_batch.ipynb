{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from captum.attr import LayerIntegratedGradients, LayerGradientXActivation\n",
    "from transformers import XLNetConfig, XLNetForTokenClassification\n",
    "from xlnet_plabel_utils import GWSDatasetFromPandas  # custom dataset and trainer, CorrCoef, collate_fn, compute_metrics, compute_metrics_saved  # custom dataset and trainer\n",
    "import pytorch_lightning as pl\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "# suppress warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "part = 0\n",
    "tot_parts = 16\n",
    "gbs = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class model_CTRL(torch.nn.Module):\n",
    "    def __init__(self, model):\n",
    "        super().__init__()\n",
    "        self.model = model \n",
    "    \n",
    "    def forward(self, x, index_val):\n",
    "        # input dict\n",
    "        out_batch = {}\n",
    "\n",
    "        out_batch[\"input_ids\"] = x.unsqueeze(0)\n",
    "        for k, v in out_batch.items():\n",
    "            out_batch[k] = v.to(device)\n",
    "\n",
    "        out_batch[\"input_ids\"] = torch.tensor(out_batch[\"input_ids\"]).to(device).to(torch.int32)\n",
    "        out_batch[\"input_ids\"] = out_batch[\"input_ids\"].squeeze(0)\n",
    "        pred = self.model(out_batch[\"input_ids\"])\n",
    "\n",
    "        # get dim 0\n",
    "        pred_fin = torch.relu(pred[\"logits\"][:, :, 0])\n",
    "\n",
    "        # set output to be values in each examples at index_val\n",
    "        out_tensor = torch.zeros(len(index_val))\n",
    "        for el, val in enumerate(index_val):\n",
    "            out_tensor[el] = pred_fin[el][val]\n",
    "\n",
    "        return out_tensor\n",
    "    \n",
    "class model_DD(torch.nn.Module):\n",
    "    def __init__(self, model):\n",
    "        super().__init__()\n",
    "        self.model = model \n",
    "    \n",
    "    def forward(self, x, index_val):\n",
    "        # input dict\n",
    "        out_batch = {}\n",
    "\n",
    "        out_batch[\"input_ids\"] = x.unsqueeze(0)\n",
    "        for k, v in out_batch.items():\n",
    "            out_batch[k] = v.to(device)\n",
    "\n",
    "        out_batch[\"input_ids\"] = torch.tensor(out_batch[\"input_ids\"]).to(device).to(torch.int32)\n",
    "        out_batch[\"input_ids\"] = out_batch[\"input_ids\"].squeeze(0)\n",
    "        pred = self.model(out_batch[\"input_ids\"])\n",
    "\n",
    "        # get dim 1\n",
    "        pred_fin = pred[\"logits\"][:, :, 1]\n",
    "\n",
    "        # set output to be values in each examples at index_val\n",
    "        out_tensor = torch.zeros(len(index_val))\n",
    "        for el, val in enumerate(index_val):\n",
    "            out_tensor[el] = pred_fin[el][val]\n",
    "\n",
    "        return out_tensor\n",
    "\n",
    "def lig_output(model, x, y, mode='ctrl'):\n",
    "    if mode == 'ctrl':\n",
    "        model_fin = model_CTRL(model)\n",
    "    elif mode == 'dd':\n",
    "        model_fin = model_DD(model)\n",
    "        \n",
    "    lig = LayerIntegratedGradients(model_fin, model_fin.model.transformer.word_embedding)\n",
    "\n",
    "    # set torch graph to allow unused tensors\n",
    "    with torch.autograd.set_detect_anomaly(True):    \n",
    "        # get all indices\n",
    "        len_sample = len(x)\n",
    "        attributions_sample = np.zeros((len_sample, len_sample))\n",
    "\n",
    "        for j in tqdm(range(0, len_sample, gbs)):\n",
    "            index_val = list(range(j, min(j+gbs, len_sample)))\n",
    "\n",
    "            index_val = torch.tensor(index_val).to(device)\n",
    "\n",
    "            out_batch = {}\n",
    "\n",
    "            out_batch[\"input_ids\"] = x\n",
    "            \n",
    "            out_batch[\"input_ids\"] = torch.tensor(out_batch[\"input_ids\"]).to(device).to(torch.int32)\n",
    "\n",
    "            baseline_inp = torch.ones(out_batch[\"input_ids\"].shape) * 70 # 70 is the padding token\n",
    "            baseline_inp = baseline_inp.to(device).to(torch.int32)\n",
    "\n",
    "            # repeat the input and baseline tensors\n",
    "            out_batch[\"input_ids\"] = out_batch[\"input_ids\"].repeat(len(index_val), 1)\n",
    "            baseline_inp = baseline_inp.repeat(len(index_val), 1)\n",
    "\n",
    "            attributions = lig.attribute((out_batch[\"input_ids\"]), baselines=baseline_inp, \n",
    "                                                    method = 'gausslegendre', return_convergence_delta = False, additional_forward_args=index_val, n_steps=10, internal_batch_size=gbs)\n",
    "\n",
    "            attributions = torch.permute(attributions, (1, 0, 2))\n",
    "            attributions = torch.sum(attributions, dim=2)\n",
    "\n",
    "            # norm the attributions per example\n",
    "            for ex in range(attributions.shape[0]):\n",
    "                attributions[ex] = attributions[ex] / torch.norm(attributions[ex])\n",
    "            attributions = attributions.detach().cpu().numpy()\n",
    "            attributions_sample[j:j+len(index_val)] = attributions\n",
    "        \n",
    "        attributions_sample = np.array(attributions_sample)\n",
    "\n",
    "        # remove first column which is padding token\n",
    "        attributions_sample = attributions_sample[1:, 1:]\n",
    "\n",
    "        # flatten the attributions\n",
    "        attributions_sample = attributions_sample.flatten()\n",
    "\n",
    "    return attributions_sample\n",
    "\n",
    "def lxg_output(model, x, y, mode='ctrl'):\n",
    "    if mode == 'ctrl':\n",
    "        model_fin = model_CTRL(model)\n",
    "    elif mode == 'dd':\n",
    "        model_fin = model_DD(model)\n",
    "        \n",
    "    lxg = LayerGradientXActivation(model_fin, model_fin.model.transformer.word_embedding)\n",
    "\n",
    "    # set torch graph to allow unused tensors\n",
    "    with torch.autograd.set_detect_anomaly(True):\n",
    "        len_sample = len(x)\n",
    "        attributions_sample = np.zeros((len_sample, len_sample))\n",
    "\n",
    "        for j in tqdm(range(0, len_sample, gbs)):\n",
    "            index_val = list(range(j, min(j+gbs, len_sample)))\n",
    "\n",
    "            index_val = torch.tensor(index_val).to(device)\n",
    "\n",
    "            out_batch = {}\n",
    "\n",
    "            out_batch[\"input_ids\"] = x\n",
    "            \n",
    "            out_batch[\"input_ids\"] = torch.tensor(out_batch[\"input_ids\"]).to(device).to(torch.int32)\n",
    "\n",
    "            baseline_inp = torch.ones(out_batch[\"input_ids\"].shape) * 70 # 70 is the padding token\n",
    "            baseline_inp = baseline_inp.to(device).to(torch.int32)\n",
    "\n",
    "            # repeat the input and baseline tensors\n",
    "            out_batch[\"input_ids\"] = out_batch[\"input_ids\"].repeat(len(index_val), 1)\n",
    "            baseline_inp = baseline_inp.repeat(len(index_val), 1)\n",
    "\n",
    "            attributions = lxg.attribute((out_batch[\"input_ids\"]), additional_forward_args=index_val)\n",
    "            \n",
    "            attributions = torch.permute(attributions, (1, 0, 2))\n",
    "            attributions = torch.sum(attributions, dim=2)\n",
    "\n",
    "            # norm the attributions per example\n",
    "            for ex in range(attributions.shape[0]):\n",
    "                attributions[ex] = attributions[ex] / torch.norm(attributions[ex])\n",
    "            attributions = attributions.detach().cpu().numpy()\n",
    "            attributions_sample[j:j+len(index_val)] = attributions\n",
    "        \n",
    "        attributions_sample = np.array(attributions_sample)\n",
    "\n",
    "        # remove first column which is padding token\n",
    "        attributions_sample = attributions_sample[1:, 1:]\n",
    "\n",
    "        # flatten the attributions\n",
    "        attributions_sample = attributions_sample.flatten()\n",
    "\n",
    "    return attributions_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reproducibility\n",
    "seed_val = 2\n",
    "pl.seed_everything(seed_val) \n",
    "\n",
    "# add argument for part\n",
    "print(\"part: \", part)\n",
    "\n",
    "# model parameters\n",
    "annot_thresh = 0.3\n",
    "longZerosThresh_val = 20\n",
    "percNansThresh_val = 0.05\n",
    "d_model_val = 512\n",
    "n_layers_val = 6\n",
    "n_heads_val = 4\n",
    "dropout_val = 0.1\n",
    "lr_val = 1e-4\n",
    "batch_size_val = 2\n",
    "loss_fun_name = '4L' # 5L\n",
    "\n",
    "# dataset paths \n",
    "data_folder = '/net/lts2gdk0/mnt/scratch/lts2/nallapar/rb-prof/data/Jan_2024/Lina/processed/'\n",
    "\n",
    "# model name and output folder path\n",
    "model_name = 'XLNet-PLabelDH  Exp: exp1 [NL: 6, NH: 4, D: 512, LR: 0.0001, BS: 2, LF: 4L, Dr: 0.1, S: 2]' ## CHANGE to the model with the highest performance\n",
    "output_loc = 'saved_models/' + model_name \n",
    "\n",
    "condition_dict_values = {64: 'CTRL', 65: 'ILE', 66: 'LEU', 67: 'LEU_ILE', 68: 'LEU_ILE_VAL', 69: 'VAL'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class XLNetDH(XLNetForTokenClassification):\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "        self.classifier = torch.nn.Linear(d_model_val, 2, bias=True)\n",
    "\n",
    "config = XLNetConfig(vocab_size=71, pad_token_id=70, d_model = d_model_val, n_layer = n_layers_val, n_head = n_heads_val, d_inner = d_model_val, num_labels = 1, dropout=dropout_val) # 64*6 tokens + 1 for padding\n",
    "model = XLNetDH(config)\n",
    "\n",
    "# generate dataset\n",
    "test_dataset = pd.read_csv('data/orig/val_0.3_NZ_20_PercNan_0.05.csv')\n",
    "num_samples = len(test_dataset)\n",
    "\n",
    "output_folder = 'all_interpret_orig_val/'\n",
    "\n",
    "# # check files in the output folder\n",
    "files = os.listdir(output_folder)\n",
    "\n",
    "# find the indices of the files in the part of the dataset that are not present\n",
    "\n",
    "# get start and stop of the part\n",
    "# full_indices = [2986, 2987, 2988, 2989, 2990, 2991, 2992, 2993, 2994, 2995, 2996, 2997, 2998, 2999, 3000, 3001, 3002, 3003, 3004, 3005, 3006, 3007, 3008, 3009, 3010, 3011, 3012, 3013, 3014, 3015, 3016, 3017, 3018, 3019, 3020, 3021, 3022, 3023, 3024, 3025, 3026, 3027, 3028, 3029, 3030, 3031, 3032, 3033, 3034, 3035, 3036, 3037, 3038, 3039, 3040, 3041, 3042, 3043, 3044, 3045, 3046, 3047, 3048, 3049, 3050, 3051, 3052, 3053, 3054, 3055, 3056, 3057, 3058, 3059, 3060, 3061, 3062, 3063, 3064, 3065, 3066, 3067, 3068, 3069, 3070, 3071, 3072, 3073, 3074, 3075, 3076, 3077, 3078, 3079, 3080, 3081, 3082, 3083, 3084, 3085, 3086, 3087, 3088, 3089, 3090, 3091, 3092, 3093, 3094, 3095, 3096, 3097, 3098, 3099, 3100, 3101, 3102, 3103, 3104, 3105, 3106, 3107, 3108, 3109, 3110, 3111, 3112, 3113, 3114, 3115, 3116, 3117, 3118, 3119, 3120, 3121, 3122, 3123, 3124, 3125, 3126, 3127, 3128, 3129, 3130, 3131, 3132, 3133, 3134, 3135, 3136, 3137, 3138, 3139, 3140, 3141, 3142, 3143, 3144, 3145, 3146, 3147, 3148, 3149, 3150, 3151, 3152, 3153, 3154, 3155, 3156, 3157, 3158, 3159, 3160, 3161, 3162, 3163, 8371, 8372, 8373, 8374, 8375, 8376, 8377, 8378, 8379, 8380, 8381, 8382, 8383, 8384, 8385, 8386, 8387, 8388, 8389, 8390, 8391, 8392, 8393, 8394, 8395, 8396, 8397, 8398, 8399, 8400, 8401, 8402, 8403, 8404, 8405, 8406, 8407, 8408, 8409, 8410, 8411, 8412, 8413, 8414, 8415, 8416, 8417, 8418, 8419, 8420, 8421, 8422, 8423, 8424, 8425, 8426, 8427, 8428, 8429, 8430, 8431, 8432, 8433, 8434, 8435, 8436, 8437, 8438, 10529, 10530, 10531, 10532, 10533, 10534, 10535, 10536, 10537, 10538, 10539, 10540, 10541, 10542, 10543, 10544, 10545, 10546, 10547, 10548, 14712, 14713, 14714, 14715, 14716, 14717, 14718, 14719, 14720, 14721, 14722, 14723, 14724, 14725, 14726, 14727, 14728, 14729, 14730, 14731, 14732, 14733, 14734, 14735, 14736, 14737, 14738, 14739, 14740, 14741, 14742, 14743, 14744, 14745, 14746, 14747, 14748, 14749, 14750, 14751, 14752, 14753, 14754, 14755, 14756, 14757, 14758, 14759, 14760, 14761, 14762, 14763, 14764, 14765, 14766, 14767, 14768, 16870, 16871, 16872, 16873, 16874, 16875, 16876, 16877, 16878]\n",
    "\n",
    "# start = int(part * len(full_indices) / tot_parts)\n",
    "# stop = int((part + 1) * len(full_indices) / tot_parts)\n",
    "\n",
    "# print(\"Number of samples to interpret: \", stop - start + 1)\n",
    "\n",
    "# indices = full_indices[start:stop]\n",
    "\n",
    "# test_dataset = test_dataset.iloc[indices]\n",
    "\n",
    "# # dataset split into 64 parts, get start and stop of the part\n",
    "start = int(part * len(test_dataset) / tot_parts)\n",
    "stop = int((part + 1) * len(test_dataset) / tot_parts)\n",
    "\n",
    "# change start point depending on what files are already present\n",
    "for i in range(start, stop):\n",
    "    if 'sample_' + str(i) + '.npz' in files:\n",
    "        start = i\n",
    "    else:\n",
    "        break\n",
    "\n",
    "print(\"start: \", start)\n",
    "print(\"stop: \", stop)\n",
    "\n",
    "test_dataset = test_dataset[start:stop]\n",
    "\n",
    "# convert pandas dataframes into torch datasets\n",
    "test_dataset = GWSDatasetFromPandas(test_dataset)\n",
    "print(\"samples in test dataset: \", len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model from the saved model\n",
    "model = model.from_pretrained(output_loc + \"/best_model\")\n",
    "model.to(device)\n",
    "\n",
    "# set model to evaluation mode\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count = 0\n",
    "with torch.autograd.set_detect_anomaly(True):\n",
    "    for i, (x_input, y_true_full, y_true_ctrl, gene, transcript) in tqdm(enumerate(test_dataset)):\n",
    "        x = torch.tensor(x_input)\n",
    "        # remove first token which is condition token\n",
    "        y = torch.tensor(y_true_full)\n",
    "\n",
    "        condition_token = condition_dict_values[int(x[0].item())]\n",
    "\n",
    "        # get LIG attributions\n",
    "        lig_sample_ctrl = lig_output(model, x, y, mode='ctrl')\n",
    "        lig_sample_dd = lig_output(model, x, y, mode='dd')\n",
    "\n",
    "        # # get LXG attributions\n",
    "        lxg_sample_ctrl = lxg_output(model, x, y, mode='ctrl')\n",
    "        lxg_sample_dd = lxg_output(model, x, y, mode='dd')\n",
    "\n",
    "        x_input_dev = torch.unsqueeze(x_input, 0).to('cuda')\n",
    "        y_pred_full = model(x_input_dev).logits[0]\n",
    "        y_pred_ctrl = torch.relu(y_pred_full[1:, 0]).cpu().detach().numpy()\n",
    "        y_pred_depr_diff = y_pred_full[1:, 1].cpu().detach().numpy()\n",
    "\n",
    "        y_pred_full_sample = y_pred_ctrl + y_pred_depr_diff\n",
    "        y_true_dd_sample = y_true_full - y_true_ctrl\n",
    "\n",
    "        # make dict out of everything\n",
    "        out_dict = {\n",
    "            'x_input': x_input,\n",
    "            'y_true_full': y_true_full,\n",
    "            'y_pred_full': y_pred_full_sample,\n",
    "            'y_true_ctrl': y_true_ctrl,\n",
    "            'gene': gene,\n",
    "            'transcript': transcript,\n",
    "            'lig_ctrl': lig_sample_ctrl,\n",
    "            'lig_dd': lig_sample_dd,\n",
    "            'lxg_ctrl': lxg_sample_ctrl,\n",
    "            'lxg_dd': lxg_sample_dd,\n",
    "            'y_pred_ctrl': y_pred_ctrl,\n",
    "            'y_pred_depr_diff': y_pred_depr_diff,\n",
    "            'y_true_dd': y_true_dd_sample,\n",
    "            'condition': condition_token\n",
    "        }\n",
    "\n",
    "        # save dict\n",
    "        # out_num = indices[count]\n",
    "        np.savez_compressed(output_folder + 'sample_' + str(start+i) + '.npz', out_dict)\n",
    "        # count += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "riboclette",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
