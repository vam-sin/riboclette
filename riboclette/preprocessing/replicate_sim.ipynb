{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# libraries\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from Bio import SeqIO\n",
    "from tqdm.auto import tqdm\n",
    "import pickle as pkl\n",
    "import itertools\n",
    "from scipy.stats import pearsonr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# id to codon and codon to id\n",
    "id_to_codon = {idx:''.join(el) for idx, el in enumerate(itertools.product(['A', 'T', 'C', 'G'], repeat=3))}\n",
    "codon_to_id = {v:k for k,v in id_to_codon.items()}\n",
    "\n",
    "def make_dataframe(\n",
    "    ribo_fpath: str, df_trans_to_seq, count_norm: str = \"mean\"\n",
    "):\n",
    "    ribo_fname = ribo_fpath.split(\"/\")[-1].split(\".\")[0]\n",
    "\n",
    "    # Import dataset with ribosome data\n",
    "    df_ribo = pd.read_csv(\n",
    "        ribo_fpath,\n",
    "        sep=\" \",\n",
    "        on_bad_lines=\"warn\",\n",
    "        dtype=dict(gene=\"category\", transcript=\"category\"),\n",
    "    ).rename(columns={\"count\": \"counts\"})\n",
    "\n",
    "    # Define count normalization function\n",
    "    if count_norm == \"max\":\n",
    "        f_norm = lambda x: x / x.max()\n",
    "    elif count_norm == \"mean\":\n",
    "        f_norm = lambda x: x / x.mean()\n",
    "    elif count_norm == \"sum\":\n",
    "        f_norm = lambda x: x / x.sum()\n",
    "    else:\n",
    "        raise ValueError()\n",
    "\n",
    "    # Create final dataframe\n",
    "    final_df = (\n",
    "        df_ribo.merge(df_trans_to_seq).assign(fname=ribo_fname)\n",
    "        # Filter spurious positions at the end of the sequence\n",
    "        .query(\"position_A_site <= n_codons * 3\")\n",
    "        # Compute normalized counts\n",
    "        .assign(\n",
    "            norm_counts=lambda df: df.groupby(\"gene\", observed=True).counts.transform(\n",
    "                f_norm\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "\n",
    "    return final_df\n",
    "\n",
    "\n",
    "def make_all_dataframes(\n",
    "    fasta_path: str,\n",
    "    rb_path: str,\n",
    "    max_n_codons: int = 2000,\n",
    "    count_norm: str = \"mean\",\n",
    "):\n",
    "    # Import FASTA\n",
    "    data = []\n",
    "    with open(fasta_path, mode=\"r\") as handle:\n",
    "        for record in SeqIO.parse(handle, \"fasta\"):\n",
    "            data.append([record.id, str(record.seq)])\n",
    "\n",
    "    # Create transcripts to sequences mapping\n",
    "\n",
    "    df_trans_to_seq = pd.DataFrame(data, columns=[\"transcript\", \"sequence\"])\n",
    "\n",
    "    # Removes those sequences that have Ns\n",
    "    sequence_has_n = df_trans_to_seq.sequence.str.contains(\"N\", regex=False)\n",
    "    df_trans_to_seq = df_trans_to_seq.loc[~sequence_has_n]\n",
    "\n",
    "    # Number of codons in sequence\n",
    "    df_trans_to_seq = df_trans_to_seq.assign(\n",
    "        n_codons=lambda df: df.sequence.str.len() // 3\n",
    "    )\n",
    "\n",
    "    # Compute and merge dataframes\n",
    "    dfs = [\n",
    "        make_dataframe(\n",
    "            ribo_fpath = rb_path,\n",
    "            df_trans_to_seq=df_trans_to_seq.drop(\"sequence\", axis=1),\n",
    "            count_norm=count_norm,\n",
    "        )\n",
    "    ]\n",
    "    dfs = pd.concat(dfs)\n",
    "    for col in [\"transcript\", \"gene\", \"fname\"]:\n",
    "        dfs[col] = dfs[col].astype(\"category\")\n",
    "\n",
    "    dfs = dfs.groupby([\"transcript\", \"position_A_site\"], observed=True)\n",
    "\n",
    "    # Average replicates\n",
    "    dfs = dfs.agg(dict(norm_counts=\"mean\", gene=\"first\")).reset_index()\n",
    "    \n",
    "    dfs = dfs.assign(codon_idx=lambda df: df.position_A_site // 3)\n",
    "    dfs = dfs.groupby(\"transcript\", observed=True)\n",
    "    dfs = dfs.agg(\n",
    "        {\n",
    "            \"norm_counts\": lambda x: x.tolist(),\n",
    "            \"codon_idx\": lambda x: x.tolist(),\n",
    "            \"gene\": \"first\",\n",
    "        }\n",
    "    ).reset_index()\n",
    "    dfs = dfs.merge(df_trans_to_seq)\n",
    "\n",
    "    dfs = dfs.assign(\n",
    "        n_annot=lambda df: df.norm_counts.transform(lambda x: len(x))\n",
    "        / (df.sequence.str.len() // 3)\n",
    "    )\n",
    "\n",
    "    dfs = dfs.assign(perc_annot=lambda df: df.n_annot / df.n_codons)\n",
    "\n",
    "    # Filter by max sequence lenght\n",
    "    dfs = dfs.query(\"n_codons<@max_n_codons\")\n",
    "\n",
    "    return dfs\n",
    "\n",
    "# def fucntion sequence to codon ids\n",
    "def sequence2codonids(seq):\n",
    "    codon_ids = []\n",
    "    for i in range(0, len(seq), 3):\n",
    "        codon = seq[i:i+3]\n",
    "        if len(codon) == 3:\n",
    "            codon_ids.append(codon_to_id[codon])\n",
    "\n",
    "    return codon_ids\n",
    "\n",
    "def process_merged_df(df):\n",
    "    # remove transcripts with N in sequence\n",
    "    df = df[df['sequence'].str.contains('N') == False]\n",
    "\n",
    "    codon_seqs = []\n",
    "    sequences = list(df['sequence'])\n",
    "    genes = list(df['gene'])\n",
    "    transcripts = list(df['transcript'])\n",
    "    perc_non_zero_annots = []\n",
    "    norm_counts = list(df['norm_counts'])\n",
    "    codon_idx = list(df[\"codon_idx\"])\n",
    "    annot_seqs = []\n",
    "\n",
    "    for i in range(len(sequences)):\n",
    "        seq = sequences[i]\n",
    "        seq = sequence2codonids(seq)\n",
    "        codon_seqs.append(seq)\n",
    "        codon_idx_sample = codon_idx[i]\n",
    "        # convert to list of int\n",
    "        codon_idx_sample = [int(i) for i in codon_idx_sample[1:-1].split(',')]\n",
    "        annot_seq_sample = []\n",
    "        norm_counts_sample = [float(i) for i in norm_counts[i][1:-1].split(',')]\n",
    "        for j in range(len(seq)):\n",
    "            if j in codon_idx_sample:\n",
    "                annot_seq_sample.append(norm_counts_sample[codon_idx_sample.index(j)])\n",
    "            else:\n",
    "                annot_seq_sample.append(0.0)\n",
    "        annot_seqs.append(annot_seq_sample)\n",
    "\n",
    "        # calculate percentage of non-zero annotations\n",
    "        perc_non_zero_annots.append(sum([1 for i in annot_seq_sample if i != 0.0])/len(annot_seq_sample))\n",
    "\n",
    "    final_df = pd.DataFrame(list(zip(genes, transcripts, codon_seqs, annot_seqs, perc_non_zero_annots)), columns = ['gene', 'transcript', 'codon_sequence', 'annotations', 'perc_non_zero_annots'])\n",
    "\n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FOLDER = '/net/lts2gdk0/mnt/scratch/lts2/nallapar/rb-prof/data/Jan_2024/Lina/'\n",
    "LIVER_FOLDER = '/net/lts2gdk0/mnt/scratch/lts2/nallapar/rb-prof/data/Jan_2024/Liver/'\n",
    "# merge the dataframes\n",
    "fa_path = f'{DATA_FOLDER}/reference/ensembl.cds.fa'\n",
    "\n",
    "test_data_path = '/nfs_home/nallapar/final/riboclette/riboclette/models/data/orig/test_0.3_NZ_20_PercNan_0.05.csv'\n",
    "out_folder = '/net/lts2gdk0/mnt/scratch/lts2/nallapar/rb-prof/data/Jan_2024/cleaned_data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv(test_data_path)\n",
    "genes_test_full = list(test_data['gene'])\n",
    "transcripts_test_full = list(test_data['transcript'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def annot_PCC_sim(x, y):\n",
    "    x = np.array(x)\n",
    "    y = np.array(y)\n",
    "    # print(len(x), len(y))\n",
    "\n",
    "    # print(x, y)\n",
    "\n",
    "    nan_mask_x = np.isnan(x)\n",
    "    nan_mask_y = np.isnan(y)\n",
    "    nan_mask = np.logical_or(nan_mask_x, nan_mask_y)\n",
    "    x = x[~nan_mask]\n",
    "    y = y[~nan_mask]\n",
    "\n",
    "    # print(x, y)\n",
    "    if len(x) == 0:\n",
    "        return np.nan\n",
    "    else:\n",
    "        return pearsonr(x, y)[0]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conditions = ['CTRL', 'LEU', 'ILE', 'VAL', 'LEU_ILE', 'LEU_ILE_VAL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for condition in conditions:\n",
    "    # for each gene in the CTRL data, check how similar the replicate annotations are\n",
    "    # get the gene names\n",
    "    print(\"Condition: \", condition)\n",
    "    ctrl_files = os.listdir(out_folder + condition + '/')\n",
    "    num_reps = len(ctrl_files)\n",
    "    ctrl_genes = []\n",
    "    ctrl_dfs = []\n",
    "\n",
    "    for i in range(len(ctrl_files)):\n",
    "        ctrl_df = pd.read_csv(out_folder + condition + '/' + ctrl_files[i])\n",
    "        ctrl_df = ctrl_df[ctrl_df['gene'].isin(genes_test_full)]\n",
    "        ctrl_df = ctrl_df[ctrl_df['transcript'].isin(transcripts_test_full)]\n",
    "\n",
    "        ctrl_dfs.append(ctrl_df)\n",
    "        ctrl_genes.extend(list(ctrl_df['transcript']))\n",
    "\n",
    "    ctrl_genes = list(set(ctrl_genes))\n",
    "\n",
    "    # permutations in which replicates can be split into 2 groups\n",
    "    if num_reps > 5:\n",
    "        # get 5 random perms from the list, dont calculate the full perms\n",
    "        # generate 5 random permutations manually\n",
    "        perms = []\n",
    "        for i in range(5):\n",
    "            perm = np.random.permutation(num_reps)\n",
    "            perms.append(perm[:num_reps//2])\n",
    "    else:      \n",
    "        perms = list(itertools.combinations(range(num_reps), num_reps//2))\n",
    "\n",
    "    group1_full = []\n",
    "    group2_full = []\n",
    "\n",
    "    if len(perms) >= 5:\n",
    "        num_splits = 5\n",
    "        # get 5 random perms from the list\n",
    "        for i in range(num_splits):\n",
    "            group1_full.append([j for j in perms[i]])\n",
    "            group2_full.append([j for j in range(num_reps) if j not in perms[i]])\n",
    "    else:\n",
    "        num_splits = len(perms)\n",
    "        for i in range(len(perms)):\n",
    "            group1_full.append([j for j in perms[i]])\n",
    "            group2_full.append([j for j in range(num_reps) if j not in perms[i]])\n",
    "\n",
    "    print(\"Split Groups\")\n",
    "\n",
    "    print(group1_full)\n",
    "    print(group2_full)\n",
    "\n",
    "    # get the gene annotations for each gene\n",
    "    # split replicates into 2 groups randomly\n",
    "    split_pcc = []\n",
    "    for k in range(num_splits):\n",
    "        group1 = group1_full[k]\n",
    "        group2 = group2_full[k]\n",
    "\n",
    "        gene_annotations = {}\n",
    "        for i in range(len(ctrl_genes)):\n",
    "            gene = ctrl_genes[i]\n",
    "            gene_annotations[gene] = []\n",
    "            num_codons = 0\n",
    "            for j in range(len(ctrl_files)):\n",
    "                if gene in list(ctrl_dfs[j]['transcript']):\n",
    "                    gene_df = ctrl_dfs[j][ctrl_dfs[j]['transcript'] == gene]\n",
    "                    gene_annotations[gene].append([float(x) for x in gene_df['annotations'].values[0][1:-1].split(',')])\n",
    "                    num_codons = len(gene_df['annotations'].values[0][1:-1].split(','))\n",
    "                    break\n",
    "            for j in range(len(ctrl_files)):\n",
    "                gene_df = ctrl_dfs[j][ctrl_dfs[j]['transcript'] == gene]\n",
    "                try:\n",
    "                    gene_annotations[gene].append([float(x) for x in gene_df['annotations'].values[0][1:-1].split(',')])\n",
    "                except:\n",
    "                    gene_annotations[gene].append([np.nan for i in range(num_codons)])\n",
    "            gene_annotations[gene] = [np.nanmean(np.array(gene_annotations[gene])[group1], axis = 0), np.nanmean(np.array(gene_annotations[gene])[group2], axis = 0)]\n",
    "\n",
    "        # calculate the pairwise pearson correlation between the annotations and choose the least value\n",
    "        gene_PCC = {}\n",
    "        for i in range(len(ctrl_genes)):\n",
    "            gene = ctrl_genes[i]\n",
    "            gene_annotations_sample = gene_annotations[gene]\n",
    "            # print(gene_annotations_sample)\n",
    "            gene_PCC[gene] = annot_PCC_sim(gene_annotations_sample[0], gene_annotations_sample[1])\n",
    "        \n",
    "        # get the average of the gene PCC values\n",
    "        # convert gene_PCC to df\n",
    "        df = pd.DataFrame.from_dict(gene_PCC, orient = 'index', columns = ['PCC'])\n",
    "        df.to_csv(\"df_reps_sims/\" + condition + '_split_' + str(k) + '_gene_PCC.csv')\n",
    "        gene_PCC_values_ctrl = list(gene_PCC.values())\n",
    "        gene_PCC_avg_ctrl = np.nanmean(gene_PCC_values_ctrl)\n",
    "\n",
    "        split_pcc.append(gene_PCC_avg_ctrl)\n",
    "\n",
    "        print(\"Split \" + str(k) + \" gene PCC average: \", gene_PCC_avg_ctrl)\n",
    "\n",
    "    print(condition + \" final split PCC average: \", np.mean(split_pcc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test instances only\n",
    "# LEU_ILE_VAL final split PCC average:  0.9170877492072175\n",
    "# LEU_ILE final split PCC average:  0.924799669884757\n",
    "# VAL final split PCC average:  0.9239766993445738\n",
    "# ILE final split PCC average:  0.8620134134078624\n",
    "# LEU final split PCC average:  0.9322250754557618\n",
    "# CTRL final split PCC average:  0.9770054420545804"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LEU_ILE_VAL final split PCC average:  0.7500969373121209\n",
    "# VAL final split PCC average:  0.7611953402793622\n",
    "# ILE final split PCC average:  0.7049178068697376\n",
    "# LEU final split PCC average:  0.7758710738503477\n",
    "# LEU_ILE final split PCC average:  0.7666773313577476\n",
    "# CTRL final split PCC average:  0.8370606904527795"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
