{
  "best_metric": 1.028967022895813,
  "best_model_checkpoint": "saved_models/XLNetDepr-3_256_8-ALL_NA-PEL-BS1-GWS_PCC_IT192_DH_3L_NZ20_PNTh0.05_AnnotThresh0.5/checkpoint-325686",
  "epoch": 197.0,
  "global_step": 1258042,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.08,
      "learning_rate": 9.99608518634513e-05,
      "loss": 2.3394,
      "step": 500
    },
    {
      "epoch": 0.16,
      "learning_rate": 9.99217037269026e-05,
      "loss": 2.08,
      "step": 1000
    },
    {
      "epoch": 0.23,
      "learning_rate": 9.98825555903539e-05,
      "loss": 2.0102,
      "step": 1500
    },
    {
      "epoch": 0.31,
      "learning_rate": 9.98434074538052e-05,
      "loss": 1.9819,
      "step": 2000
    },
    {
      "epoch": 0.39,
      "learning_rate": 9.980425931725649e-05,
      "loss": 1.8502,
      "step": 2500
    },
    {
      "epoch": 0.47,
      "learning_rate": 9.97651111807078e-05,
      "loss": 1.7074,
      "step": 3000
    },
    {
      "epoch": 0.55,
      "learning_rate": 9.972596304415909e-05,
      "loss": 1.6659,
      "step": 3500
    },
    {
      "epoch": 0.63,
      "learning_rate": 9.96868149076104e-05,
      "loss": 1.5958,
      "step": 4000
    },
    {
      "epoch": 0.7,
      "learning_rate": 9.964766677106169e-05,
      "loss": 1.5995,
      "step": 4500
    },
    {
      "epoch": 0.78,
      "learning_rate": 9.960851863451301e-05,
      "loss": 1.6036,
      "step": 5000
    },
    {
      "epoch": 0.86,
      "learning_rate": 9.95693704979643e-05,
      "loss": 1.5577,
      "step": 5500
    },
    {
      "epoch": 0.94,
      "learning_rate": 9.953022236141561e-05,
      "loss": 1.5291,
      "step": 6000
    },
    {
      "epoch": 1.0,
      "eval_loss": 1.3462711572647095,
      "eval_r": 0.4627210199832916,
      "eval_runtime": 29.3559,
      "eval_samples_per_second": 54.231,
      "eval_steps_per_second": 54.231,
      "step": 6386
    },
    {
      "epoch": 1.02,
      "learning_rate": 9.94910742248669e-05,
      "loss": 1.4879,
      "step": 6500
    },
    {
      "epoch": 1.1,
      "learning_rate": 9.945192608831821e-05,
      "loss": 1.4735,
      "step": 7000
    },
    {
      "epoch": 1.17,
      "learning_rate": 9.94127779517695e-05,
      "loss": 1.4454,
      "step": 7500
    },
    {
      "epoch": 1.25,
      "learning_rate": 9.937362981522081e-05,
      "loss": 1.4337,
      "step": 8000
    },
    {
      "epoch": 1.33,
      "learning_rate": 9.93344816786721e-05,
      "loss": 1.446,
      "step": 8500
    },
    {
      "epoch": 1.41,
      "learning_rate": 9.929533354212341e-05,
      "loss": 1.4331,
      "step": 9000
    },
    {
      "epoch": 1.49,
      "learning_rate": 9.92561854055747e-05,
      "loss": 1.4131,
      "step": 9500
    },
    {
      "epoch": 1.57,
      "learning_rate": 9.921703726902601e-05,
      "loss": 1.4099,
      "step": 10000
    },
    {
      "epoch": 1.64,
      "learning_rate": 9.91778891324773e-05,
      "loss": 1.3929,
      "step": 10500
    },
    {
      "epoch": 1.72,
      "learning_rate": 9.913874099592861e-05,
      "loss": 1.3682,
      "step": 11000
    },
    {
      "epoch": 1.8,
      "learning_rate": 9.90995928593799e-05,
      "loss": 1.3789,
      "step": 11500
    },
    {
      "epoch": 1.88,
      "learning_rate": 9.90604447228312e-05,
      "loss": 1.368,
      "step": 12000
    },
    {
      "epoch": 1.96,
      "learning_rate": 9.90212965862825e-05,
      "loss": 1.3816,
      "step": 12500
    },
    {
      "epoch": 2.0,
      "eval_loss": 1.2306777238845825,
      "eval_r": 0.5235552191734314,
      "eval_runtime": 27.7992,
      "eval_samples_per_second": 57.268,
      "eval_steps_per_second": 57.268,
      "step": 12772
    },
    {
      "epoch": 2.04,
      "learning_rate": 9.89821484497338e-05,
      "loss": 1.3655,
      "step": 13000
    },
    {
      "epoch": 2.11,
      "learning_rate": 9.89430003131851e-05,
      "loss": 1.3604,
      "step": 13500
    },
    {
      "epoch": 2.19,
      "learning_rate": 9.89038521766364e-05,
      "loss": 1.3281,
      "step": 14000
    },
    {
      "epoch": 2.27,
      "learning_rate": 9.88647040400877e-05,
      "loss": 1.3459,
      "step": 14500
    },
    {
      "epoch": 2.35,
      "learning_rate": 9.8825555903539e-05,
      "loss": 1.3237,
      "step": 15000
    },
    {
      "epoch": 2.43,
      "learning_rate": 9.87864077669903e-05,
      "loss": 1.3451,
      "step": 15500
    },
    {
      "epoch": 2.51,
      "learning_rate": 9.874725963044158e-05,
      "loss": 1.3316,
      "step": 16000
    },
    {
      "epoch": 2.58,
      "learning_rate": 9.87081114938929e-05,
      "loss": 1.3214,
      "step": 16500
    },
    {
      "epoch": 2.66,
      "learning_rate": 9.866896335734419e-05,
      "loss": 1.3408,
      "step": 17000
    },
    {
      "epoch": 2.74,
      "learning_rate": 9.86298152207955e-05,
      "loss": 1.3141,
      "step": 17500
    },
    {
      "epoch": 2.82,
      "learning_rate": 9.859066708424679e-05,
      "loss": 1.3291,
      "step": 18000
    },
    {
      "epoch": 2.9,
      "learning_rate": 9.85515189476981e-05,
      "loss": 1.3187,
      "step": 18500
    },
    {
      "epoch": 2.98,
      "learning_rate": 9.851237081114939e-05,
      "loss": 1.2996,
      "step": 19000
    },
    {
      "epoch": 3.0,
      "eval_loss": 1.1840418577194214,
      "eval_r": 0.5474006533622742,
      "eval_runtime": 28.0925,
      "eval_samples_per_second": 56.67,
      "eval_steps_per_second": 56.67,
      "step": 19158
    },
    {
      "epoch": 3.05,
      "learning_rate": 9.84732226746007e-05,
      "loss": 1.3156,
      "step": 19500
    },
    {
      "epoch": 3.13,
      "learning_rate": 9.843407453805199e-05,
      "loss": 1.293,
      "step": 20000
    },
    {
      "epoch": 3.21,
      "learning_rate": 9.83949264015033e-05,
      "loss": 1.2976,
      "step": 20500
    },
    {
      "epoch": 3.29,
      "learning_rate": 9.835577826495459e-05,
      "loss": 1.3007,
      "step": 21000
    },
    {
      "epoch": 3.37,
      "learning_rate": 9.83166301284059e-05,
      "loss": 1.2816,
      "step": 21500
    },
    {
      "epoch": 3.45,
      "learning_rate": 9.827748199185719e-05,
      "loss": 1.28,
      "step": 22000
    },
    {
      "epoch": 3.52,
      "learning_rate": 9.82383338553085e-05,
      "loss": 1.2863,
      "step": 22500
    },
    {
      "epoch": 3.6,
      "learning_rate": 9.819918571875979e-05,
      "loss": 1.2915,
      "step": 23000
    },
    {
      "epoch": 3.68,
      "learning_rate": 9.81600375822111e-05,
      "loss": 1.2999,
      "step": 23500
    },
    {
      "epoch": 3.76,
      "learning_rate": 9.812088944566239e-05,
      "loss": 1.2863,
      "step": 24000
    },
    {
      "epoch": 3.84,
      "learning_rate": 9.808174130911369e-05,
      "loss": 1.2687,
      "step": 24500
    },
    {
      "epoch": 3.91,
      "learning_rate": 9.804259317256499e-05,
      "loss": 1.3035,
      "step": 25000
    },
    {
      "epoch": 3.99,
      "learning_rate": 9.800344503601629e-05,
      "loss": 1.2822,
      "step": 25500
    },
    {
      "epoch": 4.0,
      "eval_loss": 1.156773567199707,
      "eval_r": 0.5581056475639343,
      "eval_runtime": 28.1361,
      "eval_samples_per_second": 56.582,
      "eval_steps_per_second": 56.582,
      "step": 25544
    },
    {
      "epoch": 4.07,
      "learning_rate": 9.796429689946759e-05,
      "loss": 1.2744,
      "step": 26000
    },
    {
      "epoch": 4.15,
      "learning_rate": 9.792514876291889e-05,
      "loss": 1.2835,
      "step": 26500
    },
    {
      "epoch": 4.23,
      "learning_rate": 9.788600062637019e-05,
      "loss": 1.2678,
      "step": 27000
    },
    {
      "epoch": 4.31,
      "learning_rate": 9.784685248982149e-05,
      "loss": 1.2758,
      "step": 27500
    },
    {
      "epoch": 4.38,
      "learning_rate": 9.780770435327279e-05,
      "loss": 1.266,
      "step": 28000
    },
    {
      "epoch": 4.46,
      "learning_rate": 9.776855621672408e-05,
      "loss": 1.2603,
      "step": 28500
    },
    {
      "epoch": 4.54,
      "learning_rate": 9.772940808017539e-05,
      "loss": 1.2654,
      "step": 29000
    },
    {
      "epoch": 4.62,
      "learning_rate": 9.769025994362668e-05,
      "loss": 1.2648,
      "step": 29500
    },
    {
      "epoch": 4.7,
      "learning_rate": 9.765111180707799e-05,
      "loss": 1.2656,
      "step": 30000
    },
    {
      "epoch": 4.78,
      "learning_rate": 9.761196367052928e-05,
      "loss": 1.262,
      "step": 30500
    },
    {
      "epoch": 4.85,
      "learning_rate": 9.757281553398059e-05,
      "loss": 1.2585,
      "step": 31000
    },
    {
      "epoch": 4.93,
      "learning_rate": 9.753366739743188e-05,
      "loss": 1.2587,
      "step": 31500
    },
    {
      "epoch": 5.0,
      "eval_loss": 1.1357614994049072,
      "eval_r": 0.5676077008247375,
      "eval_runtime": 27.6058,
      "eval_samples_per_second": 57.669,
      "eval_steps_per_second": 57.669,
      "step": 31930
    },
    {
      "epoch": 5.01,
      "learning_rate": 9.749451926088319e-05,
      "loss": 1.2535,
      "step": 32000
    },
    {
      "epoch": 5.09,
      "learning_rate": 9.745537112433448e-05,
      "loss": 1.2582,
      "step": 32500
    },
    {
      "epoch": 5.17,
      "learning_rate": 9.741622298778579e-05,
      "loss": 1.2532,
      "step": 33000
    },
    {
      "epoch": 5.25,
      "learning_rate": 9.737707485123708e-05,
      "loss": 1.2366,
      "step": 33500
    },
    {
      "epoch": 5.32,
      "learning_rate": 9.733792671468839e-05,
      "loss": 1.2549,
      "step": 34000
    },
    {
      "epoch": 5.4,
      "learning_rate": 9.729877857813968e-05,
      "loss": 1.2298,
      "step": 34500
    },
    {
      "epoch": 5.48,
      "learning_rate": 9.725963044159099e-05,
      "loss": 1.2699,
      "step": 35000
    },
    {
      "epoch": 5.56,
      "learning_rate": 9.722048230504228e-05,
      "loss": 1.2472,
      "step": 35500
    },
    {
      "epoch": 5.64,
      "learning_rate": 9.71813341684936e-05,
      "loss": 1.2417,
      "step": 36000
    },
    {
      "epoch": 5.72,
      "learning_rate": 9.714218603194488e-05,
      "loss": 1.2345,
      "step": 36500
    },
    {
      "epoch": 5.79,
      "learning_rate": 9.71030378953962e-05,
      "loss": 1.2494,
      "step": 37000
    },
    {
      "epoch": 5.87,
      "learning_rate": 9.706388975884748e-05,
      "loss": 1.2248,
      "step": 37500
    },
    {
      "epoch": 5.95,
      "learning_rate": 9.702474162229878e-05,
      "loss": 1.2458,
      "step": 38000
    },
    {
      "epoch": 6.0,
      "eval_loss": 1.1252777576446533,
      "eval_r": 0.572856068611145,
      "eval_runtime": 28.2961,
      "eval_samples_per_second": 56.262,
      "eval_steps_per_second": 56.262,
      "step": 38316
    },
    {
      "epoch": 6.03,
      "learning_rate": 9.698559348575008e-05,
      "loss": 1.236,
      "step": 38500
    },
    {
      "epoch": 6.11,
      "learning_rate": 9.694644534920138e-05,
      "loss": 1.2102,
      "step": 39000
    },
    {
      "epoch": 6.19,
      "learning_rate": 9.690729721265268e-05,
      "loss": 1.2118,
      "step": 39500
    },
    {
      "epoch": 6.26,
      "learning_rate": 9.686814907610398e-05,
      "loss": 1.2294,
      "step": 40000
    },
    {
      "epoch": 6.34,
      "learning_rate": 9.682900093955528e-05,
      "loss": 1.2371,
      "step": 40500
    },
    {
      "epoch": 6.42,
      "learning_rate": 9.678985280300658e-05,
      "loss": 1.2253,
      "step": 41000
    },
    {
      "epoch": 6.5,
      "learning_rate": 9.675070466645788e-05,
      "loss": 1.2261,
      "step": 41500
    },
    {
      "epoch": 6.58,
      "learning_rate": 9.671155652990918e-05,
      "loss": 1.2286,
      "step": 42000
    },
    {
      "epoch": 6.66,
      "learning_rate": 9.667240839336048e-05,
      "loss": 1.2522,
      "step": 42500
    },
    {
      "epoch": 6.73,
      "learning_rate": 9.663326025681177e-05,
      "loss": 1.2379,
      "step": 43000
    },
    {
      "epoch": 6.81,
      "learning_rate": 9.659411212026308e-05,
      "loss": 1.2215,
      "step": 43500
    },
    {
      "epoch": 6.89,
      "learning_rate": 9.655496398371437e-05,
      "loss": 1.2206,
      "step": 44000
    },
    {
      "epoch": 6.97,
      "learning_rate": 9.651581584716568e-05,
      "loss": 1.236,
      "step": 44500
    },
    {
      "epoch": 7.0,
      "eval_loss": 1.110272765159607,
      "eval_r": 0.5791366100311279,
      "eval_runtime": 27.9701,
      "eval_samples_per_second": 56.918,
      "eval_steps_per_second": 56.918,
      "step": 44702
    },
    {
      "epoch": 7.05,
      "learning_rate": 9.647666771061697e-05,
      "loss": 1.2315,
      "step": 45000
    },
    {
      "epoch": 7.12,
      "learning_rate": 9.643751957406828e-05,
      "loss": 1.2073,
      "step": 45500
    },
    {
      "epoch": 7.2,
      "learning_rate": 9.639837143751957e-05,
      "loss": 1.2332,
      "step": 46000
    },
    {
      "epoch": 7.28,
      "learning_rate": 9.635922330097088e-05,
      "loss": 1.2153,
      "step": 46500
    },
    {
      "epoch": 7.36,
      "learning_rate": 9.632007516442217e-05,
      "loss": 1.1954,
      "step": 47000
    },
    {
      "epoch": 7.44,
      "learning_rate": 9.628092702787348e-05,
      "loss": 1.2083,
      "step": 47500
    },
    {
      "epoch": 7.52,
      "learning_rate": 9.624177889132477e-05,
      "loss": 1.2227,
      "step": 48000
    },
    {
      "epoch": 7.59,
      "learning_rate": 9.620263075477609e-05,
      "loss": 1.2047,
      "step": 48500
    },
    {
      "epoch": 7.67,
      "learning_rate": 9.616348261822737e-05,
      "loss": 1.2027,
      "step": 49000
    },
    {
      "epoch": 7.75,
      "learning_rate": 9.612433448167869e-05,
      "loss": 1.2196,
      "step": 49500
    },
    {
      "epoch": 7.83,
      "learning_rate": 9.608518634512997e-05,
      "loss": 1.2092,
      "step": 50000
    },
    {
      "epoch": 7.91,
      "learning_rate": 9.604603820858127e-05,
      "loss": 1.2043,
      "step": 50500
    },
    {
      "epoch": 7.99,
      "learning_rate": 9.600689007203257e-05,
      "loss": 1.2147,
      "step": 51000
    },
    {
      "epoch": 8.0,
      "eval_loss": 1.1047828197479248,
      "eval_r": 0.5833042860031128,
      "eval_runtime": 28.0401,
      "eval_samples_per_second": 56.776,
      "eval_steps_per_second": 56.776,
      "step": 51088
    },
    {
      "epoch": 8.06,
      "learning_rate": 9.596774193548387e-05,
      "loss": 1.2023,
      "step": 51500
    },
    {
      "epoch": 8.14,
      "learning_rate": 9.592859379893517e-05,
      "loss": 1.2053,
      "step": 52000
    },
    {
      "epoch": 8.22,
      "learning_rate": 9.588944566238647e-05,
      "loss": 1.1987,
      "step": 52500
    },
    {
      "epoch": 8.3,
      "learning_rate": 9.585029752583777e-05,
      "loss": 1.1819,
      "step": 53000
    },
    {
      "epoch": 8.38,
      "learning_rate": 9.581114938928907e-05,
      "loss": 1.1988,
      "step": 53500
    },
    {
      "epoch": 8.46,
      "learning_rate": 9.577200125274037e-05,
      "loss": 1.22,
      "step": 54000
    },
    {
      "epoch": 8.53,
      "learning_rate": 9.573285311619167e-05,
      "loss": 1.191,
      "step": 54500
    },
    {
      "epoch": 8.61,
      "learning_rate": 9.569370497964297e-05,
      "loss": 1.2074,
      "step": 55000
    },
    {
      "epoch": 8.69,
      "learning_rate": 9.565455684309427e-05,
      "loss": 1.1823,
      "step": 55500
    },
    {
      "epoch": 8.77,
      "learning_rate": 9.561540870654558e-05,
      "loss": 1.188,
      "step": 56000
    },
    {
      "epoch": 8.85,
      "learning_rate": 9.557626056999688e-05,
      "loss": 1.1978,
      "step": 56500
    },
    {
      "epoch": 8.93,
      "learning_rate": 9.553711243344818e-05,
      "loss": 1.1876,
      "step": 57000
    },
    {
      "epoch": 9.0,
      "eval_loss": 1.0937646627426147,
      "eval_r": 0.585046648979187,
      "eval_runtime": 27.7929,
      "eval_samples_per_second": 57.281,
      "eval_steps_per_second": 57.281,
      "step": 57474
    },
    {
      "epoch": 9.0,
      "learning_rate": 9.549796429689946e-05,
      "loss": 1.205,
      "step": 57500
    },
    {
      "epoch": 9.08,
      "learning_rate": 9.545881616035078e-05,
      "loss": 1.1898,
      "step": 58000
    },
    {
      "epoch": 9.16,
      "learning_rate": 9.541966802380206e-05,
      "loss": 1.1594,
      "step": 58500
    },
    {
      "epoch": 9.24,
      "learning_rate": 9.538051988725338e-05,
      "loss": 1.1937,
      "step": 59000
    },
    {
      "epoch": 9.32,
      "learning_rate": 9.534137175070466e-05,
      "loss": 1.1912,
      "step": 59500
    },
    {
      "epoch": 9.4,
      "learning_rate": 9.530222361415598e-05,
      "loss": 1.1697,
      "step": 60000
    },
    {
      "epoch": 9.47,
      "learning_rate": 9.526307547760726e-05,
      "loss": 1.1782,
      "step": 60500
    },
    {
      "epoch": 9.55,
      "learning_rate": 9.522392734105858e-05,
      "loss": 1.1871,
      "step": 61000
    },
    {
      "epoch": 9.63,
      "learning_rate": 9.518477920450986e-05,
      "loss": 1.1914,
      "step": 61500
    },
    {
      "epoch": 9.71,
      "learning_rate": 9.514563106796118e-05,
      "loss": 1.1886,
      "step": 62000
    },
    {
      "epoch": 9.79,
      "learning_rate": 9.510648293141246e-05,
      "loss": 1.1994,
      "step": 62500
    },
    {
      "epoch": 9.87,
      "learning_rate": 9.506733479486378e-05,
      "loss": 1.1923,
      "step": 63000
    },
    {
      "epoch": 9.94,
      "learning_rate": 9.502818665831506e-05,
      "loss": 1.1949,
      "step": 63500
    },
    {
      "epoch": 10.0,
      "eval_loss": 1.0800892114639282,
      "eval_r": 0.5896174311637878,
      "eval_runtime": 27.6092,
      "eval_samples_per_second": 57.662,
      "eval_steps_per_second": 57.662,
      "step": 63860
    },
    {
      "epoch": 10.02,
      "learning_rate": 9.498903852176636e-05,
      "loss": 1.168,
      "step": 64000
    },
    {
      "epoch": 10.1,
      "learning_rate": 9.494989038521767e-05,
      "loss": 1.1692,
      "step": 64500
    },
    {
      "epoch": 10.18,
      "learning_rate": 9.491074224866897e-05,
      "loss": 1.2023,
      "step": 65000
    },
    {
      "epoch": 10.26,
      "learning_rate": 9.487159411212027e-05,
      "loss": 1.1728,
      "step": 65500
    },
    {
      "epoch": 10.34,
      "learning_rate": 9.483244597557157e-05,
      "loss": 1.1762,
      "step": 66000
    },
    {
      "epoch": 10.41,
      "learning_rate": 9.479329783902287e-05,
      "loss": 1.1859,
      "step": 66500
    },
    {
      "epoch": 10.49,
      "learning_rate": 9.475414970247417e-05,
      "loss": 1.1697,
      "step": 67000
    },
    {
      "epoch": 10.57,
      "learning_rate": 9.471500156592547e-05,
      "loss": 1.1852,
      "step": 67500
    },
    {
      "epoch": 10.65,
      "learning_rate": 9.467585342937677e-05,
      "loss": 1.1662,
      "step": 68000
    },
    {
      "epoch": 10.73,
      "learning_rate": 9.463670529282807e-05,
      "loss": 1.1667,
      "step": 68500
    },
    {
      "epoch": 10.8,
      "learning_rate": 9.459755715627937e-05,
      "loss": 1.1584,
      "step": 69000
    },
    {
      "epoch": 10.88,
      "learning_rate": 9.455840901973067e-05,
      "loss": 1.172,
      "step": 69500
    },
    {
      "epoch": 10.96,
      "learning_rate": 9.451926088318197e-05,
      "loss": 1.184,
      "step": 70000
    },
    {
      "epoch": 11.0,
      "eval_loss": 1.074059247970581,
      "eval_r": 0.593712329864502,
      "eval_runtime": 27.6433,
      "eval_samples_per_second": 57.591,
      "eval_steps_per_second": 57.591,
      "step": 70246
    },
    {
      "epoch": 11.04,
      "learning_rate": 9.448011274663327e-05,
      "loss": 1.1552,
      "step": 70500
    },
    {
      "epoch": 11.12,
      "learning_rate": 9.444096461008455e-05,
      "loss": 1.1663,
      "step": 71000
    },
    {
      "epoch": 11.2,
      "learning_rate": 9.440181647353587e-05,
      "loss": 1.171,
      "step": 71500
    },
    {
      "epoch": 11.27,
      "learning_rate": 9.436266833698715e-05,
      "loss": 1.1657,
      "step": 72000
    },
    {
      "epoch": 11.35,
      "learning_rate": 9.432352020043847e-05,
      "loss": 1.188,
      "step": 72500
    },
    {
      "epoch": 11.43,
      "learning_rate": 9.428437206388976e-05,
      "loss": 1.1695,
      "step": 73000
    },
    {
      "epoch": 11.51,
      "learning_rate": 9.424522392734107e-05,
      "loss": 1.1799,
      "step": 73500
    },
    {
      "epoch": 11.59,
      "learning_rate": 9.420607579079236e-05,
      "loss": 1.1687,
      "step": 74000
    },
    {
      "epoch": 11.67,
      "learning_rate": 9.416692765424367e-05,
      "loss": 1.1558,
      "step": 74500
    },
    {
      "epoch": 11.74,
      "learning_rate": 9.412777951769496e-05,
      "loss": 1.1566,
      "step": 75000
    },
    {
      "epoch": 11.82,
      "learning_rate": 9.408863138114627e-05,
      "loss": 1.1678,
      "step": 75500
    },
    {
      "epoch": 11.9,
      "learning_rate": 9.404948324459756e-05,
      "loss": 1.1693,
      "step": 76000
    },
    {
      "epoch": 11.98,
      "learning_rate": 9.401033510804887e-05,
      "loss": 1.1643,
      "step": 76500
    },
    {
      "epoch": 12.0,
      "eval_loss": 1.072095513343811,
      "eval_r": 0.5952156782150269,
      "eval_runtime": 28.2375,
      "eval_samples_per_second": 56.379,
      "eval_steps_per_second": 56.379,
      "step": 76632
    },
    {
      "epoch": 12.06,
      "learning_rate": 9.397118697150016e-05,
      "loss": 1.154,
      "step": 77000
    },
    {
      "epoch": 12.14,
      "learning_rate": 9.393203883495146e-05,
      "loss": 1.186,
      "step": 77500
    },
    {
      "epoch": 12.21,
      "learning_rate": 9.389289069840276e-05,
      "loss": 1.1575,
      "step": 78000
    },
    {
      "epoch": 12.29,
      "learning_rate": 9.385374256185406e-05,
      "loss": 1.1681,
      "step": 78500
    },
    {
      "epoch": 12.37,
      "learning_rate": 9.381459442530536e-05,
      "loss": 1.142,
      "step": 79000
    },
    {
      "epoch": 12.45,
      "learning_rate": 9.377544628875666e-05,
      "loss": 1.1647,
      "step": 79500
    },
    {
      "epoch": 12.53,
      "learning_rate": 9.373629815220796e-05,
      "loss": 1.1569,
      "step": 80000
    },
    {
      "epoch": 12.61,
      "learning_rate": 9.369715001565926e-05,
      "loss": 1.1498,
      "step": 80500
    },
    {
      "epoch": 12.68,
      "learning_rate": 9.365800187911056e-05,
      "loss": 1.1499,
      "step": 81000
    },
    {
      "epoch": 12.76,
      "learning_rate": 9.361885374256186e-05,
      "loss": 1.1784,
      "step": 81500
    },
    {
      "epoch": 12.84,
      "learning_rate": 9.357970560601316e-05,
      "loss": 1.1577,
      "step": 82000
    },
    {
      "epoch": 12.92,
      "learning_rate": 9.354055746946446e-05,
      "loss": 1.1804,
      "step": 82500
    },
    {
      "epoch": 13.0,
      "learning_rate": 9.350140933291576e-05,
      "loss": 1.1576,
      "step": 83000
    },
    {
      "epoch": 13.0,
      "eval_loss": 1.062264323234558,
      "eval_r": 0.5984395742416382,
      "eval_runtime": 28.4612,
      "eval_samples_per_second": 55.936,
      "eval_steps_per_second": 55.936,
      "step": 83018
    },
    {
      "epoch": 13.08,
      "learning_rate": 9.346226119636706e-05,
      "loss": 1.1442,
      "step": 83500
    },
    {
      "epoch": 13.15,
      "learning_rate": 9.342311305981836e-05,
      "loss": 1.1622,
      "step": 84000
    },
    {
      "epoch": 13.23,
      "learning_rate": 9.338396492326966e-05,
      "loss": 1.1625,
      "step": 84500
    },
    {
      "epoch": 13.31,
      "learning_rate": 9.334481678672096e-05,
      "loss": 1.1553,
      "step": 85000
    },
    {
      "epoch": 13.39,
      "learning_rate": 9.330566865017225e-05,
      "loss": 1.1407,
      "step": 85500
    },
    {
      "epoch": 13.47,
      "learning_rate": 9.326652051362356e-05,
      "loss": 1.1545,
      "step": 86000
    },
    {
      "epoch": 13.55,
      "learning_rate": 9.322737237707485e-05,
      "loss": 1.1655,
      "step": 86500
    },
    {
      "epoch": 13.62,
      "learning_rate": 9.318822424052616e-05,
      "loss": 1.1505,
      "step": 87000
    },
    {
      "epoch": 13.7,
      "learning_rate": 9.314907610397745e-05,
      "loss": 1.1678,
      "step": 87500
    },
    {
      "epoch": 13.78,
      "learning_rate": 9.310992796742876e-05,
      "loss": 1.1613,
      "step": 88000
    },
    {
      "epoch": 13.86,
      "learning_rate": 9.307077983088005e-05,
      "loss": 1.1484,
      "step": 88500
    },
    {
      "epoch": 13.94,
      "learning_rate": 9.303163169433136e-05,
      "loss": 1.1417,
      "step": 89000
    },
    {
      "epoch": 14.0,
      "eval_loss": 1.062491774559021,
      "eval_r": 0.6004797220230103,
      "eval_runtime": 27.7874,
      "eval_samples_per_second": 57.292,
      "eval_steps_per_second": 57.292,
      "step": 89404
    },
    {
      "epoch": 14.02,
      "learning_rate": 9.299248355778265e-05,
      "loss": 1.1631,
      "step": 89500
    },
    {
      "epoch": 14.09,
      "learning_rate": 9.295333542123395e-05,
      "loss": 1.1291,
      "step": 90000
    },
    {
      "epoch": 14.17,
      "learning_rate": 9.291418728468525e-05,
      "loss": 1.14,
      "step": 90500
    },
    {
      "epoch": 14.25,
      "learning_rate": 9.287503914813655e-05,
      "loss": 1.1481,
      "step": 91000
    },
    {
      "epoch": 14.33,
      "learning_rate": 9.283589101158785e-05,
      "loss": 1.1623,
      "step": 91500
    },
    {
      "epoch": 14.41,
      "learning_rate": 9.279674287503915e-05,
      "loss": 1.1489,
      "step": 92000
    },
    {
      "epoch": 14.48,
      "learning_rate": 9.275759473849045e-05,
      "loss": 1.1433,
      "step": 92500
    },
    {
      "epoch": 14.56,
      "learning_rate": 9.271844660194175e-05,
      "loss": 1.1436,
      "step": 93000
    },
    {
      "epoch": 14.64,
      "learning_rate": 9.267929846539305e-05,
      "loss": 1.1442,
      "step": 93500
    },
    {
      "epoch": 14.72,
      "learning_rate": 9.264015032884435e-05,
      "loss": 1.1434,
      "step": 94000
    },
    {
      "epoch": 14.8,
      "learning_rate": 9.260100219229565e-05,
      "loss": 1.1444,
      "step": 94500
    },
    {
      "epoch": 14.88,
      "learning_rate": 9.256185405574695e-05,
      "loss": 1.1774,
      "step": 95000
    },
    {
      "epoch": 14.95,
      "learning_rate": 9.252270591919825e-05,
      "loss": 1.1518,
      "step": 95500
    },
    {
      "epoch": 15.0,
      "eval_loss": 1.064144253730774,
      "eval_r": 0.5994089841842651,
      "eval_runtime": 27.9168,
      "eval_samples_per_second": 57.027,
      "eval_steps_per_second": 57.027,
      "step": 95790
    },
    {
      "epoch": 15.03,
      "learning_rate": 9.248355778264955e-05,
      "loss": 1.1404,
      "step": 96000
    },
    {
      "epoch": 15.11,
      "learning_rate": 9.244440964610085e-05,
      "loss": 1.1536,
      "step": 96500
    },
    {
      "epoch": 15.19,
      "learning_rate": 9.240526150955215e-05,
      "loss": 1.1497,
      "step": 97000
    },
    {
      "epoch": 15.27,
      "learning_rate": 9.236611337300345e-05,
      "loss": 1.136,
      "step": 97500
    },
    {
      "epoch": 15.35,
      "learning_rate": 9.232696523645475e-05,
      "loss": 1.1456,
      "step": 98000
    },
    {
      "epoch": 15.42,
      "learning_rate": 9.228781709990605e-05,
      "loss": 1.1696,
      "step": 98500
    },
    {
      "epoch": 15.5,
      "learning_rate": 9.224866896335734e-05,
      "loss": 1.155,
      "step": 99000
    },
    {
      "epoch": 15.58,
      "learning_rate": 9.220952082680865e-05,
      "loss": 1.1575,
      "step": 99500
    },
    {
      "epoch": 15.66,
      "learning_rate": 9.217037269025994e-05,
      "loss": 1.1083,
      "step": 100000
    },
    {
      "epoch": 15.74,
      "learning_rate": 9.213122455371125e-05,
      "loss": 1.1368,
      "step": 100500
    },
    {
      "epoch": 15.82,
      "learning_rate": 9.209207641716254e-05,
      "loss": 1.1333,
      "step": 101000
    },
    {
      "epoch": 15.89,
      "learning_rate": 9.205292828061385e-05,
      "loss": 1.1421,
      "step": 101500
    },
    {
      "epoch": 15.97,
      "learning_rate": 9.201378014406514e-05,
      "loss": 1.1415,
      "step": 102000
    },
    {
      "epoch": 16.0,
      "eval_loss": 1.0547698736190796,
      "eval_r": 0.6031479835510254,
      "eval_runtime": 27.8459,
      "eval_samples_per_second": 57.172,
      "eval_steps_per_second": 57.172,
      "step": 102176
    },
    {
      "epoch": 16.05,
      "learning_rate": 9.197463200751645e-05,
      "loss": 1.1334,
      "step": 102500
    },
    {
      "epoch": 16.13,
      "learning_rate": 9.193548387096774e-05,
      "loss": 1.1314,
      "step": 103000
    },
    {
      "epoch": 16.21,
      "learning_rate": 9.189633573441904e-05,
      "loss": 1.1443,
      "step": 103500
    },
    {
      "epoch": 16.29,
      "learning_rate": 9.185718759787034e-05,
      "loss": 1.1492,
      "step": 104000
    },
    {
      "epoch": 16.36,
      "learning_rate": 9.181803946132164e-05,
      "loss": 1.1379,
      "step": 104500
    },
    {
      "epoch": 16.44,
      "learning_rate": 9.177889132477294e-05,
      "loss": 1.1293,
      "step": 105000
    },
    {
      "epoch": 16.52,
      "learning_rate": 9.173974318822424e-05,
      "loss": 1.1456,
      "step": 105500
    },
    {
      "epoch": 16.6,
      "learning_rate": 9.170059505167554e-05,
      "loss": 1.1413,
      "step": 106000
    },
    {
      "epoch": 16.68,
      "learning_rate": 9.166144691512684e-05,
      "loss": 1.1377,
      "step": 106500
    },
    {
      "epoch": 16.76,
      "learning_rate": 9.162229877857814e-05,
      "loss": 1.1437,
      "step": 107000
    },
    {
      "epoch": 16.83,
      "learning_rate": 9.158315064202944e-05,
      "loss": 1.1351,
      "step": 107500
    },
    {
      "epoch": 16.91,
      "learning_rate": 9.154400250548074e-05,
      "loss": 1.1479,
      "step": 108000
    },
    {
      "epoch": 16.99,
      "learning_rate": 9.150485436893204e-05,
      "loss": 1.1434,
      "step": 108500
    },
    {
      "epoch": 17.0,
      "eval_loss": 1.0547422170639038,
      "eval_r": 0.6039228439331055,
      "eval_runtime": 27.1509,
      "eval_samples_per_second": 58.635,
      "eval_steps_per_second": 58.635,
      "step": 108562
    },
    {
      "epoch": 17.07,
      "learning_rate": 9.146570623238334e-05,
      "loss": 1.1519,
      "step": 109000
    },
    {
      "epoch": 17.15,
      "learning_rate": 9.142655809583464e-05,
      "loss": 1.1456,
      "step": 109500
    },
    {
      "epoch": 17.23,
      "learning_rate": 9.138740995928594e-05,
      "loss": 1.1247,
      "step": 110000
    },
    {
      "epoch": 17.3,
      "learning_rate": 9.134826182273724e-05,
      "loss": 1.132,
      "step": 110500
    },
    {
      "epoch": 17.38,
      "learning_rate": 9.130911368618854e-05,
      "loss": 1.1477,
      "step": 111000
    },
    {
      "epoch": 17.46,
      "learning_rate": 9.126996554963985e-05,
      "loss": 1.1243,
      "step": 111500
    },
    {
      "epoch": 17.54,
      "learning_rate": 9.123081741309115e-05,
      "loss": 1.1359,
      "step": 112000
    },
    {
      "epoch": 17.62,
      "learning_rate": 9.119166927654245e-05,
      "loss": 1.1278,
      "step": 112500
    },
    {
      "epoch": 17.69,
      "learning_rate": 9.115252113999375e-05,
      "loss": 1.1521,
      "step": 113000
    },
    {
      "epoch": 17.77,
      "learning_rate": 9.111337300344503e-05,
      "loss": 1.132,
      "step": 113500
    },
    {
      "epoch": 17.85,
      "learning_rate": 9.107422486689635e-05,
      "loss": 1.1279,
      "step": 114000
    },
    {
      "epoch": 17.93,
      "learning_rate": 9.103507673034763e-05,
      "loss": 1.1217,
      "step": 114500
    },
    {
      "epoch": 18.0,
      "eval_loss": 1.0549495220184326,
      "eval_r": 0.6046115159988403,
      "eval_runtime": 27.5786,
      "eval_samples_per_second": 57.726,
      "eval_steps_per_second": 57.726,
      "step": 114948
    },
    {
      "epoch": 18.01,
      "learning_rate": 9.099592859379895e-05,
      "loss": 1.147,
      "step": 115000
    },
    {
      "epoch": 18.09,
      "learning_rate": 9.095678045725023e-05,
      "loss": 1.1115,
      "step": 115500
    },
    {
      "epoch": 18.16,
      "learning_rate": 9.091763232070153e-05,
      "loss": 1.1301,
      "step": 116000
    },
    {
      "epoch": 18.24,
      "learning_rate": 9.087848418415283e-05,
      "loss": 1.1328,
      "step": 116500
    },
    {
      "epoch": 18.32,
      "learning_rate": 9.083933604760413e-05,
      "loss": 1.1306,
      "step": 117000
    },
    {
      "epoch": 18.4,
      "learning_rate": 9.080018791105543e-05,
      "loss": 1.1297,
      "step": 117500
    },
    {
      "epoch": 18.48,
      "learning_rate": 9.076103977450673e-05,
      "loss": 1.1364,
      "step": 118000
    },
    {
      "epoch": 18.56,
      "learning_rate": 9.072189163795803e-05,
      "loss": 1.1366,
      "step": 118500
    },
    {
      "epoch": 18.63,
      "learning_rate": 9.068274350140933e-05,
      "loss": 1.1479,
      "step": 119000
    },
    {
      "epoch": 18.71,
      "learning_rate": 9.064359536486063e-05,
      "loss": 1.1286,
      "step": 119500
    },
    {
      "epoch": 18.79,
      "learning_rate": 9.060444722831194e-05,
      "loss": 1.1395,
      "step": 120000
    },
    {
      "epoch": 18.87,
      "learning_rate": 9.056529909176324e-05,
      "loss": 1.1463,
      "step": 120500
    },
    {
      "epoch": 18.95,
      "learning_rate": 9.052615095521454e-05,
      "loss": 1.1153,
      "step": 121000
    },
    {
      "epoch": 19.0,
      "eval_loss": 1.0624439716339111,
      "eval_r": 0.6035078167915344,
      "eval_runtime": 27.5112,
      "eval_samples_per_second": 57.867,
      "eval_steps_per_second": 57.867,
      "step": 121334
    },
    {
      "epoch": 19.03,
      "learning_rate": 9.048700281866584e-05,
      "loss": 1.1322,
      "step": 121500
    },
    {
      "epoch": 19.1,
      "learning_rate": 9.044785468211714e-05,
      "loss": 1.1353,
      "step": 122000
    },
    {
      "epoch": 19.18,
      "learning_rate": 9.040870654556844e-05,
      "loss": 1.133,
      "step": 122500
    },
    {
      "epoch": 19.26,
      "learning_rate": 9.036955840901974e-05,
      "loss": 1.113,
      "step": 123000
    },
    {
      "epoch": 19.34,
      "learning_rate": 9.033041027247104e-05,
      "loss": 1.1411,
      "step": 123500
    },
    {
      "epoch": 19.42,
      "learning_rate": 9.029126213592234e-05,
      "loss": 1.1061,
      "step": 124000
    },
    {
      "epoch": 19.5,
      "learning_rate": 9.025211399937364e-05,
      "loss": 1.1379,
      "step": 124500
    },
    {
      "epoch": 19.57,
      "learning_rate": 9.021296586282494e-05,
      "loss": 1.106,
      "step": 125000
    },
    {
      "epoch": 19.65,
      "learning_rate": 9.017381772627624e-05,
      "loss": 1.1141,
      "step": 125500
    },
    {
      "epoch": 19.73,
      "learning_rate": 9.013466958972754e-05,
      "loss": 1.1304,
      "step": 126000
    },
    {
      "epoch": 19.81,
      "learning_rate": 9.009552145317884e-05,
      "loss": 1.1483,
      "step": 126500
    },
    {
      "epoch": 19.89,
      "learning_rate": 9.005637331663014e-05,
      "loss": 1.1324,
      "step": 127000
    },
    {
      "epoch": 19.97,
      "learning_rate": 9.001722518008144e-05,
      "loss": 1.128,
      "step": 127500
    },
    {
      "epoch": 20.0,
      "eval_loss": 1.0484340190887451,
      "eval_r": 0.6071404814720154,
      "eval_runtime": 27.6326,
      "eval_samples_per_second": 57.613,
      "eval_steps_per_second": 57.613,
      "step": 127720
    },
    {
      "epoch": 20.04,
      "learning_rate": 8.997807704353273e-05,
      "loss": 1.1158,
      "step": 128000
    },
    {
      "epoch": 20.12,
      "learning_rate": 8.993892890698404e-05,
      "loss": 1.1354,
      "step": 128500
    },
    {
      "epoch": 20.2,
      "learning_rate": 8.989978077043533e-05,
      "loss": 1.1345,
      "step": 129000
    },
    {
      "epoch": 20.28,
      "learning_rate": 8.986063263388663e-05,
      "loss": 1.1529,
      "step": 129500
    },
    {
      "epoch": 20.36,
      "learning_rate": 8.982148449733793e-05,
      "loss": 1.1057,
      "step": 130000
    },
    {
      "epoch": 20.44,
      "learning_rate": 8.978233636078923e-05,
      "loss": 1.1353,
      "step": 130500
    },
    {
      "epoch": 20.51,
      "learning_rate": 8.974318822424053e-05,
      "loss": 1.1363,
      "step": 131000
    },
    {
      "epoch": 20.59,
      "learning_rate": 8.970404008769183e-05,
      "loss": 1.1039,
      "step": 131500
    },
    {
      "epoch": 20.67,
      "learning_rate": 8.966489195114313e-05,
      "loss": 1.1218,
      "step": 132000
    },
    {
      "epoch": 20.75,
      "learning_rate": 8.962574381459443e-05,
      "loss": 1.1225,
      "step": 132500
    },
    {
      "epoch": 20.83,
      "learning_rate": 8.958659567804573e-05,
      "loss": 1.1052,
      "step": 133000
    },
    {
      "epoch": 20.91,
      "learning_rate": 8.954744754149703e-05,
      "loss": 1.1298,
      "step": 133500
    },
    {
      "epoch": 20.98,
      "learning_rate": 8.950829940494833e-05,
      "loss": 1.1281,
      "step": 134000
    },
    {
      "epoch": 21.0,
      "eval_loss": 1.0416960716247559,
      "eval_r": 0.6072396636009216,
      "eval_runtime": 27.5551,
      "eval_samples_per_second": 57.775,
      "eval_steps_per_second": 57.775,
      "step": 134106
    },
    {
      "epoch": 21.06,
      "learning_rate": 8.946915126839963e-05,
      "loss": 1.1161,
      "step": 134500
    },
    {
      "epoch": 21.14,
      "learning_rate": 8.943000313185093e-05,
      "loss": 1.1409,
      "step": 135000
    },
    {
      "epoch": 21.22,
      "learning_rate": 8.939085499530223e-05,
      "loss": 1.13,
      "step": 135500
    },
    {
      "epoch": 21.3,
      "learning_rate": 8.935170685875353e-05,
      "loss": 1.1329,
      "step": 136000
    },
    {
      "epoch": 21.37,
      "learning_rate": 8.931255872220483e-05,
      "loss": 1.1177,
      "step": 136500
    },
    {
      "epoch": 21.45,
      "learning_rate": 8.927341058565613e-05,
      "loss": 1.1175,
      "step": 137000
    },
    {
      "epoch": 21.53,
      "learning_rate": 8.923426244910743e-05,
      "loss": 1.117,
      "step": 137500
    },
    {
      "epoch": 21.61,
      "learning_rate": 8.919511431255873e-05,
      "loss": 1.1221,
      "step": 138000
    },
    {
      "epoch": 21.69,
      "learning_rate": 8.915596617601003e-05,
      "loss": 1.138,
      "step": 138500
    },
    {
      "epoch": 21.77,
      "learning_rate": 8.911681803946133e-05,
      "loss": 1.1174,
      "step": 139000
    },
    {
      "epoch": 21.84,
      "learning_rate": 8.907766990291263e-05,
      "loss": 1.1145,
      "step": 139500
    },
    {
      "epoch": 21.92,
      "learning_rate": 8.903852176636393e-05,
      "loss": 1.0911,
      "step": 140000
    },
    {
      "epoch": 22.0,
      "eval_loss": 1.0475826263427734,
      "eval_r": 0.6076748371124268,
      "eval_runtime": 28.7045,
      "eval_samples_per_second": 55.462,
      "eval_steps_per_second": 55.462,
      "step": 140492
    },
    {
      "epoch": 22.0,
      "learning_rate": 8.899937362981523e-05,
      "loss": 1.1181,
      "step": 140500
    },
    {
      "epoch": 22.08,
      "learning_rate": 8.896022549326653e-05,
      "loss": 1.1122,
      "step": 141000
    },
    {
      "epoch": 22.16,
      "learning_rate": 8.892107735671782e-05,
      "loss": 1.1141,
      "step": 141500
    },
    {
      "epoch": 22.24,
      "learning_rate": 8.888192922016913e-05,
      "loss": 1.1236,
      "step": 142000
    },
    {
      "epoch": 22.31,
      "learning_rate": 8.884278108362042e-05,
      "loss": 1.1247,
      "step": 142500
    },
    {
      "epoch": 22.39,
      "learning_rate": 8.880363294707172e-05,
      "loss": 1.1317,
      "step": 143000
    },
    {
      "epoch": 22.47,
      "learning_rate": 8.876448481052302e-05,
      "loss": 1.124,
      "step": 143500
    },
    {
      "epoch": 22.55,
      "learning_rate": 8.872533667397432e-05,
      "loss": 1.1059,
      "step": 144000
    },
    {
      "epoch": 22.63,
      "learning_rate": 8.868618853742562e-05,
      "loss": 1.1102,
      "step": 144500
    },
    {
      "epoch": 22.71,
      "learning_rate": 8.864704040087692e-05,
      "loss": 1.1223,
      "step": 145000
    },
    {
      "epoch": 22.78,
      "learning_rate": 8.860789226432822e-05,
      "loss": 1.117,
      "step": 145500
    },
    {
      "epoch": 22.86,
      "learning_rate": 8.856874412777952e-05,
      "loss": 1.1266,
      "step": 146000
    },
    {
      "epoch": 22.94,
      "learning_rate": 8.852959599123082e-05,
      "loss": 1.1364,
      "step": 146500
    },
    {
      "epoch": 23.0,
      "eval_loss": 1.045177936553955,
      "eval_r": 0.6089239716529846,
      "eval_runtime": 27.7014,
      "eval_samples_per_second": 57.47,
      "eval_steps_per_second": 57.47,
      "step": 146878
    },
    {
      "epoch": 23.02,
      "learning_rate": 8.849044785468212e-05,
      "loss": 1.0936,
      "step": 147000
    },
    {
      "epoch": 23.1,
      "learning_rate": 8.845129971813342e-05,
      "loss": 1.1409,
      "step": 147500
    },
    {
      "epoch": 23.18,
      "learning_rate": 8.841215158158472e-05,
      "loss": 1.11,
      "step": 148000
    },
    {
      "epoch": 23.25,
      "learning_rate": 8.837300344503602e-05,
      "loss": 1.1221,
      "step": 148500
    },
    {
      "epoch": 23.33,
      "learning_rate": 8.833385530848732e-05,
      "loss": 1.1339,
      "step": 149000
    },
    {
      "epoch": 23.41,
      "learning_rate": 8.829470717193862e-05,
      "loss": 1.116,
      "step": 149500
    },
    {
      "epoch": 23.49,
      "learning_rate": 8.825555903538992e-05,
      "loss": 1.1013,
      "step": 150000
    },
    {
      "epoch": 23.57,
      "learning_rate": 8.821641089884122e-05,
      "loss": 1.0955,
      "step": 150500
    },
    {
      "epoch": 23.65,
      "learning_rate": 8.817726276229252e-05,
      "loss": 1.1172,
      "step": 151000
    },
    {
      "epoch": 23.72,
      "learning_rate": 8.813811462574382e-05,
      "loss": 1.1242,
      "step": 151500
    },
    {
      "epoch": 23.8,
      "learning_rate": 8.809896648919512e-05,
      "loss": 1.1088,
      "step": 152000
    },
    {
      "epoch": 23.88,
      "learning_rate": 8.805981835264642e-05,
      "loss": 1.1041,
      "step": 152500
    },
    {
      "epoch": 23.96,
      "learning_rate": 8.802067021609772e-05,
      "loss": 1.1206,
      "step": 153000
    },
    {
      "epoch": 24.0,
      "eval_loss": 1.040993332862854,
      "eval_r": 0.6096900105476379,
      "eval_runtime": 27.4391,
      "eval_samples_per_second": 58.019,
      "eval_steps_per_second": 58.019,
      "step": 153264
    },
    {
      "epoch": 24.04,
      "learning_rate": 8.798152207954902e-05,
      "loss": 1.1344,
      "step": 153500
    },
    {
      "epoch": 24.12,
      "learning_rate": 8.794237394300032e-05,
      "loss": 1.1216,
      "step": 154000
    },
    {
      "epoch": 24.19,
      "learning_rate": 8.790322580645162e-05,
      "loss": 1.1023,
      "step": 154500
    },
    {
      "epoch": 24.27,
      "learning_rate": 8.786407766990292e-05,
      "loss": 1.1014,
      "step": 155000
    },
    {
      "epoch": 24.35,
      "learning_rate": 8.782492953335421e-05,
      "loss": 1.1139,
      "step": 155500
    },
    {
      "epoch": 24.43,
      "learning_rate": 8.778578139680551e-05,
      "loss": 1.1361,
      "step": 156000
    },
    {
      "epoch": 24.51,
      "learning_rate": 8.774663326025681e-05,
      "loss": 1.1052,
      "step": 156500
    },
    {
      "epoch": 24.59,
      "learning_rate": 8.770748512370811e-05,
      "loss": 1.105,
      "step": 157000
    },
    {
      "epoch": 24.66,
      "learning_rate": 8.766833698715941e-05,
      "loss": 1.1125,
      "step": 157500
    },
    {
      "epoch": 24.74,
      "learning_rate": 8.762918885061071e-05,
      "loss": 1.1242,
      "step": 158000
    },
    {
      "epoch": 24.82,
      "learning_rate": 8.759004071406201e-05,
      "loss": 1.1192,
      "step": 158500
    },
    {
      "epoch": 24.9,
      "learning_rate": 8.755089257751331e-05,
      "loss": 1.1008,
      "step": 159000
    },
    {
      "epoch": 24.98,
      "learning_rate": 8.751174444096461e-05,
      "loss": 1.1,
      "step": 159500
    },
    {
      "epoch": 25.0,
      "eval_loss": 1.0432246923446655,
      "eval_r": 0.6083799004554749,
      "eval_runtime": 27.3589,
      "eval_samples_per_second": 58.189,
      "eval_steps_per_second": 58.189,
      "step": 159650
    },
    {
      "epoch": 25.05,
      "learning_rate": 8.747259630441591e-05,
      "loss": 1.1109,
      "step": 160000
    },
    {
      "epoch": 25.13,
      "learning_rate": 8.743344816786721e-05,
      "loss": 1.1035,
      "step": 160500
    },
    {
      "epoch": 25.21,
      "learning_rate": 8.739430003131851e-05,
      "loss": 1.1086,
      "step": 161000
    },
    {
      "epoch": 25.29,
      "learning_rate": 8.735515189476981e-05,
      "loss": 1.1151,
      "step": 161500
    },
    {
      "epoch": 25.37,
      "learning_rate": 8.731600375822111e-05,
      "loss": 1.1229,
      "step": 162000
    },
    {
      "epoch": 25.45,
      "learning_rate": 8.727685562167241e-05,
      "loss": 1.1159,
      "step": 162500
    },
    {
      "epoch": 25.52,
      "learning_rate": 8.723770748512371e-05,
      "loss": 1.1259,
      "step": 163000
    },
    {
      "epoch": 25.6,
      "learning_rate": 8.719855934857501e-05,
      "loss": 1.1198,
      "step": 163500
    },
    {
      "epoch": 25.68,
      "learning_rate": 8.715941121202631e-05,
      "loss": 1.107,
      "step": 164000
    },
    {
      "epoch": 25.76,
      "learning_rate": 8.712026307547761e-05,
      "loss": 1.1057,
      "step": 164500
    },
    {
      "epoch": 25.84,
      "learning_rate": 8.708111493892891e-05,
      "loss": 1.1111,
      "step": 165000
    },
    {
      "epoch": 25.92,
      "learning_rate": 8.704196680238021e-05,
      "loss": 1.1161,
      "step": 165500
    },
    {
      "epoch": 25.99,
      "learning_rate": 8.700281866583151e-05,
      "loss": 1.1079,
      "step": 166000
    },
    {
      "epoch": 26.0,
      "eval_loss": 1.0492688417434692,
      "eval_r": 0.6078624129295349,
      "eval_runtime": 27.8685,
      "eval_samples_per_second": 57.125,
      "eval_steps_per_second": 57.125,
      "step": 166036
    },
    {
      "epoch": 26.07,
      "learning_rate": 8.696367052928281e-05,
      "loss": 1.1213,
      "step": 166500
    },
    {
      "epoch": 26.15,
      "learning_rate": 8.692452239273412e-05,
      "loss": 1.1147,
      "step": 167000
    },
    {
      "epoch": 26.23,
      "learning_rate": 8.688537425618542e-05,
      "loss": 1.1106,
      "step": 167500
    },
    {
      "epoch": 26.31,
      "learning_rate": 8.684622611963672e-05,
      "loss": 1.092,
      "step": 168000
    },
    {
      "epoch": 26.39,
      "learning_rate": 8.680707798308802e-05,
      "loss": 1.119,
      "step": 168500
    },
    {
      "epoch": 26.46,
      "learning_rate": 8.67679298465393e-05,
      "loss": 1.1143,
      "step": 169000
    },
    {
      "epoch": 26.54,
      "learning_rate": 8.672878170999062e-05,
      "loss": 1.1212,
      "step": 169500
    },
    {
      "epoch": 26.62,
      "learning_rate": 8.66896335734419e-05,
      "loss": 1.0813,
      "step": 170000
    },
    {
      "epoch": 26.7,
      "learning_rate": 8.66504854368932e-05,
      "loss": 1.1192,
      "step": 170500
    },
    {
      "epoch": 26.78,
      "learning_rate": 8.66113373003445e-05,
      "loss": 1.1076,
      "step": 171000
    },
    {
      "epoch": 26.86,
      "learning_rate": 8.65721891637958e-05,
      "loss": 1.1101,
      "step": 171500
    },
    {
      "epoch": 26.93,
      "learning_rate": 8.65330410272471e-05,
      "loss": 1.1156,
      "step": 172000
    },
    {
      "epoch": 27.0,
      "eval_loss": 1.0381351709365845,
      "eval_r": 0.6095055341720581,
      "eval_runtime": 28.1148,
      "eval_samples_per_second": 56.625,
      "eval_steps_per_second": 56.625,
      "step": 172422
    },
    {
      "epoch": 27.01,
      "learning_rate": 8.64938928906984e-05,
      "loss": 1.0998,
      "step": 172500
    },
    {
      "epoch": 27.09,
      "learning_rate": 8.64547447541497e-05,
      "loss": 1.09,
      "step": 173000
    },
    {
      "epoch": 27.17,
      "learning_rate": 8.6415596617601e-05,
      "loss": 1.0945,
      "step": 173500
    },
    {
      "epoch": 27.25,
      "learning_rate": 8.63764484810523e-05,
      "loss": 1.1159,
      "step": 174000
    },
    {
      "epoch": 27.33,
      "learning_rate": 8.63373003445036e-05,
      "loss": 1.1197,
      "step": 174500
    },
    {
      "epoch": 27.4,
      "learning_rate": 8.62981522079549e-05,
      "loss": 1.1001,
      "step": 175000
    },
    {
      "epoch": 27.48,
      "learning_rate": 8.62590040714062e-05,
      "loss": 1.0891,
      "step": 175500
    },
    {
      "epoch": 27.56,
      "learning_rate": 8.62198559348575e-05,
      "loss": 1.0957,
      "step": 176000
    },
    {
      "epoch": 27.64,
      "learning_rate": 8.61807077983088e-05,
      "loss": 1.1158,
      "step": 176500
    },
    {
      "epoch": 27.72,
      "learning_rate": 8.61415596617601e-05,
      "loss": 1.1305,
      "step": 177000
    },
    {
      "epoch": 27.8,
      "learning_rate": 8.61024115252114e-05,
      "loss": 1.1242,
      "step": 177500
    },
    {
      "epoch": 27.87,
      "learning_rate": 8.60632633886627e-05,
      "loss": 1.103,
      "step": 178000
    },
    {
      "epoch": 27.95,
      "learning_rate": 8.6024115252114e-05,
      "loss": 1.1114,
      "step": 178500
    },
    {
      "epoch": 28.0,
      "eval_loss": 1.0423192977905273,
      "eval_r": 0.6098690032958984,
      "eval_runtime": 27.4155,
      "eval_samples_per_second": 58.069,
      "eval_steps_per_second": 58.069,
      "step": 178808
    },
    {
      "epoch": 28.03,
      "learning_rate": 8.59849671155653e-05,
      "loss": 1.1027,
      "step": 179000
    },
    {
      "epoch": 28.11,
      "learning_rate": 8.594581897901661e-05,
      "loss": 1.1022,
      "step": 179500
    },
    {
      "epoch": 28.19,
      "learning_rate": 8.590667084246791e-05,
      "loss": 1.1151,
      "step": 180000
    },
    {
      "epoch": 28.26,
      "learning_rate": 8.586752270591921e-05,
      "loss": 1.0925,
      "step": 180500
    },
    {
      "epoch": 28.34,
      "learning_rate": 8.582837456937051e-05,
      "loss": 1.1144,
      "step": 181000
    },
    {
      "epoch": 28.42,
      "learning_rate": 8.57892264328218e-05,
      "loss": 1.1172,
      "step": 181500
    },
    {
      "epoch": 28.5,
      "learning_rate": 8.575007829627311e-05,
      "loss": 1.108,
      "step": 182000
    },
    {
      "epoch": 28.58,
      "learning_rate": 8.57109301597244e-05,
      "loss": 1.0896,
      "step": 182500
    },
    {
      "epoch": 28.66,
      "learning_rate": 8.567178202317571e-05,
      "loss": 1.0978,
      "step": 183000
    },
    {
      "epoch": 28.73,
      "learning_rate": 8.5632633886627e-05,
      "loss": 1.0901,
      "step": 183500
    },
    {
      "epoch": 28.81,
      "learning_rate": 8.55934857500783e-05,
      "loss": 1.0897,
      "step": 184000
    },
    {
      "epoch": 28.89,
      "learning_rate": 8.55543376135296e-05,
      "loss": 1.1062,
      "step": 184500
    },
    {
      "epoch": 28.97,
      "learning_rate": 8.55151894769809e-05,
      "loss": 1.1337,
      "step": 185000
    },
    {
      "epoch": 29.0,
      "eval_loss": 1.0361937284469604,
      "eval_r": 0.611913800239563,
      "eval_runtime": 27.7365,
      "eval_samples_per_second": 57.397,
      "eval_steps_per_second": 57.397,
      "step": 185194
    },
    {
      "epoch": 29.05,
      "learning_rate": 8.54760413404322e-05,
      "loss": 1.1128,
      "step": 185500
    },
    {
      "epoch": 29.13,
      "learning_rate": 8.54368932038835e-05,
      "loss": 1.0733,
      "step": 186000
    },
    {
      "epoch": 29.2,
      "learning_rate": 8.53977450673348e-05,
      "loss": 1.1054,
      "step": 186500
    },
    {
      "epoch": 29.28,
      "learning_rate": 8.53585969307861e-05,
      "loss": 1.1224,
      "step": 187000
    },
    {
      "epoch": 29.36,
      "learning_rate": 8.53194487942374e-05,
      "loss": 1.1061,
      "step": 187500
    },
    {
      "epoch": 29.44,
      "learning_rate": 8.52803006576887e-05,
      "loss": 1.0976,
      "step": 188000
    },
    {
      "epoch": 29.52,
      "learning_rate": 8.524115252114e-05,
      "loss": 1.0896,
      "step": 188500
    },
    {
      "epoch": 29.6,
      "learning_rate": 8.52020043845913e-05,
      "loss": 1.1044,
      "step": 189000
    },
    {
      "epoch": 29.67,
      "learning_rate": 8.51628562480426e-05,
      "loss": 1.1017,
      "step": 189500
    },
    {
      "epoch": 29.75,
      "learning_rate": 8.51237081114939e-05,
      "loss": 1.1077,
      "step": 190000
    },
    {
      "epoch": 29.83,
      "learning_rate": 8.50845599749452e-05,
      "loss": 1.1028,
      "step": 190500
    },
    {
      "epoch": 29.91,
      "learning_rate": 8.50454118383965e-05,
      "loss": 1.0819,
      "step": 191000
    },
    {
      "epoch": 29.99,
      "learning_rate": 8.50062637018478e-05,
      "loss": 1.1136,
      "step": 191500
    },
    {
      "epoch": 30.0,
      "eval_loss": 1.0393959283828735,
      "eval_r": 0.6115639805793762,
      "eval_runtime": 27.4126,
      "eval_samples_per_second": 58.076,
      "eval_steps_per_second": 58.076,
      "step": 191580
    },
    {
      "epoch": 30.07,
      "learning_rate": 8.49671155652991e-05,
      "loss": 1.1055,
      "step": 192000
    },
    {
      "epoch": 30.14,
      "learning_rate": 8.49279674287504e-05,
      "loss": 1.1,
      "step": 192500
    },
    {
      "epoch": 30.22,
      "learning_rate": 8.48888192922017e-05,
      "loss": 1.1083,
      "step": 193000
    },
    {
      "epoch": 30.3,
      "learning_rate": 8.4849671155653e-05,
      "loss": 1.1091,
      "step": 193500
    },
    {
      "epoch": 30.38,
      "learning_rate": 8.48105230191043e-05,
      "loss": 1.1019,
      "step": 194000
    },
    {
      "epoch": 30.46,
      "learning_rate": 8.47713748825556e-05,
      "loss": 1.1094,
      "step": 194500
    },
    {
      "epoch": 30.54,
      "learning_rate": 8.473222674600689e-05,
      "loss": 1.0937,
      "step": 195000
    },
    {
      "epoch": 30.61,
      "learning_rate": 8.46930786094582e-05,
      "loss": 1.1026,
      "step": 195500
    },
    {
      "epoch": 30.69,
      "learning_rate": 8.465393047290949e-05,
      "loss": 1.0831,
      "step": 196000
    },
    {
      "epoch": 30.77,
      "learning_rate": 8.46147823363608e-05,
      "loss": 1.0857,
      "step": 196500
    },
    {
      "epoch": 30.85,
      "learning_rate": 8.457563419981209e-05,
      "loss": 1.0851,
      "step": 197000
    },
    {
      "epoch": 30.93,
      "learning_rate": 8.45364860632634e-05,
      "loss": 1.1153,
      "step": 197500
    },
    {
      "epoch": 31.0,
      "eval_loss": 1.0366803407669067,
      "eval_r": 0.6124266386032104,
      "eval_runtime": 27.5547,
      "eval_samples_per_second": 57.776,
      "eval_steps_per_second": 57.776,
      "step": 197966
    },
    {
      "epoch": 31.01,
      "learning_rate": 8.449733792671469e-05,
      "loss": 1.0998,
      "step": 198000
    },
    {
      "epoch": 31.08,
      "learning_rate": 8.445818979016599e-05,
      "loss": 1.0948,
      "step": 198500
    },
    {
      "epoch": 31.16,
      "learning_rate": 8.441904165361729e-05,
      "loss": 1.1049,
      "step": 199000
    },
    {
      "epoch": 31.24,
      "learning_rate": 8.437989351706859e-05,
      "loss": 1.0975,
      "step": 199500
    },
    {
      "epoch": 31.32,
      "learning_rate": 8.434074538051989e-05,
      "loss": 1.087,
      "step": 200000
    },
    {
      "epoch": 31.4,
      "learning_rate": 8.430159724397119e-05,
      "loss": 1.0874,
      "step": 200500
    },
    {
      "epoch": 31.48,
      "learning_rate": 8.426244910742249e-05,
      "loss": 1.0964,
      "step": 201000
    },
    {
      "epoch": 31.55,
      "learning_rate": 8.422330097087379e-05,
      "loss": 1.1011,
      "step": 201500
    },
    {
      "epoch": 31.63,
      "learning_rate": 8.418415283432509e-05,
      "loss": 1.0993,
      "step": 202000
    },
    {
      "epoch": 31.71,
      "learning_rate": 8.414500469777639e-05,
      "loss": 1.0883,
      "step": 202500
    },
    {
      "epoch": 31.79,
      "learning_rate": 8.410585656122769e-05,
      "loss": 1.1093,
      "step": 203000
    },
    {
      "epoch": 31.87,
      "learning_rate": 8.406670842467899e-05,
      "loss": 1.1112,
      "step": 203500
    },
    {
      "epoch": 31.94,
      "learning_rate": 8.402756028813029e-05,
      "loss": 1.0768,
      "step": 204000
    },
    {
      "epoch": 32.0,
      "eval_loss": 1.0360960960388184,
      "eval_r": 0.6112610101699829,
      "eval_runtime": 27.4629,
      "eval_samples_per_second": 57.969,
      "eval_steps_per_second": 57.969,
      "step": 204352
    },
    {
      "epoch": 32.02,
      "learning_rate": 8.398841215158159e-05,
      "loss": 1.1144,
      "step": 204500
    },
    {
      "epoch": 32.1,
      "learning_rate": 8.394926401503289e-05,
      "loss": 1.0889,
      "step": 205000
    },
    {
      "epoch": 32.18,
      "learning_rate": 8.391011587848419e-05,
      "loss": 1.1067,
      "step": 205500
    },
    {
      "epoch": 32.26,
      "learning_rate": 8.387096774193549e-05,
      "loss": 1.0751,
      "step": 206000
    },
    {
      "epoch": 32.34,
      "learning_rate": 8.383181960538679e-05,
      "loss": 1.0954,
      "step": 206500
    },
    {
      "epoch": 32.41,
      "learning_rate": 8.379267146883809e-05,
      "loss": 1.0966,
      "step": 207000
    },
    {
      "epoch": 32.49,
      "learning_rate": 8.375352333228939e-05,
      "loss": 1.0868,
      "step": 207500
    },
    {
      "epoch": 32.57,
      "learning_rate": 8.371437519574069e-05,
      "loss": 1.1002,
      "step": 208000
    },
    {
      "epoch": 32.65,
      "learning_rate": 8.367522705919198e-05,
      "loss": 1.1048,
      "step": 208500
    },
    {
      "epoch": 32.73,
      "learning_rate": 8.363607892264329e-05,
      "loss": 1.1046,
      "step": 209000
    },
    {
      "epoch": 32.81,
      "learning_rate": 8.359693078609458e-05,
      "loss": 1.1016,
      "step": 209500
    },
    {
      "epoch": 32.88,
      "learning_rate": 8.355778264954589e-05,
      "loss": 1.1085,
      "step": 210000
    },
    {
      "epoch": 32.96,
      "learning_rate": 8.351863451299718e-05,
      "loss": 1.0949,
      "step": 210500
    },
    {
      "epoch": 33.0,
      "eval_loss": 1.043012022972107,
      "eval_r": 0.6089126467704773,
      "eval_runtime": 27.6221,
      "eval_samples_per_second": 57.635,
      "eval_steps_per_second": 57.635,
      "step": 210738
    },
    {
      "epoch": 33.04,
      "learning_rate": 8.34794863764485e-05,
      "loss": 1.0798,
      "step": 211000
    },
    {
      "epoch": 33.12,
      "learning_rate": 8.344033823989978e-05,
      "loss": 1.0918,
      "step": 211500
    },
    {
      "epoch": 33.2,
      "learning_rate": 8.340119010335108e-05,
      "loss": 1.1051,
      "step": 212000
    },
    {
      "epoch": 33.28,
      "learning_rate": 8.336204196680238e-05,
      "loss": 1.0968,
      "step": 212500
    },
    {
      "epoch": 33.35,
      "learning_rate": 8.332289383025368e-05,
      "loss": 1.0988,
      "step": 213000
    },
    {
      "epoch": 33.43,
      "learning_rate": 8.328374569370498e-05,
      "loss": 1.0737,
      "step": 213500
    },
    {
      "epoch": 33.51,
      "learning_rate": 8.324459755715628e-05,
      "loss": 1.0911,
      "step": 214000
    },
    {
      "epoch": 33.59,
      "learning_rate": 8.320544942060758e-05,
      "loss": 1.0903,
      "step": 214500
    },
    {
      "epoch": 33.67,
      "learning_rate": 8.316630128405888e-05,
      "loss": 1.0963,
      "step": 215000
    },
    {
      "epoch": 33.75,
      "learning_rate": 8.312715314751018e-05,
      "loss": 1.0811,
      "step": 215500
    },
    {
      "epoch": 33.82,
      "learning_rate": 8.308800501096148e-05,
      "loss": 1.1119,
      "step": 216000
    },
    {
      "epoch": 33.9,
      "learning_rate": 8.304885687441278e-05,
      "loss": 1.1218,
      "step": 216500
    },
    {
      "epoch": 33.98,
      "learning_rate": 8.300970873786408e-05,
      "loss": 1.0858,
      "step": 217000
    },
    {
      "epoch": 34.0,
      "eval_loss": 1.0334378480911255,
      "eval_r": 0.6117669343948364,
      "eval_runtime": 28.0926,
      "eval_samples_per_second": 56.67,
      "eval_steps_per_second": 56.67,
      "step": 217124
    },
    {
      "epoch": 34.06,
      "learning_rate": 8.297056060131538e-05,
      "loss": 1.0765,
      "step": 217500
    },
    {
      "epoch": 34.14,
      "learning_rate": 8.293141246476668e-05,
      "loss": 1.0883,
      "step": 218000
    },
    {
      "epoch": 34.22,
      "learning_rate": 8.289226432821798e-05,
      "loss": 1.0928,
      "step": 218500
    },
    {
      "epoch": 34.29,
      "learning_rate": 8.285311619166928e-05,
      "loss": 1.1093,
      "step": 219000
    },
    {
      "epoch": 34.37,
      "learning_rate": 8.281396805512058e-05,
      "loss": 1.0847,
      "step": 219500
    },
    {
      "epoch": 34.45,
      "learning_rate": 8.277481991857188e-05,
      "loss": 1.0904,
      "step": 220000
    },
    {
      "epoch": 34.53,
      "learning_rate": 8.273567178202318e-05,
      "loss": 1.0851,
      "step": 220500
    },
    {
      "epoch": 34.61,
      "learning_rate": 8.269652364547447e-05,
      "loss": 1.0727,
      "step": 221000
    },
    {
      "epoch": 34.69,
      "learning_rate": 8.265737550892578e-05,
      "loss": 1.0775,
      "step": 221500
    },
    {
      "epoch": 34.76,
      "learning_rate": 8.261822737237707e-05,
      "loss": 1.1135,
      "step": 222000
    },
    {
      "epoch": 34.84,
      "learning_rate": 8.257907923582839e-05,
      "loss": 1.0997,
      "step": 222500
    },
    {
      "epoch": 34.92,
      "learning_rate": 8.253993109927967e-05,
      "loss": 1.0986,
      "step": 223000
    },
    {
      "epoch": 35.0,
      "learning_rate": 8.250078296273099e-05,
      "loss": 1.0993,
      "step": 223500
    },
    {
      "epoch": 35.0,
      "eval_loss": 1.036948323249817,
      "eval_r": 0.6122395992279053,
      "eval_runtime": 27.5529,
      "eval_samples_per_second": 57.78,
      "eval_steps_per_second": 57.78,
      "step": 223510
    },
    {
      "epoch": 35.08,
      "learning_rate": 8.246163482618227e-05,
      "loss": 1.0851,
      "step": 224000
    },
    {
      "epoch": 35.16,
      "learning_rate": 8.242248668963359e-05,
      "loss": 1.0862,
      "step": 224500
    },
    {
      "epoch": 35.23,
      "learning_rate": 8.238333855308487e-05,
      "loss": 1.107,
      "step": 225000
    },
    {
      "epoch": 35.31,
      "learning_rate": 8.234419041653619e-05,
      "loss": 1.0851,
      "step": 225500
    },
    {
      "epoch": 35.39,
      "learning_rate": 8.230504227998747e-05,
      "loss": 1.094,
      "step": 226000
    },
    {
      "epoch": 35.47,
      "learning_rate": 8.226589414343877e-05,
      "loss": 1.09,
      "step": 226500
    },
    {
      "epoch": 35.55,
      "learning_rate": 8.222674600689007e-05,
      "loss": 1.0863,
      "step": 227000
    },
    {
      "epoch": 35.62,
      "learning_rate": 8.218759787034137e-05,
      "loss": 1.0997,
      "step": 227500
    },
    {
      "epoch": 35.7,
      "learning_rate": 8.214844973379267e-05,
      "loss": 1.0994,
      "step": 228000
    },
    {
      "epoch": 35.78,
      "learning_rate": 8.210930159724397e-05,
      "loss": 1.0749,
      "step": 228500
    },
    {
      "epoch": 35.86,
      "learning_rate": 8.207015346069527e-05,
      "loss": 1.0997,
      "step": 229000
    },
    {
      "epoch": 35.94,
      "learning_rate": 8.203100532414657e-05,
      "loss": 1.088,
      "step": 229500
    },
    {
      "epoch": 36.0,
      "eval_loss": 1.0341216325759888,
      "eval_r": 0.6123219132423401,
      "eval_runtime": 27.2643,
      "eval_samples_per_second": 58.391,
      "eval_steps_per_second": 58.391,
      "step": 229896
    },
    {
      "epoch": 36.02,
      "learning_rate": 8.199185718759787e-05,
      "loss": 1.0814,
      "step": 230000
    },
    {
      "epoch": 36.09,
      "learning_rate": 8.195270905104917e-05,
      "loss": 1.0878,
      "step": 230500
    },
    {
      "epoch": 36.17,
      "learning_rate": 8.191356091450048e-05,
      "loss": 1.087,
      "step": 231000
    },
    {
      "epoch": 36.25,
      "learning_rate": 8.187441277795178e-05,
      "loss": 1.0736,
      "step": 231500
    },
    {
      "epoch": 36.33,
      "learning_rate": 8.183526464140308e-05,
      "loss": 1.079,
      "step": 232000
    },
    {
      "epoch": 36.41,
      "learning_rate": 8.179611650485438e-05,
      "loss": 1.0968,
      "step": 232500
    },
    {
      "epoch": 36.49,
      "learning_rate": 8.175696836830568e-05,
      "loss": 1.0852,
      "step": 233000
    },
    {
      "epoch": 36.56,
      "learning_rate": 8.171782023175698e-05,
      "loss": 1.0904,
      "step": 233500
    },
    {
      "epoch": 36.64,
      "learning_rate": 8.167867209520828e-05,
      "loss": 1.1069,
      "step": 234000
    },
    {
      "epoch": 36.72,
      "learning_rate": 8.163952395865956e-05,
      "loss": 1.0794,
      "step": 234500
    },
    {
      "epoch": 36.8,
      "learning_rate": 8.160037582211088e-05,
      "loss": 1.0937,
      "step": 235000
    },
    {
      "epoch": 36.88,
      "learning_rate": 8.156122768556216e-05,
      "loss": 1.0981,
      "step": 235500
    },
    {
      "epoch": 36.96,
      "learning_rate": 8.152207954901348e-05,
      "loss": 1.0838,
      "step": 236000
    },
    {
      "epoch": 37.0,
      "eval_loss": 1.034777283668518,
      "eval_r": 0.612538754940033,
      "eval_runtime": 27.5885,
      "eval_samples_per_second": 57.705,
      "eval_steps_per_second": 57.705,
      "step": 236282
    },
    {
      "epoch": 37.03,
      "learning_rate": 8.148293141246476e-05,
      "loss": 1.0915,
      "step": 236500
    },
    {
      "epoch": 37.11,
      "learning_rate": 8.144378327591608e-05,
      "loss": 1.0899,
      "step": 237000
    },
    {
      "epoch": 37.19,
      "learning_rate": 8.140463513936736e-05,
      "loss": 1.0798,
      "step": 237500
    },
    {
      "epoch": 37.27,
      "learning_rate": 8.136548700281868e-05,
      "loss": 1.0768,
      "step": 238000
    },
    {
      "epoch": 37.35,
      "learning_rate": 8.132633886626996e-05,
      "loss": 1.0805,
      "step": 238500
    },
    {
      "epoch": 37.43,
      "learning_rate": 8.128719072972128e-05,
      "loss": 1.0688,
      "step": 239000
    },
    {
      "epoch": 37.5,
      "learning_rate": 8.124804259317257e-05,
      "loss": 1.0991,
      "step": 239500
    },
    {
      "epoch": 37.58,
      "learning_rate": 8.120889445662388e-05,
      "loss": 1.0708,
      "step": 240000
    },
    {
      "epoch": 37.66,
      "learning_rate": 8.116974632007517e-05,
      "loss": 1.1021,
      "step": 240500
    },
    {
      "epoch": 37.74,
      "learning_rate": 8.113059818352647e-05,
      "loss": 1.0926,
      "step": 241000
    },
    {
      "epoch": 37.82,
      "learning_rate": 8.109145004697777e-05,
      "loss": 1.0803,
      "step": 241500
    },
    {
      "epoch": 37.9,
      "learning_rate": 8.105230191042907e-05,
      "loss": 1.0839,
      "step": 242000
    },
    {
      "epoch": 37.97,
      "learning_rate": 8.101315377388037e-05,
      "loss": 1.095,
      "step": 242500
    },
    {
      "epoch": 38.0,
      "eval_loss": 1.039628505706787,
      "eval_r": 0.6090543866157532,
      "eval_runtime": 27.2195,
      "eval_samples_per_second": 58.487,
      "eval_steps_per_second": 58.487,
      "step": 242668
    },
    {
      "epoch": 38.05,
      "learning_rate": 8.097400563733167e-05,
      "loss": 1.1029,
      "step": 243000
    },
    {
      "epoch": 38.13,
      "learning_rate": 8.093485750078297e-05,
      "loss": 1.0762,
      "step": 243500
    },
    {
      "epoch": 38.21,
      "learning_rate": 8.089570936423427e-05,
      "loss": 1.083,
      "step": 244000
    },
    {
      "epoch": 38.29,
      "learning_rate": 8.085656122768557e-05,
      "loss": 1.0828,
      "step": 244500
    },
    {
      "epoch": 38.37,
      "learning_rate": 8.081741309113687e-05,
      "loss": 1.0834,
      "step": 245000
    },
    {
      "epoch": 38.44,
      "learning_rate": 8.077826495458817e-05,
      "loss": 1.0998,
      "step": 245500
    },
    {
      "epoch": 38.52,
      "learning_rate": 8.073911681803947e-05,
      "loss": 1.1037,
      "step": 246000
    },
    {
      "epoch": 38.6,
      "learning_rate": 8.069996868149077e-05,
      "loss": 1.0808,
      "step": 246500
    },
    {
      "epoch": 38.68,
      "learning_rate": 8.066082054494206e-05,
      "loss": 1.0944,
      "step": 247000
    },
    {
      "epoch": 38.76,
      "learning_rate": 8.062167240839337e-05,
      "loss": 1.0794,
      "step": 247500
    },
    {
      "epoch": 38.83,
      "learning_rate": 8.058252427184466e-05,
      "loss": 1.0745,
      "step": 248000
    },
    {
      "epoch": 38.91,
      "learning_rate": 8.054337613529597e-05,
      "loss": 1.0812,
      "step": 248500
    },
    {
      "epoch": 38.99,
      "learning_rate": 8.050422799874726e-05,
      "loss": 1.0777,
      "step": 249000
    },
    {
      "epoch": 39.0,
      "eval_loss": 1.0349012613296509,
      "eval_r": 0.6123341917991638,
      "eval_runtime": 27.7589,
      "eval_samples_per_second": 57.351,
      "eval_steps_per_second": 57.351,
      "step": 249054
    },
    {
      "epoch": 39.07,
      "learning_rate": 8.046507986219857e-05,
      "loss": 1.0866,
      "step": 249500
    },
    {
      "epoch": 39.15,
      "learning_rate": 8.042593172564986e-05,
      "loss": 1.0703,
      "step": 250000
    },
    {
      "epoch": 39.23,
      "learning_rate": 8.038678358910117e-05,
      "loss": 1.1173,
      "step": 250500
    },
    {
      "epoch": 39.3,
      "learning_rate": 8.034763545255246e-05,
      "loss": 1.0883,
      "step": 251000
    },
    {
      "epoch": 39.38,
      "learning_rate": 8.030848731600377e-05,
      "loss": 1.1091,
      "step": 251500
    },
    {
      "epoch": 39.46,
      "learning_rate": 8.026933917945506e-05,
      "loss": 1.0655,
      "step": 252000
    },
    {
      "epoch": 39.54,
      "learning_rate": 8.023019104290637e-05,
      "loss": 1.0794,
      "step": 252500
    },
    {
      "epoch": 39.62,
      "learning_rate": 8.019104290635766e-05,
      "loss": 1.0774,
      "step": 253000
    },
    {
      "epoch": 39.7,
      "learning_rate": 8.015189476980897e-05,
      "loss": 1.0878,
      "step": 253500
    },
    {
      "epoch": 39.77,
      "learning_rate": 8.011274663326026e-05,
      "loss": 1.0948,
      "step": 254000
    },
    {
      "epoch": 39.85,
      "learning_rate": 8.007359849671156e-05,
      "loss": 1.0746,
      "step": 254500
    },
    {
      "epoch": 39.93,
      "learning_rate": 8.003445036016286e-05,
      "loss": 1.0798,
      "step": 255000
    },
    {
      "epoch": 40.0,
      "eval_loss": 1.0312418937683105,
      "eval_r": 0.6129531860351562,
      "eval_runtime": 27.4453,
      "eval_samples_per_second": 58.006,
      "eval_steps_per_second": 58.006,
      "step": 255440
    },
    {
      "epoch": 40.01,
      "learning_rate": 7.999530222361416e-05,
      "loss": 1.0635,
      "step": 255500
    },
    {
      "epoch": 40.09,
      "learning_rate": 7.995615408706546e-05,
      "loss": 1.0807,
      "step": 256000
    },
    {
      "epoch": 40.17,
      "learning_rate": 7.991700595051676e-05,
      "loss": 1.0505,
      "step": 256500
    },
    {
      "epoch": 40.24,
      "learning_rate": 7.987785781396806e-05,
      "loss": 1.0903,
      "step": 257000
    },
    {
      "epoch": 40.32,
      "learning_rate": 7.983870967741936e-05,
      "loss": 1.0877,
      "step": 257500
    },
    {
      "epoch": 40.4,
      "learning_rate": 7.979956154087066e-05,
      "loss": 1.098,
      "step": 258000
    },
    {
      "epoch": 40.48,
      "learning_rate": 7.976041340432196e-05,
      "loss": 1.0725,
      "step": 258500
    },
    {
      "epoch": 40.56,
      "learning_rate": 7.972126526777326e-05,
      "loss": 1.0835,
      "step": 259000
    },
    {
      "epoch": 40.64,
      "learning_rate": 7.968211713122456e-05,
      "loss": 1.0658,
      "step": 259500
    },
    {
      "epoch": 40.71,
      "learning_rate": 7.964296899467586e-05,
      "loss": 1.0834,
      "step": 260000
    },
    {
      "epoch": 40.79,
      "learning_rate": 7.960382085812715e-05,
      "loss": 1.0827,
      "step": 260500
    },
    {
      "epoch": 40.87,
      "learning_rate": 7.956467272157846e-05,
      "loss": 1.0916,
      "step": 261000
    },
    {
      "epoch": 40.95,
      "learning_rate": 7.952552458502975e-05,
      "loss": 1.0798,
      "step": 261500
    },
    {
      "epoch": 41.0,
      "eval_loss": 1.0385783910751343,
      "eval_r": 0.6105376482009888,
      "eval_runtime": 28.0667,
      "eval_samples_per_second": 56.722,
      "eval_steps_per_second": 56.722,
      "step": 261826
    },
    {
      "epoch": 41.03,
      "learning_rate": 7.948637644848106e-05,
      "loss": 1.0842,
      "step": 262000
    },
    {
      "epoch": 41.11,
      "learning_rate": 7.944722831193235e-05,
      "loss": 1.0912,
      "step": 262500
    },
    {
      "epoch": 41.18,
      "learning_rate": 7.940808017538366e-05,
      "loss": 1.0782,
      "step": 263000
    },
    {
      "epoch": 41.26,
      "learning_rate": 7.936893203883495e-05,
      "loss": 1.0844,
      "step": 263500
    },
    {
      "epoch": 41.34,
      "learning_rate": 7.932978390228626e-05,
      "loss": 1.0745,
      "step": 264000
    },
    {
      "epoch": 41.42,
      "learning_rate": 7.929063576573755e-05,
      "loss": 1.0657,
      "step": 264500
    },
    {
      "epoch": 41.5,
      "learning_rate": 7.925148762918886e-05,
      "loss": 1.0829,
      "step": 265000
    },
    {
      "epoch": 41.58,
      "learning_rate": 7.921233949264015e-05,
      "loss": 1.0903,
      "step": 265500
    },
    {
      "epoch": 41.65,
      "learning_rate": 7.917319135609146e-05,
      "loss": 1.0739,
      "step": 266000
    },
    {
      "epoch": 41.73,
      "learning_rate": 7.913404321954275e-05,
      "loss": 1.0919,
      "step": 266500
    },
    {
      "epoch": 41.81,
      "learning_rate": 7.909489508299406e-05,
      "loss": 1.0877,
      "step": 267000
    },
    {
      "epoch": 41.89,
      "learning_rate": 7.905574694644535e-05,
      "loss": 1.0825,
      "step": 267500
    },
    {
      "epoch": 41.97,
      "learning_rate": 7.901659880989666e-05,
      "loss": 1.0747,
      "step": 268000
    },
    {
      "epoch": 42.0,
      "eval_loss": 1.036248803138733,
      "eval_r": 0.6120827198028564,
      "eval_runtime": 28.1523,
      "eval_samples_per_second": 56.549,
      "eval_steps_per_second": 56.549,
      "step": 268212
    },
    {
      "epoch": 42.05,
      "learning_rate": 7.897745067334795e-05,
      "loss": 1.0722,
      "step": 268500
    },
    {
      "epoch": 42.12,
      "learning_rate": 7.893830253679925e-05,
      "loss": 1.0686,
      "step": 269000
    },
    {
      "epoch": 42.2,
      "learning_rate": 7.889915440025055e-05,
      "loss": 1.0925,
      "step": 269500
    },
    {
      "epoch": 42.28,
      "learning_rate": 7.886000626370185e-05,
      "loss": 1.0642,
      "step": 270000
    },
    {
      "epoch": 42.36,
      "learning_rate": 7.882085812715315e-05,
      "loss": 1.0746,
      "step": 270500
    },
    {
      "epoch": 42.44,
      "learning_rate": 7.878170999060445e-05,
      "loss": 1.056,
      "step": 271000
    },
    {
      "epoch": 42.51,
      "learning_rate": 7.874256185405575e-05,
      "loss": 1.0548,
      "step": 271500
    },
    {
      "epoch": 42.59,
      "learning_rate": 7.870341371750705e-05,
      "loss": 1.0877,
      "step": 272000
    },
    {
      "epoch": 42.67,
      "learning_rate": 7.866426558095835e-05,
      "loss": 1.0786,
      "step": 272500
    },
    {
      "epoch": 42.75,
      "learning_rate": 7.862511744440965e-05,
      "loss": 1.0634,
      "step": 273000
    },
    {
      "epoch": 42.83,
      "learning_rate": 7.858596930786095e-05,
      "loss": 1.0778,
      "step": 273500
    },
    {
      "epoch": 42.91,
      "learning_rate": 7.854682117131224e-05,
      "loss": 1.0963,
      "step": 274000
    },
    {
      "epoch": 42.98,
      "learning_rate": 7.850767303476355e-05,
      "loss": 1.0973,
      "step": 274500
    },
    {
      "epoch": 43.0,
      "eval_loss": 1.038066029548645,
      "eval_r": 0.6123140454292297,
      "eval_runtime": 28.4037,
      "eval_samples_per_second": 56.049,
      "eval_steps_per_second": 56.049,
      "step": 274598
    },
    {
      "epoch": 43.06,
      "learning_rate": 7.846852489821484e-05,
      "loss": 1.0811,
      "step": 275000
    },
    {
      "epoch": 43.14,
      "learning_rate": 7.842937676166615e-05,
      "loss": 1.0623,
      "step": 275500
    },
    {
      "epoch": 43.22,
      "learning_rate": 7.839022862511744e-05,
      "loss": 1.0672,
      "step": 276000
    },
    {
      "epoch": 43.3,
      "learning_rate": 7.835108048856875e-05,
      "loss": 1.0805,
      "step": 276500
    },
    {
      "epoch": 43.38,
      "learning_rate": 7.831193235202004e-05,
      "loss": 1.0887,
      "step": 277000
    },
    {
      "epoch": 43.45,
      "learning_rate": 7.827278421547135e-05,
      "loss": 1.0851,
      "step": 277500
    },
    {
      "epoch": 43.53,
      "learning_rate": 7.823363607892264e-05,
      "loss": 1.0951,
      "step": 278000
    },
    {
      "epoch": 43.61,
      "learning_rate": 7.819448794237396e-05,
      "loss": 1.0686,
      "step": 278500
    },
    {
      "epoch": 43.69,
      "learning_rate": 7.815533980582524e-05,
      "loss": 1.0825,
      "step": 279000
    },
    {
      "epoch": 43.77,
      "learning_rate": 7.811619166927656e-05,
      "loss": 1.072,
      "step": 279500
    },
    {
      "epoch": 43.85,
      "learning_rate": 7.807704353272784e-05,
      "loss": 1.0734,
      "step": 280000
    },
    {
      "epoch": 43.92,
      "learning_rate": 7.803789539617916e-05,
      "loss": 1.0832,
      "step": 280500
    },
    {
      "epoch": 44.0,
      "eval_loss": 1.0312795639038086,
      "eval_r": 0.614341139793396,
      "eval_runtime": 27.8813,
      "eval_samples_per_second": 57.099,
      "eval_steps_per_second": 57.099,
      "step": 280984
    },
    {
      "epoch": 44.0,
      "learning_rate": 7.799874725963044e-05,
      "loss": 1.0683,
      "step": 281000
    },
    {
      "epoch": 44.08,
      "learning_rate": 7.795959912308176e-05,
      "loss": 1.0624,
      "step": 281500
    },
    {
      "epoch": 44.16,
      "learning_rate": 7.792045098653304e-05,
      "loss": 1.0765,
      "step": 282000
    },
    {
      "epoch": 44.24,
      "learning_rate": 7.788130284998434e-05,
      "loss": 1.0792,
      "step": 282500
    },
    {
      "epoch": 44.32,
      "learning_rate": 7.784215471343564e-05,
      "loss": 1.0864,
      "step": 283000
    },
    {
      "epoch": 44.39,
      "learning_rate": 7.780300657688694e-05,
      "loss": 1.0835,
      "step": 283500
    },
    {
      "epoch": 44.47,
      "learning_rate": 7.776385844033824e-05,
      "loss": 1.0768,
      "step": 284000
    },
    {
      "epoch": 44.55,
      "learning_rate": 7.772471030378954e-05,
      "loss": 1.0782,
      "step": 284500
    },
    {
      "epoch": 44.63,
      "learning_rate": 7.768556216724084e-05,
      "loss": 1.0615,
      "step": 285000
    },
    {
      "epoch": 44.71,
      "learning_rate": 7.764641403069214e-05,
      "loss": 1.0785,
      "step": 285500
    },
    {
      "epoch": 44.79,
      "learning_rate": 7.760726589414344e-05,
      "loss": 1.0807,
      "step": 286000
    },
    {
      "epoch": 44.86,
      "learning_rate": 7.756811775759473e-05,
      "loss": 1.0732,
      "step": 286500
    },
    {
      "epoch": 44.94,
      "learning_rate": 7.752896962104605e-05,
      "loss": 1.0615,
      "step": 287000
    },
    {
      "epoch": 45.0,
      "eval_loss": 1.0352685451507568,
      "eval_r": 0.6117385625839233,
      "eval_runtime": 27.9797,
      "eval_samples_per_second": 56.898,
      "eval_steps_per_second": 56.898,
      "step": 287370
    },
    {
      "epoch": 45.02,
      "learning_rate": 7.748982148449733e-05,
      "loss": 1.0841,
      "step": 287500
    },
    {
      "epoch": 45.1,
      "learning_rate": 7.745067334794865e-05,
      "loss": 1.0736,
      "step": 288000
    },
    {
      "epoch": 45.18,
      "learning_rate": 7.741152521139993e-05,
      "loss": 1.0609,
      "step": 288500
    },
    {
      "epoch": 45.26,
      "learning_rate": 7.737237707485125e-05,
      "loss": 1.0864,
      "step": 289000
    },
    {
      "epoch": 45.33,
      "learning_rate": 7.733322893830253e-05,
      "loss": 1.0803,
      "step": 289500
    },
    {
      "epoch": 45.41,
      "learning_rate": 7.729408080175385e-05,
      "loss": 1.0616,
      "step": 290000
    },
    {
      "epoch": 45.49,
      "learning_rate": 7.725493266520513e-05,
      "loss": 1.0511,
      "step": 290500
    },
    {
      "epoch": 45.57,
      "learning_rate": 7.721578452865645e-05,
      "loss": 1.0828,
      "step": 291000
    },
    {
      "epoch": 45.65,
      "learning_rate": 7.717663639210773e-05,
      "loss": 1.0857,
      "step": 291500
    },
    {
      "epoch": 45.73,
      "learning_rate": 7.713748825555905e-05,
      "loss": 1.0652,
      "step": 292000
    },
    {
      "epoch": 45.8,
      "learning_rate": 7.709834011901033e-05,
      "loss": 1.073,
      "step": 292500
    },
    {
      "epoch": 45.88,
      "learning_rate": 7.705919198246165e-05,
      "loss": 1.0754,
      "step": 293000
    },
    {
      "epoch": 45.96,
      "learning_rate": 7.702004384591293e-05,
      "loss": 1.0778,
      "step": 293500
    },
    {
      "epoch": 46.0,
      "eval_loss": 1.0392106771469116,
      "eval_r": 0.6103735566139221,
      "eval_runtime": 27.785,
      "eval_samples_per_second": 57.297,
      "eval_steps_per_second": 57.297,
      "step": 293756
    },
    {
      "epoch": 46.04,
      "learning_rate": 7.698089570936425e-05,
      "loss": 1.0734,
      "step": 294000
    },
    {
      "epoch": 46.12,
      "learning_rate": 7.694174757281554e-05,
      "loss": 1.0719,
      "step": 294500
    },
    {
      "epoch": 46.19,
      "learning_rate": 7.690259943626685e-05,
      "loss": 1.0742,
      "step": 295000
    },
    {
      "epoch": 46.27,
      "learning_rate": 7.686345129971814e-05,
      "loss": 1.0722,
      "step": 295500
    },
    {
      "epoch": 46.35,
      "learning_rate": 7.682430316316944e-05,
      "loss": 1.061,
      "step": 296000
    },
    {
      "epoch": 46.43,
      "learning_rate": 7.678515502662074e-05,
      "loss": 1.0691,
      "step": 296500
    },
    {
      "epoch": 46.51,
      "learning_rate": 7.674600689007204e-05,
      "loss": 1.0542,
      "step": 297000
    },
    {
      "epoch": 46.59,
      "learning_rate": 7.670685875352334e-05,
      "loss": 1.0972,
      "step": 297500
    },
    {
      "epoch": 46.66,
      "learning_rate": 7.666771061697464e-05,
      "loss": 1.0762,
      "step": 298000
    },
    {
      "epoch": 46.74,
      "learning_rate": 7.662856248042594e-05,
      "loss": 1.0606,
      "step": 298500
    },
    {
      "epoch": 46.82,
      "learning_rate": 7.658941434387724e-05,
      "loss": 1.0748,
      "step": 299000
    },
    {
      "epoch": 46.9,
      "learning_rate": 7.655026620732854e-05,
      "loss": 1.0857,
      "step": 299500
    },
    {
      "epoch": 46.98,
      "learning_rate": 7.651111807077982e-05,
      "loss": 1.0718,
      "step": 300000
    },
    {
      "epoch": 47.0,
      "eval_loss": 1.0377967357635498,
      "eval_r": 0.6115450263023376,
      "eval_runtime": 27.5511,
      "eval_samples_per_second": 57.784,
      "eval_steps_per_second": 57.784,
      "step": 300142
    },
    {
      "epoch": 47.06,
      "learning_rate": 7.647196993423114e-05,
      "loss": 1.0684,
      "step": 300500
    },
    {
      "epoch": 47.13,
      "learning_rate": 7.643282179768242e-05,
      "loss": 1.0742,
      "step": 301000
    },
    {
      "epoch": 47.21,
      "learning_rate": 7.639367366113374e-05,
      "loss": 1.0589,
      "step": 301500
    },
    {
      "epoch": 47.29,
      "learning_rate": 7.635452552458502e-05,
      "loss": 1.0597,
      "step": 302000
    },
    {
      "epoch": 47.37,
      "learning_rate": 7.631537738803634e-05,
      "loss": 1.0766,
      "step": 302500
    },
    {
      "epoch": 47.45,
      "learning_rate": 7.627622925148763e-05,
      "loss": 1.0653,
      "step": 303000
    },
    {
      "epoch": 47.53,
      "learning_rate": 7.623708111493894e-05,
      "loss": 1.0579,
      "step": 303500
    },
    {
      "epoch": 47.6,
      "learning_rate": 7.619793297839023e-05,
      "loss": 1.1006,
      "step": 304000
    },
    {
      "epoch": 47.68,
      "learning_rate": 7.615878484184154e-05,
      "loss": 1.0918,
      "step": 304500
    },
    {
      "epoch": 47.76,
      "learning_rate": 7.611963670529283e-05,
      "loss": 1.0568,
      "step": 305000
    },
    {
      "epoch": 47.84,
      "learning_rate": 7.608048856874414e-05,
      "loss": 1.0419,
      "step": 305500
    },
    {
      "epoch": 47.92,
      "learning_rate": 7.604134043219543e-05,
      "loss": 1.0877,
      "step": 306000
    },
    {
      "epoch": 48.0,
      "learning_rate": 7.600219229564674e-05,
      "loss": 1.0828,
      "step": 306500
    },
    {
      "epoch": 48.0,
      "eval_loss": 1.0350348949432373,
      "eval_r": 0.6115190982818604,
      "eval_runtime": 27.7316,
      "eval_samples_per_second": 57.407,
      "eval_steps_per_second": 57.407,
      "step": 306528
    },
    {
      "epoch": 48.07,
      "learning_rate": 7.596304415909803e-05,
      "loss": 1.0655,
      "step": 307000
    },
    {
      "epoch": 48.15,
      "learning_rate": 7.592389602254934e-05,
      "loss": 1.0786,
      "step": 307500
    },
    {
      "epoch": 48.23,
      "learning_rate": 7.588474788600063e-05,
      "loss": 1.0757,
      "step": 308000
    },
    {
      "epoch": 48.31,
      "learning_rate": 7.584559974945193e-05,
      "loss": 1.0547,
      "step": 308500
    },
    {
      "epoch": 48.39,
      "learning_rate": 7.580645161290323e-05,
      "loss": 1.078,
      "step": 309000
    },
    {
      "epoch": 48.47,
      "learning_rate": 7.576730347635453e-05,
      "loss": 1.0728,
      "step": 309500
    },
    {
      "epoch": 48.54,
      "learning_rate": 7.572815533980583e-05,
      "loss": 1.0683,
      "step": 310000
    },
    {
      "epoch": 48.62,
      "learning_rate": 7.568900720325713e-05,
      "loss": 1.0892,
      "step": 310500
    },
    {
      "epoch": 48.7,
      "learning_rate": 7.564985906670843e-05,
      "loss": 1.0529,
      "step": 311000
    },
    {
      "epoch": 48.78,
      "learning_rate": 7.561071093015973e-05,
      "loss": 1.0696,
      "step": 311500
    },
    {
      "epoch": 48.86,
      "learning_rate": 7.557156279361103e-05,
      "loss": 1.0588,
      "step": 312000
    },
    {
      "epoch": 48.94,
      "learning_rate": 7.553241465706232e-05,
      "loss": 1.0708,
      "step": 312500
    },
    {
      "epoch": 49.0,
      "eval_loss": 1.0333397388458252,
      "eval_r": 0.6133798956871033,
      "eval_runtime": 27.8064,
      "eval_samples_per_second": 57.253,
      "eval_steps_per_second": 57.253,
      "step": 312914
    },
    {
      "epoch": 49.01,
      "learning_rate": 7.549326652051363e-05,
      "loss": 1.0865,
      "step": 313000
    },
    {
      "epoch": 49.09,
      "learning_rate": 7.545411838396492e-05,
      "loss": 1.0733,
      "step": 313500
    },
    {
      "epoch": 49.17,
      "learning_rate": 7.541497024741623e-05,
      "loss": 1.0555,
      "step": 314000
    },
    {
      "epoch": 49.25,
      "learning_rate": 7.537582211086752e-05,
      "loss": 1.077,
      "step": 314500
    },
    {
      "epoch": 49.33,
      "learning_rate": 7.533667397431883e-05,
      "loss": 1.0715,
      "step": 315000
    },
    {
      "epoch": 49.4,
      "learning_rate": 7.529752583777012e-05,
      "loss": 1.0683,
      "step": 315500
    },
    {
      "epoch": 49.48,
      "learning_rate": 7.525837770122143e-05,
      "loss": 1.0562,
      "step": 316000
    },
    {
      "epoch": 49.56,
      "learning_rate": 7.521922956467272e-05,
      "loss": 1.0737,
      "step": 316500
    },
    {
      "epoch": 49.64,
      "learning_rate": 7.518008142812403e-05,
      "loss": 1.0439,
      "step": 317000
    },
    {
      "epoch": 49.72,
      "learning_rate": 7.514093329157532e-05,
      "loss": 1.0963,
      "step": 317500
    },
    {
      "epoch": 49.8,
      "learning_rate": 7.510178515502663e-05,
      "loss": 1.0762,
      "step": 318000
    },
    {
      "epoch": 49.87,
      "learning_rate": 7.506263701847792e-05,
      "loss": 1.0638,
      "step": 318500
    },
    {
      "epoch": 49.95,
      "learning_rate": 7.502348888192923e-05,
      "loss": 1.0842,
      "step": 319000
    },
    {
      "epoch": 50.0,
      "eval_loss": 1.0304536819458008,
      "eval_r": 0.6140138506889343,
      "eval_runtime": 27.3608,
      "eval_samples_per_second": 58.185,
      "eval_steps_per_second": 58.185,
      "step": 319300
    },
    {
      "epoch": 50.03,
      "learning_rate": 7.498434074538052e-05,
      "loss": 1.0516,
      "step": 319500
    },
    {
      "epoch": 50.11,
      "learning_rate": 7.494519260883183e-05,
      "loss": 1.0748,
      "step": 320000
    },
    {
      "epoch": 50.19,
      "learning_rate": 7.490604447228312e-05,
      "loss": 1.0475,
      "step": 320500
    },
    {
      "epoch": 50.27,
      "learning_rate": 7.486689633573443e-05,
      "loss": 1.0913,
      "step": 321000
    },
    {
      "epoch": 50.34,
      "learning_rate": 7.482774819918572e-05,
      "loss": 1.0676,
      "step": 321500
    },
    {
      "epoch": 50.42,
      "learning_rate": 7.478860006263702e-05,
      "loss": 1.0688,
      "step": 322000
    },
    {
      "epoch": 50.5,
      "learning_rate": 7.474945192608832e-05,
      "loss": 1.0511,
      "step": 322500
    },
    {
      "epoch": 50.58,
      "learning_rate": 7.471030378953962e-05,
      "loss": 1.0702,
      "step": 323000
    },
    {
      "epoch": 50.66,
      "learning_rate": 7.467115565299092e-05,
      "loss": 1.084,
      "step": 323500
    },
    {
      "epoch": 50.74,
      "learning_rate": 7.463200751644222e-05,
      "loss": 1.0647,
      "step": 324000
    },
    {
      "epoch": 50.81,
      "learning_rate": 7.459285937989352e-05,
      "loss": 1.0631,
      "step": 324500
    },
    {
      "epoch": 50.89,
      "learning_rate": 7.455371124334482e-05,
      "loss": 1.0557,
      "step": 325000
    },
    {
      "epoch": 50.97,
      "learning_rate": 7.451456310679612e-05,
      "loss": 1.0748,
      "step": 325500
    },
    {
      "epoch": 51.0,
      "eval_loss": 1.028967022895813,
      "eval_r": 0.6146112084388733,
      "eval_runtime": 27.4701,
      "eval_samples_per_second": 57.954,
      "eval_steps_per_second": 57.954,
      "step": 325686
    },
    {
      "epoch": 51.05,
      "learning_rate": 7.447541497024741e-05,
      "loss": 1.0543,
      "step": 326000
    },
    {
      "epoch": 51.13,
      "learning_rate": 7.443626683369872e-05,
      "loss": 1.0751,
      "step": 326500
    },
    {
      "epoch": 51.21,
      "learning_rate": 7.439711869715001e-05,
      "loss": 1.0563,
      "step": 327000
    },
    {
      "epoch": 51.28,
      "learning_rate": 7.435797056060132e-05,
      "loss": 1.0635,
      "step": 327500
    },
    {
      "epoch": 51.36,
      "learning_rate": 7.431882242405261e-05,
      "loss": 1.0733,
      "step": 328000
    },
    {
      "epoch": 51.44,
      "learning_rate": 7.427967428750392e-05,
      "loss": 1.0596,
      "step": 328500
    },
    {
      "epoch": 51.52,
      "learning_rate": 7.424052615095521e-05,
      "loss": 1.0906,
      "step": 329000
    },
    {
      "epoch": 51.6,
      "learning_rate": 7.420137801440652e-05,
      "loss": 1.0622,
      "step": 329500
    },
    {
      "epoch": 51.68,
      "learning_rate": 7.416222987785781e-05,
      "loss": 1.0655,
      "step": 330000
    },
    {
      "epoch": 51.75,
      "learning_rate": 7.412308174130912e-05,
      "loss": 1.0569,
      "step": 330500
    },
    {
      "epoch": 51.83,
      "learning_rate": 7.408393360476041e-05,
      "loss": 1.0695,
      "step": 331000
    },
    {
      "epoch": 51.91,
      "learning_rate": 7.404478546821172e-05,
      "loss": 1.0525,
      "step": 331500
    },
    {
      "epoch": 51.99,
      "learning_rate": 7.400563733166301e-05,
      "loss": 1.0788,
      "step": 332000
    },
    {
      "epoch": 52.0,
      "eval_loss": 1.0317579507827759,
      "eval_r": 0.6130781173706055,
      "eval_runtime": 27.8115,
      "eval_samples_per_second": 57.243,
      "eval_steps_per_second": 57.243,
      "step": 332072
    },
    {
      "epoch": 52.07,
      "learning_rate": 7.396648919511432e-05,
      "loss": 1.0578,
      "step": 332500
    },
    {
      "epoch": 52.15,
      "learning_rate": 7.392734105856561e-05,
      "loss": 1.0696,
      "step": 333000
    },
    {
      "epoch": 52.22,
      "learning_rate": 7.388819292201693e-05,
      "loss": 1.0619,
      "step": 333500
    },
    {
      "epoch": 52.3,
      "learning_rate": 7.384904478546821e-05,
      "loss": 1.0694,
      "step": 334000
    },
    {
      "epoch": 52.38,
      "learning_rate": 7.380989664891953e-05,
      "loss": 1.0711,
      "step": 334500
    },
    {
      "epoch": 52.46,
      "learning_rate": 7.377074851237081e-05,
      "loss": 1.0589,
      "step": 335000
    },
    {
      "epoch": 52.54,
      "learning_rate": 7.373160037582211e-05,
      "loss": 1.0729,
      "step": 335500
    },
    {
      "epoch": 52.62,
      "learning_rate": 7.369245223927341e-05,
      "loss": 1.0642,
      "step": 336000
    },
    {
      "epoch": 52.69,
      "learning_rate": 7.365330410272471e-05,
      "loss": 1.0759,
      "step": 336500
    },
    {
      "epoch": 52.77,
      "learning_rate": 7.361415596617601e-05,
      "loss": 1.0708,
      "step": 337000
    },
    {
      "epoch": 52.85,
      "learning_rate": 7.357500782962731e-05,
      "loss": 1.05,
      "step": 337500
    },
    {
      "epoch": 52.93,
      "learning_rate": 7.353585969307861e-05,
      "loss": 1.0667,
      "step": 338000
    },
    {
      "epoch": 53.0,
      "eval_loss": 1.0368711948394775,
      "eval_r": 0.6123631000518799,
      "eval_runtime": 27.3085,
      "eval_samples_per_second": 58.297,
      "eval_steps_per_second": 58.297,
      "step": 338458
    },
    {
      "epoch": 53.01,
      "learning_rate": 7.349671155652991e-05,
      "loss": 1.0381,
      "step": 338500
    },
    {
      "epoch": 53.08,
      "learning_rate": 7.345756341998121e-05,
      "loss": 1.064,
      "step": 339000
    },
    {
      "epoch": 53.16,
      "learning_rate": 7.34184152834325e-05,
      "loss": 1.0688,
      "step": 339500
    },
    {
      "epoch": 53.24,
      "learning_rate": 7.337926714688381e-05,
      "loss": 1.0605,
      "step": 340000
    },
    {
      "epoch": 53.32,
      "learning_rate": 7.33401190103351e-05,
      "loss": 1.0632,
      "step": 340500
    },
    {
      "epoch": 53.4,
      "learning_rate": 7.330097087378641e-05,
      "loss": 1.0526,
      "step": 341000
    },
    {
      "epoch": 53.48,
      "learning_rate": 7.32618227372377e-05,
      "loss": 1.0521,
      "step": 341500
    },
    {
      "epoch": 53.55,
      "learning_rate": 7.322267460068902e-05,
      "loss": 1.0755,
      "step": 342000
    },
    {
      "epoch": 53.63,
      "learning_rate": 7.31835264641403e-05,
      "loss": 1.0704,
      "step": 342500
    },
    {
      "epoch": 53.71,
      "learning_rate": 7.314437832759162e-05,
      "loss": 1.0628,
      "step": 343000
    },
    {
      "epoch": 53.79,
      "learning_rate": 7.31052301910429e-05,
      "loss": 1.0521,
      "step": 343500
    },
    {
      "epoch": 53.87,
      "learning_rate": 7.306608205449422e-05,
      "loss": 1.063,
      "step": 344000
    },
    {
      "epoch": 53.95,
      "learning_rate": 7.30269339179455e-05,
      "loss": 1.0556,
      "step": 344500
    },
    {
      "epoch": 54.0,
      "eval_loss": 1.0347251892089844,
      "eval_r": 0.6119822263717651,
      "eval_runtime": 27.3479,
      "eval_samples_per_second": 58.213,
      "eval_steps_per_second": 58.213,
      "step": 344844
    },
    {
      "epoch": 54.02,
      "learning_rate": 7.298778578139682e-05,
      "loss": 1.0892,
      "step": 345000
    },
    {
      "epoch": 54.1,
      "learning_rate": 7.29486376448481e-05,
      "loss": 1.0766,
      "step": 345500
    },
    {
      "epoch": 54.18,
      "learning_rate": 7.290948950829942e-05,
      "loss": 1.0645,
      "step": 346000
    },
    {
      "epoch": 54.26,
      "learning_rate": 7.28703413717507e-05,
      "loss": 1.0566,
      "step": 346500
    },
    {
      "epoch": 54.34,
      "learning_rate": 7.283119323520202e-05,
      "loss": 1.0553,
      "step": 347000
    },
    {
      "epoch": 54.42,
      "learning_rate": 7.27920450986533e-05,
      "loss": 1.0763,
      "step": 347500
    },
    {
      "epoch": 54.49,
      "learning_rate": 7.27528969621046e-05,
      "loss": 1.051,
      "step": 348000
    },
    {
      "epoch": 54.57,
      "learning_rate": 7.27137488255559e-05,
      "loss": 1.0475,
      "step": 348500
    },
    {
      "epoch": 54.65,
      "learning_rate": 7.26746006890072e-05,
      "loss": 1.0518,
      "step": 349000
    },
    {
      "epoch": 54.73,
      "learning_rate": 7.26354525524585e-05,
      "loss": 1.0537,
      "step": 349500
    },
    {
      "epoch": 54.81,
      "learning_rate": 7.25963044159098e-05,
      "loss": 1.0569,
      "step": 350000
    },
    {
      "epoch": 54.89,
      "learning_rate": 7.25571562793611e-05,
      "loss": 1.0695,
      "step": 350500
    },
    {
      "epoch": 54.96,
      "learning_rate": 7.25180081428124e-05,
      "loss": 1.0593,
      "step": 351000
    },
    {
      "epoch": 55.0,
      "eval_loss": 1.032891869544983,
      "eval_r": 0.6116704344749451,
      "eval_runtime": 27.472,
      "eval_samples_per_second": 57.95,
      "eval_steps_per_second": 57.95,
      "step": 351230
    },
    {
      "epoch": 55.04,
      "learning_rate": 7.24788600062637e-05,
      "loss": 1.0783,
      "step": 351500
    },
    {
      "epoch": 55.12,
      "learning_rate": 7.2439711869715e-05,
      "loss": 1.0499,
      "step": 352000
    },
    {
      "epoch": 55.2,
      "learning_rate": 7.24005637331663e-05,
      "loss": 1.0486,
      "step": 352500
    },
    {
      "epoch": 55.28,
      "learning_rate": 7.23614155966176e-05,
      "loss": 1.0635,
      "step": 353000
    },
    {
      "epoch": 55.36,
      "learning_rate": 7.23222674600689e-05,
      "loss": 1.0453,
      "step": 353500
    },
    {
      "epoch": 55.43,
      "learning_rate": 7.22831193235202e-05,
      "loss": 1.0625,
      "step": 354000
    },
    {
      "epoch": 55.51,
      "learning_rate": 7.224397118697151e-05,
      "loss": 1.0638,
      "step": 354500
    },
    {
      "epoch": 55.59,
      "learning_rate": 7.22048230504228e-05,
      "loss": 1.045,
      "step": 355000
    },
    {
      "epoch": 55.67,
      "learning_rate": 7.216567491387411e-05,
      "loss": 1.0639,
      "step": 355500
    },
    {
      "epoch": 55.75,
      "learning_rate": 7.21265267773254e-05,
      "loss": 1.0682,
      "step": 356000
    },
    {
      "epoch": 55.83,
      "learning_rate": 7.208737864077671e-05,
      "loss": 1.0767,
      "step": 356500
    },
    {
      "epoch": 55.9,
      "learning_rate": 7.2048230504228e-05,
      "loss": 1.056,
      "step": 357000
    },
    {
      "epoch": 55.98,
      "learning_rate": 7.200908236767931e-05,
      "loss": 1.0813,
      "step": 357500
    },
    {
      "epoch": 56.0,
      "eval_loss": 1.0359089374542236,
      "eval_r": 0.6128037571907043,
      "eval_runtime": 27.3097,
      "eval_samples_per_second": 58.294,
      "eval_steps_per_second": 58.294,
      "step": 357616
    },
    {
      "epoch": 56.06,
      "learning_rate": 7.19699342311306e-05,
      "loss": 1.0533,
      "step": 358000
    },
    {
      "epoch": 56.14,
      "learning_rate": 7.193078609458191e-05,
      "loss": 1.041,
      "step": 358500
    },
    {
      "epoch": 56.22,
      "learning_rate": 7.18916379580332e-05,
      "loss": 1.0609,
      "step": 359000
    },
    {
      "epoch": 56.3,
      "learning_rate": 7.185248982148451e-05,
      "loss": 1.0671,
      "step": 359500
    },
    {
      "epoch": 56.37,
      "learning_rate": 7.18133416849358e-05,
      "loss": 1.0601,
      "step": 360000
    },
    {
      "epoch": 56.45,
      "learning_rate": 7.177419354838711e-05,
      "loss": 1.0712,
      "step": 360500
    },
    {
      "epoch": 56.53,
      "learning_rate": 7.17350454118384e-05,
      "loss": 1.0734,
      "step": 361000
    },
    {
      "epoch": 56.61,
      "learning_rate": 7.16958972752897e-05,
      "loss": 1.0682,
      "step": 361500
    },
    {
      "epoch": 56.69,
      "learning_rate": 7.1656749138741e-05,
      "loss": 1.054,
      "step": 362000
    },
    {
      "epoch": 56.76,
      "learning_rate": 7.16176010021923e-05,
      "loss": 1.0668,
      "step": 362500
    },
    {
      "epoch": 56.84,
      "learning_rate": 7.15784528656436e-05,
      "loss": 1.0444,
      "step": 363000
    },
    {
      "epoch": 56.92,
      "learning_rate": 7.15393047290949e-05,
      "loss": 1.0587,
      "step": 363500
    },
    {
      "epoch": 57.0,
      "learning_rate": 7.15001565925462e-05,
      "loss": 1.0559,
      "step": 364000
    },
    {
      "epoch": 57.0,
      "eval_loss": 1.0324103832244873,
      "eval_r": 0.6124663352966309,
      "eval_runtime": 27.4673,
      "eval_samples_per_second": 57.96,
      "eval_steps_per_second": 57.96,
      "step": 364002
    },
    {
      "epoch": 57.08,
      "learning_rate": 7.14610084559975e-05,
      "loss": 1.0543,
      "step": 364500
    },
    {
      "epoch": 57.16,
      "learning_rate": 7.14218603194488e-05,
      "loss": 1.0644,
      "step": 365000
    },
    {
      "epoch": 57.23,
      "learning_rate": 7.13827121829001e-05,
      "loss": 1.0666,
      "step": 365500
    },
    {
      "epoch": 57.31,
      "learning_rate": 7.13435640463514e-05,
      "loss": 1.0527,
      "step": 366000
    },
    {
      "epoch": 57.39,
      "learning_rate": 7.13044159098027e-05,
      "loss": 1.0426,
      "step": 366500
    },
    {
      "epoch": 57.47,
      "learning_rate": 7.1265267773254e-05,
      "loss": 1.0511,
      "step": 367000
    },
    {
      "epoch": 57.55,
      "learning_rate": 7.122611963670529e-05,
      "loss": 1.0526,
      "step": 367500
    },
    {
      "epoch": 57.63,
      "learning_rate": 7.11869715001566e-05,
      "loss": 1.0629,
      "step": 368000
    },
    {
      "epoch": 57.7,
      "learning_rate": 7.114782336360789e-05,
      "loss": 1.0409,
      "step": 368500
    },
    {
      "epoch": 57.78,
      "learning_rate": 7.11086752270592e-05,
      "loss": 1.0767,
      "step": 369000
    },
    {
      "epoch": 57.86,
      "learning_rate": 7.106952709051049e-05,
      "loss": 1.0698,
      "step": 369500
    },
    {
      "epoch": 57.94,
      "learning_rate": 7.10303789539618e-05,
      "loss": 1.0711,
      "step": 370000
    },
    {
      "epoch": 58.0,
      "eval_loss": 1.0344945192337036,
      "eval_r": 0.6123336553573608,
      "eval_runtime": 26.8474,
      "eval_samples_per_second": 59.298,
      "eval_steps_per_second": 59.298,
      "step": 370388
    },
    {
      "epoch": 58.02,
      "learning_rate": 7.099123081741309e-05,
      "loss": 1.0559,
      "step": 370500
    },
    {
      "epoch": 58.1,
      "learning_rate": 7.09520826808644e-05,
      "loss": 1.0977,
      "step": 371000
    },
    {
      "epoch": 58.17,
      "learning_rate": 7.091293454431569e-05,
      "loss": 1.0672,
      "step": 371500
    },
    {
      "epoch": 58.25,
      "learning_rate": 7.0873786407767e-05,
      "loss": 1.0463,
      "step": 372000
    },
    {
      "epoch": 58.33,
      "learning_rate": 7.083463827121829e-05,
      "loss": 1.0677,
      "step": 372500
    },
    {
      "epoch": 58.41,
      "learning_rate": 7.07954901346696e-05,
      "loss": 1.0592,
      "step": 373000
    },
    {
      "epoch": 58.49,
      "learning_rate": 7.075634199812089e-05,
      "loss": 1.0741,
      "step": 373500
    },
    {
      "epoch": 58.57,
      "learning_rate": 7.071719386157219e-05,
      "loss": 1.0413,
      "step": 374000
    },
    {
      "epoch": 58.64,
      "learning_rate": 7.067804572502349e-05,
      "loss": 1.0612,
      "step": 374500
    },
    {
      "epoch": 58.72,
      "learning_rate": 7.063889758847479e-05,
      "loss": 1.0541,
      "step": 375000
    },
    {
      "epoch": 58.8,
      "learning_rate": 7.059974945192609e-05,
      "loss": 1.061,
      "step": 375500
    },
    {
      "epoch": 58.88,
      "learning_rate": 7.056060131537739e-05,
      "loss": 1.0485,
      "step": 376000
    },
    {
      "epoch": 58.96,
      "learning_rate": 7.052145317882869e-05,
      "loss": 1.0425,
      "step": 376500
    },
    {
      "epoch": 59.0,
      "eval_loss": 1.0355582237243652,
      "eval_r": 0.6125190258026123,
      "eval_runtime": 27.2454,
      "eval_samples_per_second": 58.432,
      "eval_steps_per_second": 58.432,
      "step": 376774
    },
    {
      "epoch": 59.04,
      "learning_rate": 7.048230504227999e-05,
      "loss": 1.0311,
      "step": 377000
    },
    {
      "epoch": 59.11,
      "learning_rate": 7.044315690573129e-05,
      "loss": 1.0451,
      "step": 377500
    },
    {
      "epoch": 59.19,
      "learning_rate": 7.040400876918259e-05,
      "loss": 1.0554,
      "step": 378000
    },
    {
      "epoch": 59.27,
      "learning_rate": 7.036486063263389e-05,
      "loss": 1.0862,
      "step": 378500
    },
    {
      "epoch": 59.35,
      "learning_rate": 7.032571249608519e-05,
      "loss": 1.0405,
      "step": 379000
    },
    {
      "epoch": 59.43,
      "learning_rate": 7.028656435953649e-05,
      "loss": 1.0409,
      "step": 379500
    },
    {
      "epoch": 59.51,
      "learning_rate": 7.024741622298779e-05,
      "loss": 1.0692,
      "step": 380000
    },
    {
      "epoch": 59.58,
      "learning_rate": 7.020826808643909e-05,
      "loss": 1.0611,
      "step": 380500
    },
    {
      "epoch": 59.66,
      "learning_rate": 7.016911994989039e-05,
      "loss": 1.0456,
      "step": 381000
    },
    {
      "epoch": 59.74,
      "learning_rate": 7.012997181334169e-05,
      "loss": 1.0746,
      "step": 381500
    },
    {
      "epoch": 59.82,
      "learning_rate": 7.009082367679298e-05,
      "loss": 1.0402,
      "step": 382000
    },
    {
      "epoch": 59.9,
      "learning_rate": 7.005167554024429e-05,
      "loss": 1.0439,
      "step": 382500
    },
    {
      "epoch": 59.97,
      "learning_rate": 7.001252740369558e-05,
      "loss": 1.054,
      "step": 383000
    },
    {
      "epoch": 60.0,
      "eval_loss": 1.0378177165985107,
      "eval_r": 0.6113843321800232,
      "eval_runtime": 27.4974,
      "eval_samples_per_second": 57.896,
      "eval_steps_per_second": 57.896,
      "step": 383160
    },
    {
      "epoch": 60.05,
      "learning_rate": 6.997337926714689e-05,
      "loss": 1.0777,
      "step": 383500
    },
    {
      "epoch": 60.13,
      "learning_rate": 6.993423113059818e-05,
      "loss": 1.0533,
      "step": 384000
    },
    {
      "epoch": 60.21,
      "learning_rate": 6.989508299404949e-05,
      "loss": 1.0701,
      "step": 384500
    },
    {
      "epoch": 60.29,
      "learning_rate": 6.985593485750078e-05,
      "loss": 1.0334,
      "step": 385000
    },
    {
      "epoch": 60.37,
      "learning_rate": 6.98167867209521e-05,
      "loss": 1.0451,
      "step": 385500
    },
    {
      "epoch": 60.44,
      "learning_rate": 6.977763858440338e-05,
      "loss": 1.0527,
      "step": 386000
    },
    {
      "epoch": 60.52,
      "learning_rate": 6.97384904478547e-05,
      "loss": 1.0636,
      "step": 386500
    },
    {
      "epoch": 60.6,
      "learning_rate": 6.969934231130598e-05,
      "loss": 1.0435,
      "step": 387000
    },
    {
      "epoch": 60.68,
      "learning_rate": 6.966019417475728e-05,
      "loss": 1.0595,
      "step": 387500
    },
    {
      "epoch": 60.76,
      "learning_rate": 6.962104603820858e-05,
      "loss": 1.0554,
      "step": 388000
    },
    {
      "epoch": 60.84,
      "learning_rate": 6.958189790165988e-05,
      "loss": 1.0454,
      "step": 388500
    },
    {
      "epoch": 60.91,
      "learning_rate": 6.954274976511118e-05,
      "loss": 1.0549,
      "step": 389000
    },
    {
      "epoch": 60.99,
      "learning_rate": 6.950360162856248e-05,
      "loss": 1.0668,
      "step": 389500
    },
    {
      "epoch": 61.0,
      "eval_loss": 1.0345871448516846,
      "eval_r": 0.6134477257728577,
      "eval_runtime": 27.2965,
      "eval_samples_per_second": 58.322,
      "eval_steps_per_second": 58.322,
      "step": 389546
    },
    {
      "epoch": 61.07,
      "learning_rate": 6.946445349201378e-05,
      "loss": 1.0647,
      "step": 390000
    },
    {
      "epoch": 61.15,
      "learning_rate": 6.942530535546508e-05,
      "loss": 1.0544,
      "step": 390500
    },
    {
      "epoch": 61.23,
      "learning_rate": 6.938615721891638e-05,
      "loss": 1.0537,
      "step": 391000
    },
    {
      "epoch": 61.31,
      "learning_rate": 6.934700908236768e-05,
      "loss": 1.0463,
      "step": 391500
    },
    {
      "epoch": 61.38,
      "learning_rate": 6.930786094581898e-05,
      "loss": 1.0488,
      "step": 392000
    },
    {
      "epoch": 61.46,
      "learning_rate": 6.926871280927028e-05,
      "loss": 1.0424,
      "step": 392500
    },
    {
      "epoch": 61.54,
      "learning_rate": 6.922956467272158e-05,
      "loss": 1.0468,
      "step": 393000
    },
    {
      "epoch": 61.62,
      "learning_rate": 6.919041653617288e-05,
      "loss": 1.0675,
      "step": 393500
    },
    {
      "epoch": 61.7,
      "learning_rate": 6.915126839962418e-05,
      "loss": 1.0517,
      "step": 394000
    },
    {
      "epoch": 61.78,
      "learning_rate": 6.911212026307548e-05,
      "loss": 1.0519,
      "step": 394500
    },
    {
      "epoch": 61.85,
      "learning_rate": 6.907297212652678e-05,
      "loss": 1.0682,
      "step": 395000
    },
    {
      "epoch": 61.93,
      "learning_rate": 6.903382398997808e-05,
      "loss": 1.0458,
      "step": 395500
    },
    {
      "epoch": 62.0,
      "eval_loss": 1.03168523311615,
      "eval_r": 0.613581657409668,
      "eval_runtime": 27.0786,
      "eval_samples_per_second": 58.792,
      "eval_steps_per_second": 58.792,
      "step": 395932
    },
    {
      "epoch": 62.01,
      "learning_rate": 6.899467585342938e-05,
      "loss": 1.0606,
      "step": 396000
    },
    {
      "epoch": 62.09,
      "learning_rate": 6.895552771688067e-05,
      "loss": 1.0537,
      "step": 396500
    },
    {
      "epoch": 62.17,
      "learning_rate": 6.891637958033198e-05,
      "loss": 1.0486,
      "step": 397000
    },
    {
      "epoch": 62.25,
      "learning_rate": 6.887723144378327e-05,
      "loss": 1.0593,
      "step": 397500
    },
    {
      "epoch": 62.32,
      "learning_rate": 6.883808330723459e-05,
      "loss": 1.0621,
      "step": 398000
    },
    {
      "epoch": 62.4,
      "learning_rate": 6.879893517068587e-05,
      "loss": 1.045,
      "step": 398500
    },
    {
      "epoch": 62.48,
      "learning_rate": 6.875978703413719e-05,
      "loss": 1.0684,
      "step": 399000
    },
    {
      "epoch": 62.56,
      "learning_rate": 6.872063889758847e-05,
      "loss": 1.0513,
      "step": 399500
    },
    {
      "epoch": 62.64,
      "learning_rate": 6.868149076103979e-05,
      "loss": 1.0325,
      "step": 400000
    },
    {
      "epoch": 62.72,
      "learning_rate": 6.864234262449107e-05,
      "loss": 1.0543,
      "step": 400500
    },
    {
      "epoch": 62.79,
      "learning_rate": 6.860319448794237e-05,
      "loss": 1.0592,
      "step": 401000
    },
    {
      "epoch": 62.87,
      "learning_rate": 6.856404635139367e-05,
      "loss": 1.0497,
      "step": 401500
    },
    {
      "epoch": 62.95,
      "learning_rate": 6.852489821484497e-05,
      "loss": 1.0537,
      "step": 402000
    },
    {
      "epoch": 63.0,
      "eval_loss": 1.0342543125152588,
      "eval_r": 0.6111125349998474,
      "eval_runtime": 27.3254,
      "eval_samples_per_second": 58.261,
      "eval_steps_per_second": 58.261,
      "step": 402318
    },
    {
      "epoch": 63.03,
      "learning_rate": 6.848575007829627e-05,
      "loss": 1.0495,
      "step": 402500
    },
    {
      "epoch": 63.11,
      "learning_rate": 6.844660194174757e-05,
      "loss": 1.0325,
      "step": 403000
    },
    {
      "epoch": 63.19,
      "learning_rate": 6.840745380519887e-05,
      "loss": 1.0718,
      "step": 403500
    },
    {
      "epoch": 63.26,
      "learning_rate": 6.836830566865017e-05,
      "loss": 1.0597,
      "step": 404000
    },
    {
      "epoch": 63.34,
      "learning_rate": 6.832915753210147e-05,
      "loss": 1.0532,
      "step": 404500
    },
    {
      "epoch": 63.42,
      "learning_rate": 6.829000939555277e-05,
      "loss": 1.0425,
      "step": 405000
    },
    {
      "epoch": 63.5,
      "learning_rate": 6.825086125900408e-05,
      "loss": 1.0526,
      "step": 405500
    },
    {
      "epoch": 63.58,
      "learning_rate": 6.821171312245538e-05,
      "loss": 1.0487,
      "step": 406000
    },
    {
      "epoch": 63.65,
      "learning_rate": 6.817256498590668e-05,
      "loss": 1.0545,
      "step": 406500
    },
    {
      "epoch": 63.73,
      "learning_rate": 6.813341684935798e-05,
      "loss": 1.0522,
      "step": 407000
    },
    {
      "epoch": 63.81,
      "learning_rate": 6.809426871280928e-05,
      "loss": 1.0543,
      "step": 407500
    },
    {
      "epoch": 63.89,
      "learning_rate": 6.805512057626058e-05,
      "loss": 1.0473,
      "step": 408000
    },
    {
      "epoch": 63.97,
      "learning_rate": 6.801597243971188e-05,
      "loss": 1.0444,
      "step": 408500
    },
    {
      "epoch": 64.0,
      "eval_loss": 1.0383665561676025,
      "eval_r": 0.6094508767127991,
      "eval_runtime": 27.2735,
      "eval_samples_per_second": 58.372,
      "eval_steps_per_second": 58.372,
      "step": 408704
    },
    {
      "epoch": 64.05,
      "learning_rate": 6.797682430316318e-05,
      "loss": 1.0496,
      "step": 409000
    },
    {
      "epoch": 64.12,
      "learning_rate": 6.793767616661448e-05,
      "loss": 1.0357,
      "step": 409500
    },
    {
      "epoch": 64.2,
      "learning_rate": 6.789852803006576e-05,
      "loss": 1.041,
      "step": 410000
    },
    {
      "epoch": 64.28,
      "learning_rate": 6.785937989351708e-05,
      "loss": 1.0508,
      "step": 410500
    },
    {
      "epoch": 64.36,
      "learning_rate": 6.782023175696836e-05,
      "loss": 1.0515,
      "step": 411000
    },
    {
      "epoch": 64.44,
      "learning_rate": 6.778108362041968e-05,
      "loss": 1.0337,
      "step": 411500
    },
    {
      "epoch": 64.52,
      "learning_rate": 6.774193548387096e-05,
      "loss": 1.0602,
      "step": 412000
    },
    {
      "epoch": 64.59,
      "learning_rate": 6.770278734732228e-05,
      "loss": 1.0535,
      "step": 412500
    },
    {
      "epoch": 64.67,
      "learning_rate": 6.766363921077356e-05,
      "loss": 1.061,
      "step": 413000
    },
    {
      "epoch": 64.75,
      "learning_rate": 6.762449107422487e-05,
      "loss": 1.0711,
      "step": 413500
    },
    {
      "epoch": 64.83,
      "learning_rate": 6.758534293767617e-05,
      "loss": 1.0405,
      "step": 414000
    },
    {
      "epoch": 64.91,
      "learning_rate": 6.754619480112747e-05,
      "loss": 1.0709,
      "step": 414500
    },
    {
      "epoch": 64.99,
      "learning_rate": 6.750704666457877e-05,
      "loss": 1.0333,
      "step": 415000
    },
    {
      "epoch": 65.0,
      "eval_loss": 1.0388249158859253,
      "eval_r": 0.6118372082710266,
      "eval_runtime": 27.7348,
      "eval_samples_per_second": 57.401,
      "eval_steps_per_second": 57.401,
      "step": 415090
    },
    {
      "epoch": 65.06,
      "learning_rate": 6.746789852803007e-05,
      "loss": 1.0797,
      "step": 415500
    },
    {
      "epoch": 65.14,
      "learning_rate": 6.742875039148137e-05,
      "loss": 1.0338,
      "step": 416000
    },
    {
      "epoch": 65.22,
      "learning_rate": 6.738960225493267e-05,
      "loss": 1.0554,
      "step": 416500
    },
    {
      "epoch": 65.3,
      "learning_rate": 6.735045411838397e-05,
      "loss": 1.0621,
      "step": 417000
    },
    {
      "epoch": 65.38,
      "learning_rate": 6.731130598183527e-05,
      "loss": 1.0577,
      "step": 417500
    },
    {
      "epoch": 65.46,
      "learning_rate": 6.727215784528657e-05,
      "loss": 1.0582,
      "step": 418000
    },
    {
      "epoch": 65.53,
      "learning_rate": 6.723300970873787e-05,
      "loss": 1.055,
      "step": 418500
    },
    {
      "epoch": 65.61,
      "learning_rate": 6.719386157218917e-05,
      "loss": 1.0257,
      "step": 419000
    },
    {
      "epoch": 65.69,
      "learning_rate": 6.715471343564047e-05,
      "loss": 1.0562,
      "step": 419500
    },
    {
      "epoch": 65.77,
      "learning_rate": 6.711556529909177e-05,
      "loss": 1.0271,
      "step": 420000
    },
    {
      "epoch": 65.85,
      "learning_rate": 6.707641716254307e-05,
      "loss": 1.0525,
      "step": 420500
    },
    {
      "epoch": 65.93,
      "learning_rate": 6.703726902599437e-05,
      "loss": 1.0298,
      "step": 421000
    },
    {
      "epoch": 66.0,
      "eval_loss": 1.032278299331665,
      "eval_r": 0.6122689843177795,
      "eval_runtime": 27.7049,
      "eval_samples_per_second": 57.463,
      "eval_steps_per_second": 57.463,
      "step": 421476
    },
    {
      "epoch": 66.0,
      "learning_rate": 6.699812088944567e-05,
      "loss": 1.05,
      "step": 421500
    },
    {
      "epoch": 66.08,
      "learning_rate": 6.695897275289697e-05,
      "loss": 1.053,
      "step": 422000
    },
    {
      "epoch": 66.16,
      "learning_rate": 6.691982461634827e-05,
      "loss": 1.0473,
      "step": 422500
    },
    {
      "epoch": 66.24,
      "learning_rate": 6.688067647979957e-05,
      "loss": 1.0398,
      "step": 423000
    },
    {
      "epoch": 66.32,
      "learning_rate": 6.684152834325087e-05,
      "loss": 1.0415,
      "step": 423500
    },
    {
      "epoch": 66.4,
      "learning_rate": 6.680238020670217e-05,
      "loss": 1.0279,
      "step": 424000
    },
    {
      "epoch": 66.47,
      "learning_rate": 6.676323207015346e-05,
      "loss": 1.0655,
      "step": 424500
    },
    {
      "epoch": 66.55,
      "learning_rate": 6.672408393360477e-05,
      "loss": 1.0478,
      "step": 425000
    },
    {
      "epoch": 66.63,
      "learning_rate": 6.668493579705606e-05,
      "loss": 1.0577,
      "step": 425500
    },
    {
      "epoch": 66.71,
      "learning_rate": 6.664578766050737e-05,
      "loss": 1.0343,
      "step": 426000
    },
    {
      "epoch": 66.79,
      "learning_rate": 6.660663952395866e-05,
      "loss": 1.0475,
      "step": 426500
    },
    {
      "epoch": 66.87,
      "learning_rate": 6.656749138740996e-05,
      "loss": 1.0598,
      "step": 427000
    },
    {
      "epoch": 66.94,
      "learning_rate": 6.652834325086126e-05,
      "loss": 1.0464,
      "step": 427500
    },
    {
      "epoch": 67.0,
      "eval_loss": 1.0313020944595337,
      "eval_r": 0.6124106645584106,
      "eval_runtime": 27.6594,
      "eval_samples_per_second": 57.557,
      "eval_steps_per_second": 57.557,
      "step": 427862
    },
    {
      "epoch": 67.02,
      "learning_rate": 6.648919511431256e-05,
      "loss": 1.057,
      "step": 428000
    },
    {
      "epoch": 67.1,
      "learning_rate": 6.645004697776386e-05,
      "loss": 1.0347,
      "step": 428500
    },
    {
      "epoch": 67.18,
      "learning_rate": 6.641089884121516e-05,
      "loss": 1.0405,
      "step": 429000
    },
    {
      "epoch": 67.26,
      "learning_rate": 6.637175070466646e-05,
      "loss": 1.051,
      "step": 429500
    },
    {
      "epoch": 67.33,
      "learning_rate": 6.633260256811776e-05,
      "loss": 1.0497,
      "step": 430000
    },
    {
      "epoch": 67.41,
      "learning_rate": 6.629345443156906e-05,
      "loss": 1.0208,
      "step": 430500
    },
    {
      "epoch": 67.49,
      "learning_rate": 6.625430629502036e-05,
      "loss": 1.0637,
      "step": 431000
    },
    {
      "epoch": 67.57,
      "learning_rate": 6.621515815847166e-05,
      "loss": 1.0381,
      "step": 431500
    },
    {
      "epoch": 67.65,
      "learning_rate": 6.617601002192296e-05,
      "loss": 1.0593,
      "step": 432000
    },
    {
      "epoch": 67.73,
      "learning_rate": 6.613686188537426e-05,
      "loss": 1.0579,
      "step": 432500
    },
    {
      "epoch": 67.8,
      "learning_rate": 6.609771374882556e-05,
      "loss": 1.0505,
      "step": 433000
    },
    {
      "epoch": 67.88,
      "learning_rate": 6.605856561227686e-05,
      "loss": 1.0446,
      "step": 433500
    },
    {
      "epoch": 67.96,
      "learning_rate": 6.601941747572816e-05,
      "loss": 1.0715,
      "step": 434000
    },
    {
      "epoch": 68.0,
      "eval_loss": 1.0423533916473389,
      "eval_r": 0.607971727848053,
      "eval_runtime": 27.695,
      "eval_samples_per_second": 57.483,
      "eval_steps_per_second": 57.483,
      "step": 434248
    },
    {
      "epoch": 68.04,
      "learning_rate": 6.598026933917946e-05,
      "loss": 1.0383,
      "step": 434500
    },
    {
      "epoch": 68.12,
      "learning_rate": 6.594112120263076e-05,
      "loss": 1.0511,
      "step": 435000
    },
    {
      "epoch": 68.2,
      "learning_rate": 6.590197306608206e-05,
      "loss": 1.047,
      "step": 435500
    },
    {
      "epoch": 68.27,
      "learning_rate": 6.586282492953336e-05,
      "loss": 1.0587,
      "step": 436000
    },
    {
      "epoch": 68.35,
      "learning_rate": 6.582367679298466e-05,
      "loss": 1.0518,
      "step": 436500
    },
    {
      "epoch": 68.43,
      "learning_rate": 6.578452865643596e-05,
      "loss": 1.0526,
      "step": 437000
    },
    {
      "epoch": 68.51,
      "learning_rate": 6.574538051988726e-05,
      "loss": 1.0427,
      "step": 437500
    },
    {
      "epoch": 68.59,
      "learning_rate": 6.570623238333855e-05,
      "loss": 1.0297,
      "step": 438000
    },
    {
      "epoch": 68.67,
      "learning_rate": 6.566708424678986e-05,
      "loss": 1.0507,
      "step": 438500
    },
    {
      "epoch": 68.74,
      "learning_rate": 6.562793611024115e-05,
      "loss": 1.0338,
      "step": 439000
    },
    {
      "epoch": 68.82,
      "learning_rate": 6.558878797369245e-05,
      "loss": 1.0317,
      "step": 439500
    },
    {
      "epoch": 68.9,
      "learning_rate": 6.554963983714375e-05,
      "loss": 1.0373,
      "step": 440000
    },
    {
      "epoch": 68.98,
      "learning_rate": 6.551049170059505e-05,
      "loss": 1.0636,
      "step": 440500
    },
    {
      "epoch": 69.0,
      "eval_loss": 1.0339274406433105,
      "eval_r": 0.6124245524406433,
      "eval_runtime": 27.6524,
      "eval_samples_per_second": 57.572,
      "eval_steps_per_second": 57.572,
      "step": 440634
    },
    {
      "epoch": 69.06,
      "learning_rate": 6.547134356404635e-05,
      "loss": 1.0479,
      "step": 441000
    },
    {
      "epoch": 69.14,
      "learning_rate": 6.543219542749765e-05,
      "loss": 1.0525,
      "step": 441500
    },
    {
      "epoch": 69.21,
      "learning_rate": 6.539304729094895e-05,
      "loss": 1.0428,
      "step": 442000
    },
    {
      "epoch": 69.29,
      "learning_rate": 6.535389915440025e-05,
      "loss": 1.0419,
      "step": 442500
    },
    {
      "epoch": 69.37,
      "learning_rate": 6.531475101785155e-05,
      "loss": 1.0291,
      "step": 443000
    },
    {
      "epoch": 69.45,
      "learning_rate": 6.527560288130285e-05,
      "loss": 1.0381,
      "step": 443500
    },
    {
      "epoch": 69.53,
      "learning_rate": 6.523645474475415e-05,
      "loss": 1.0352,
      "step": 444000
    },
    {
      "epoch": 69.61,
      "learning_rate": 6.519730660820545e-05,
      "loss": 1.0382,
      "step": 444500
    },
    {
      "epoch": 69.68,
      "learning_rate": 6.515815847165675e-05,
      "loss": 1.0628,
      "step": 445000
    },
    {
      "epoch": 69.76,
      "learning_rate": 6.511901033510805e-05,
      "loss": 1.0385,
      "step": 445500
    },
    {
      "epoch": 69.84,
      "learning_rate": 6.507986219855935e-05,
      "loss": 1.0569,
      "step": 446000
    },
    {
      "epoch": 69.92,
      "learning_rate": 6.504071406201065e-05,
      "loss": 1.0513,
      "step": 446500
    },
    {
      "epoch": 70.0,
      "learning_rate": 6.500156592546195e-05,
      "loss": 1.0675,
      "step": 447000
    },
    {
      "epoch": 70.0,
      "eval_loss": 1.0340691804885864,
      "eval_r": 0.6121721267700195,
      "eval_runtime": 28.1902,
      "eval_samples_per_second": 56.474,
      "eval_steps_per_second": 56.474,
      "step": 447020
    },
    {
      "epoch": 70.08,
      "learning_rate": 6.496241778891325e-05,
      "loss": 1.05,
      "step": 447500
    },
    {
      "epoch": 70.15,
      "learning_rate": 6.492326965236455e-05,
      "loss": 1.0346,
      "step": 448000
    },
    {
      "epoch": 70.23,
      "learning_rate": 6.488412151581585e-05,
      "loss": 1.0387,
      "step": 448500
    },
    {
      "epoch": 70.31,
      "learning_rate": 6.484497337926715e-05,
      "loss": 1.0475,
      "step": 449000
    },
    {
      "epoch": 70.39,
      "learning_rate": 6.480582524271845e-05,
      "loss": 1.0368,
      "step": 449500
    },
    {
      "epoch": 70.47,
      "learning_rate": 6.476667710616975e-05,
      "loss": 1.0637,
      "step": 450000
    },
    {
      "epoch": 70.54,
      "learning_rate": 6.472752896962105e-05,
      "loss": 1.0415,
      "step": 450500
    },
    {
      "epoch": 70.62,
      "learning_rate": 6.468838083307235e-05,
      "loss": 1.0469,
      "step": 451000
    },
    {
      "epoch": 70.7,
      "learning_rate": 6.464923269652365e-05,
      "loss": 1.0512,
      "step": 451500
    },
    {
      "epoch": 70.78,
      "learning_rate": 6.461008455997495e-05,
      "loss": 1.0523,
      "step": 452000
    },
    {
      "epoch": 70.86,
      "learning_rate": 6.457093642342624e-05,
      "loss": 1.0605,
      "step": 452500
    },
    {
      "epoch": 70.94,
      "learning_rate": 6.453178828687754e-05,
      "loss": 1.0284,
      "step": 453000
    },
    {
      "epoch": 71.0,
      "eval_loss": 1.0388356447219849,
      "eval_r": 0.6110192537307739,
      "eval_runtime": 27.7313,
      "eval_samples_per_second": 57.408,
      "eval_steps_per_second": 57.408,
      "step": 453406
    },
    {
      "epoch": 71.01,
      "learning_rate": 6.449264015032884e-05,
      "loss": 1.0265,
      "step": 453500
    },
    {
      "epoch": 71.09,
      "learning_rate": 6.445349201378014e-05,
      "loss": 1.049,
      "step": 454000
    },
    {
      "epoch": 71.17,
      "learning_rate": 6.441434387723144e-05,
      "loss": 1.0346,
      "step": 454500
    },
    {
      "epoch": 71.25,
      "learning_rate": 6.437519574068274e-05,
      "loss": 1.0241,
      "step": 455000
    },
    {
      "epoch": 71.33,
      "learning_rate": 6.433604760413404e-05,
      "loss": 1.0455,
      "step": 455500
    },
    {
      "epoch": 71.41,
      "learning_rate": 6.429689946758534e-05,
      "loss": 1.047,
      "step": 456000
    },
    {
      "epoch": 71.48,
      "learning_rate": 6.425775133103664e-05,
      "loss": 1.0412,
      "step": 456500
    },
    {
      "epoch": 71.56,
      "learning_rate": 6.421860319448794e-05,
      "loss": 1.0525,
      "step": 457000
    },
    {
      "epoch": 71.64,
      "learning_rate": 6.417945505793924e-05,
      "loss": 1.0467,
      "step": 457500
    },
    {
      "epoch": 71.72,
      "learning_rate": 6.414030692139054e-05,
      "loss": 1.0634,
      "step": 458000
    },
    {
      "epoch": 71.8,
      "learning_rate": 6.410115878484184e-05,
      "loss": 1.0583,
      "step": 458500
    },
    {
      "epoch": 71.88,
      "learning_rate": 6.406201064829314e-05,
      "loss": 1.0483,
      "step": 459000
    },
    {
      "epoch": 71.95,
      "learning_rate": 6.402286251174444e-05,
      "loss": 1.0416,
      "step": 459500
    },
    {
      "epoch": 72.0,
      "eval_loss": 1.0326764583587646,
      "eval_r": 0.6117265820503235,
      "eval_runtime": 27.4536,
      "eval_samples_per_second": 57.989,
      "eval_steps_per_second": 57.989,
      "step": 459792
    },
    {
      "epoch": 72.03,
      "learning_rate": 6.398371437519574e-05,
      "loss": 1.0232,
      "step": 460000
    },
    {
      "epoch": 72.11,
      "learning_rate": 6.394456623864704e-05,
      "loss": 1.0666,
      "step": 460500
    },
    {
      "epoch": 72.19,
      "learning_rate": 6.390541810209835e-05,
      "loss": 1.0291,
      "step": 461000
    },
    {
      "epoch": 72.27,
      "learning_rate": 6.386626996554965e-05,
      "loss": 1.0453,
      "step": 461500
    },
    {
      "epoch": 72.35,
      "learning_rate": 6.382712182900095e-05,
      "loss": 1.0418,
      "step": 462000
    },
    {
      "epoch": 72.42,
      "learning_rate": 6.378797369245225e-05,
      "loss": 1.031,
      "step": 462500
    },
    {
      "epoch": 72.5,
      "learning_rate": 6.374882555590355e-05,
      "loss": 1.0426,
      "step": 463000
    },
    {
      "epoch": 72.58,
      "learning_rate": 6.370967741935485e-05,
      "loss": 1.0306,
      "step": 463500
    },
    {
      "epoch": 72.66,
      "learning_rate": 6.367052928280615e-05,
      "loss": 1.0416,
      "step": 464000
    },
    {
      "epoch": 72.74,
      "learning_rate": 6.363138114625745e-05,
      "loss": 1.0623,
      "step": 464500
    },
    {
      "epoch": 72.82,
      "learning_rate": 6.359223300970875e-05,
      "loss": 1.0455,
      "step": 465000
    },
    {
      "epoch": 72.89,
      "learning_rate": 6.355308487316003e-05,
      "loss": 1.0341,
      "step": 465500
    },
    {
      "epoch": 72.97,
      "learning_rate": 6.351393673661135e-05,
      "loss": 1.0476,
      "step": 466000
    },
    {
      "epoch": 73.0,
      "eval_loss": 1.0327757596969604,
      "eval_r": 0.612486720085144,
      "eval_runtime": 27.4925,
      "eval_samples_per_second": 57.907,
      "eval_steps_per_second": 57.907,
      "step": 466178
    },
    {
      "epoch": 73.05,
      "learning_rate": 6.347478860006263e-05,
      "loss": 1.0279,
      "step": 466500
    },
    {
      "epoch": 73.13,
      "learning_rate": 6.343564046351393e-05,
      "loss": 1.0211,
      "step": 467000
    },
    {
      "epoch": 73.21,
      "learning_rate": 6.339649232696523e-05,
      "loss": 1.0462,
      "step": 467500
    },
    {
      "epoch": 73.29,
      "learning_rate": 6.335734419041653e-05,
      "loss": 1.0345,
      "step": 468000
    },
    {
      "epoch": 73.36,
      "learning_rate": 6.331819605386783e-05,
      "loss": 1.055,
      "step": 468500
    },
    {
      "epoch": 73.44,
      "learning_rate": 6.327904791731914e-05,
      "loss": 1.0368,
      "step": 469000
    },
    {
      "epoch": 73.52,
      "learning_rate": 6.323989978077044e-05,
      "loss": 1.0296,
      "step": 469500
    },
    {
      "epoch": 73.6,
      "learning_rate": 6.320075164422174e-05,
      "loss": 1.0481,
      "step": 470000
    },
    {
      "epoch": 73.68,
      "learning_rate": 6.316160350767304e-05,
      "loss": 1.0448,
      "step": 470500
    },
    {
      "epoch": 73.76,
      "learning_rate": 6.312245537112434e-05,
      "loss": 1.0497,
      "step": 471000
    },
    {
      "epoch": 73.83,
      "learning_rate": 6.308330723457564e-05,
      "loss": 1.0381,
      "step": 471500
    },
    {
      "epoch": 73.91,
      "learning_rate": 6.304415909802694e-05,
      "loss": 1.0505,
      "step": 472000
    },
    {
      "epoch": 73.99,
      "learning_rate": 6.300501096147824e-05,
      "loss": 1.0525,
      "step": 472500
    },
    {
      "epoch": 74.0,
      "eval_loss": 1.0380092859268188,
      "eval_r": 0.6111830472946167,
      "eval_runtime": 27.7904,
      "eval_samples_per_second": 57.286,
      "eval_steps_per_second": 57.286,
      "step": 472564
    },
    {
      "epoch": 74.07,
      "learning_rate": 6.296586282492954e-05,
      "loss": 1.0332,
      "step": 473000
    },
    {
      "epoch": 74.15,
      "learning_rate": 6.292671468838084e-05,
      "loss": 1.0194,
      "step": 473500
    },
    {
      "epoch": 74.22,
      "learning_rate": 6.288756655183214e-05,
      "loss": 1.0383,
      "step": 474000
    },
    {
      "epoch": 74.3,
      "learning_rate": 6.284841841528344e-05,
      "loss": 1.0529,
      "step": 474500
    },
    {
      "epoch": 74.38,
      "learning_rate": 6.280927027873474e-05,
      "loss": 1.0297,
      "step": 475000
    },
    {
      "epoch": 74.46,
      "learning_rate": 6.277012214218604e-05,
      "loss": 1.036,
      "step": 475500
    },
    {
      "epoch": 74.54,
      "learning_rate": 6.273097400563734e-05,
      "loss": 1.0516,
      "step": 476000
    },
    {
      "epoch": 74.62,
      "learning_rate": 6.269182586908864e-05,
      "loss": 1.0378,
      "step": 476500
    },
    {
      "epoch": 74.69,
      "learning_rate": 6.265267773253994e-05,
      "loss": 1.0319,
      "step": 477000
    },
    {
      "epoch": 74.77,
      "learning_rate": 6.261352959599124e-05,
      "loss": 1.0545,
      "step": 477500
    },
    {
      "epoch": 74.85,
      "learning_rate": 6.257438145944254e-05,
      "loss": 1.0485,
      "step": 478000
    },
    {
      "epoch": 74.93,
      "learning_rate": 6.253523332289384e-05,
      "loss": 1.0438,
      "step": 478500
    },
    {
      "epoch": 75.0,
      "eval_loss": 1.0386632680892944,
      "eval_r": 0.6089911460876465,
      "eval_runtime": 27.4098,
      "eval_samples_per_second": 58.081,
      "eval_steps_per_second": 58.081,
      "step": 478950
    },
    {
      "epoch": 75.01,
      "learning_rate": 6.249608518634513e-05,
      "loss": 1.0447,
      "step": 479000
    },
    {
      "epoch": 75.09,
      "learning_rate": 6.245693704979644e-05,
      "loss": 1.0448,
      "step": 479500
    },
    {
      "epoch": 75.16,
      "learning_rate": 6.241778891324773e-05,
      "loss": 1.0294,
      "step": 480000
    },
    {
      "epoch": 75.24,
      "learning_rate": 6.237864077669903e-05,
      "loss": 1.0237,
      "step": 480500
    },
    {
      "epoch": 75.32,
      "learning_rate": 6.233949264015033e-05,
      "loss": 1.0605,
      "step": 481000
    },
    {
      "epoch": 75.4,
      "learning_rate": 6.230034450360163e-05,
      "loss": 1.0452,
      "step": 481500
    },
    {
      "epoch": 75.48,
      "learning_rate": 6.226119636705293e-05,
      "loss": 1.0627,
      "step": 482000
    },
    {
      "epoch": 75.56,
      "learning_rate": 6.222204823050423e-05,
      "loss": 1.0339,
      "step": 482500
    },
    {
      "epoch": 75.63,
      "learning_rate": 6.218290009395553e-05,
      "loss": 1.026,
      "step": 483000
    },
    {
      "epoch": 75.71,
      "learning_rate": 6.214375195740683e-05,
      "loss": 1.0499,
      "step": 483500
    },
    {
      "epoch": 75.79,
      "learning_rate": 6.210460382085813e-05,
      "loss": 1.0285,
      "step": 484000
    },
    {
      "epoch": 75.87,
      "learning_rate": 6.206545568430943e-05,
      "loss": 1.0428,
      "step": 484500
    },
    {
      "epoch": 75.95,
      "learning_rate": 6.202630754776073e-05,
      "loss": 1.0426,
      "step": 485000
    },
    {
      "epoch": 76.0,
      "eval_loss": 1.0335497856140137,
      "eval_r": 0.6126084327697754,
      "eval_runtime": 27.6004,
      "eval_samples_per_second": 57.68,
      "eval_steps_per_second": 57.68,
      "step": 485336
    },
    {
      "epoch": 76.03,
      "learning_rate": 6.198715941121203e-05,
      "loss": 1.028,
      "step": 485500
    },
    {
      "epoch": 76.1,
      "learning_rate": 6.194801127466333e-05,
      "loss": 1.0323,
      "step": 486000
    },
    {
      "epoch": 76.18,
      "learning_rate": 6.190886313811463e-05,
      "loss": 1.0377,
      "step": 486500
    },
    {
      "epoch": 76.26,
      "learning_rate": 6.186971500156593e-05,
      "loss": 1.0382,
      "step": 487000
    },
    {
      "epoch": 76.34,
      "learning_rate": 6.183056686501723e-05,
      "loss": 1.0361,
      "step": 487500
    },
    {
      "epoch": 76.42,
      "learning_rate": 6.179141872846853e-05,
      "loss": 1.0329,
      "step": 488000
    },
    {
      "epoch": 76.5,
      "learning_rate": 6.175227059191983e-05,
      "loss": 1.0257,
      "step": 488500
    },
    {
      "epoch": 76.57,
      "learning_rate": 6.171312245537113e-05,
      "loss": 1.0479,
      "step": 489000
    },
    {
      "epoch": 76.65,
      "learning_rate": 6.167397431882243e-05,
      "loss": 1.0311,
      "step": 489500
    },
    {
      "epoch": 76.73,
      "learning_rate": 6.163482618227373e-05,
      "loss": 1.0621,
      "step": 490000
    },
    {
      "epoch": 76.81,
      "learning_rate": 6.159567804572503e-05,
      "loss": 1.0445,
      "step": 490500
    },
    {
      "epoch": 76.89,
      "learning_rate": 6.155652990917633e-05,
      "loss": 1.0428,
      "step": 491000
    },
    {
      "epoch": 76.97,
      "learning_rate": 6.151738177262763e-05,
      "loss": 1.0492,
      "step": 491500
    },
    {
      "epoch": 77.0,
      "eval_loss": 1.034131407737732,
      "eval_r": 0.6120972037315369,
      "eval_runtime": 27.4463,
      "eval_samples_per_second": 58.004,
      "eval_steps_per_second": 58.004,
      "step": 491722
    },
    {
      "epoch": 77.04,
      "learning_rate": 6.147823363607893e-05,
      "loss": 1.0264,
      "step": 492000
    },
    {
      "epoch": 77.12,
      "learning_rate": 6.143908549953022e-05,
      "loss": 1.0254,
      "step": 492500
    },
    {
      "epoch": 77.2,
      "learning_rate": 6.139993736298153e-05,
      "loss": 1.0374,
      "step": 493000
    },
    {
      "epoch": 77.28,
      "learning_rate": 6.136078922643282e-05,
      "loss": 1.0425,
      "step": 493500
    },
    {
      "epoch": 77.36,
      "learning_rate": 6.132164108988413e-05,
      "loss": 1.0415,
      "step": 494000
    },
    {
      "epoch": 77.44,
      "learning_rate": 6.128249295333542e-05,
      "loss": 1.0199,
      "step": 494500
    },
    {
      "epoch": 77.51,
      "learning_rate": 6.124334481678672e-05,
      "loss": 1.0359,
      "step": 495000
    },
    {
      "epoch": 77.59,
      "learning_rate": 6.120419668023802e-05,
      "loss": 1.058,
      "step": 495500
    },
    {
      "epoch": 77.67,
      "learning_rate": 6.116504854368932e-05,
      "loss": 1.0465,
      "step": 496000
    },
    {
      "epoch": 77.75,
      "learning_rate": 6.112590040714062e-05,
      "loss": 1.0441,
      "step": 496500
    },
    {
      "epoch": 77.83,
      "learning_rate": 6.108675227059192e-05,
      "loss": 1.0389,
      "step": 497000
    },
    {
      "epoch": 77.9,
      "learning_rate": 6.104760413404322e-05,
      "loss": 1.0429,
      "step": 497500
    },
    {
      "epoch": 77.98,
      "learning_rate": 6.100845599749452e-05,
      "loss": 1.0367,
      "step": 498000
    },
    {
      "epoch": 78.0,
      "eval_loss": 1.0311729907989502,
      "eval_r": 0.6125795245170593,
      "eval_runtime": 27.6126,
      "eval_samples_per_second": 57.655,
      "eval_steps_per_second": 57.655,
      "step": 498108
    },
    {
      "epoch": 78.06,
      "learning_rate": 6.096930786094582e-05,
      "loss": 1.0226,
      "step": 498500
    },
    {
      "epoch": 78.14,
      "learning_rate": 6.093015972439712e-05,
      "loss": 1.0361,
      "step": 499000
    },
    {
      "epoch": 78.22,
      "learning_rate": 6.089101158784842e-05,
      "loss": 1.0307,
      "step": 499500
    },
    {
      "epoch": 78.3,
      "learning_rate": 6.0851863451299715e-05,
      "loss": 1.047,
      "step": 500000
    },
    {
      "epoch": 78.37,
      "learning_rate": 6.081271531475102e-05,
      "loss": 1.0377,
      "step": 500500
    },
    {
      "epoch": 78.45,
      "learning_rate": 6.0773567178202315e-05,
      "loss": 1.0408,
      "step": 501000
    },
    {
      "epoch": 78.53,
      "learning_rate": 6.073441904165362e-05,
      "loss": 1.0191,
      "step": 501500
    },
    {
      "epoch": 78.61,
      "learning_rate": 6.0695270905104916e-05,
      "loss": 1.055,
      "step": 502000
    },
    {
      "epoch": 78.69,
      "learning_rate": 6.065612276855622e-05,
      "loss": 1.0462,
      "step": 502500
    },
    {
      "epoch": 78.77,
      "learning_rate": 6.0616974632007516e-05,
      "loss": 1.0169,
      "step": 503000
    },
    {
      "epoch": 78.84,
      "learning_rate": 6.057782649545882e-05,
      "loss": 1.0134,
      "step": 503500
    },
    {
      "epoch": 78.92,
      "learning_rate": 6.0538678358910116e-05,
      "loss": 1.0528,
      "step": 504000
    },
    {
      "epoch": 79.0,
      "eval_loss": 1.0367510318756104,
      "eval_r": 0.610304057598114,
      "eval_runtime": 26.7242,
      "eval_samples_per_second": 59.572,
      "eval_steps_per_second": 59.572,
      "step": 504494
    },
    {
      "epoch": 79.0,
      "learning_rate": 6.0499530222361423e-05,
      "loss": 1.0487,
      "step": 504500
    },
    {
      "epoch": 79.08,
      "learning_rate": 6.046038208581272e-05,
      "loss": 1.0358,
      "step": 505000
    },
    {
      "epoch": 79.16,
      "learning_rate": 6.0421233949264024e-05,
      "loss": 1.0377,
      "step": 505500
    },
    {
      "epoch": 79.24,
      "learning_rate": 6.038208581271532e-05,
      "loss": 1.0556,
      "step": 506000
    },
    {
      "epoch": 79.31,
      "learning_rate": 6.0342937676166624e-05,
      "loss": 1.0385,
      "step": 506500
    },
    {
      "epoch": 79.39,
      "learning_rate": 6.030378953961792e-05,
      "loss": 1.031,
      "step": 507000
    },
    {
      "epoch": 79.47,
      "learning_rate": 6.0264641403069225e-05,
      "loss": 1.0248,
      "step": 507500
    },
    {
      "epoch": 79.55,
      "learning_rate": 6.022549326652052e-05,
      "loss": 1.029,
      "step": 508000
    },
    {
      "epoch": 79.63,
      "learning_rate": 6.018634512997182e-05,
      "loss": 1.0232,
      "step": 508500
    },
    {
      "epoch": 79.71,
      "learning_rate": 6.014719699342312e-05,
      "loss": 1.0307,
      "step": 509000
    },
    {
      "epoch": 79.78,
      "learning_rate": 6.010804885687441e-05,
      "loss": 1.0513,
      "step": 509500
    },
    {
      "epoch": 79.86,
      "learning_rate": 6.006890072032572e-05,
      "loss": 1.0267,
      "step": 510000
    },
    {
      "epoch": 79.94,
      "learning_rate": 6.002975258377701e-05,
      "loss": 1.0553,
      "step": 510500
    },
    {
      "epoch": 80.0,
      "eval_loss": 1.0364526510238647,
      "eval_r": 0.6105245351791382,
      "eval_runtime": 27.5354,
      "eval_samples_per_second": 57.817,
      "eval_steps_per_second": 57.817,
      "step": 510880
    },
    {
      "epoch": 80.02,
      "learning_rate": 5.999060444722831e-05,
      "loss": 1.0381,
      "step": 511000
    },
    {
      "epoch": 80.1,
      "learning_rate": 5.995145631067961e-05,
      "loss": 1.0358,
      "step": 511500
    },
    {
      "epoch": 80.18,
      "learning_rate": 5.991230817413091e-05,
      "loss": 1.0266,
      "step": 512000
    },
    {
      "epoch": 80.25,
      "learning_rate": 5.987316003758221e-05,
      "loss": 1.0279,
      "step": 512500
    },
    {
      "epoch": 80.33,
      "learning_rate": 5.9834011901033514e-05,
      "loss": 1.0456,
      "step": 513000
    },
    {
      "epoch": 80.41,
      "learning_rate": 5.979486376448481e-05,
      "loss": 1.0359,
      "step": 513500
    },
    {
      "epoch": 80.49,
      "learning_rate": 5.9755715627936114e-05,
      "loss": 1.031,
      "step": 514000
    },
    {
      "epoch": 80.57,
      "learning_rate": 5.971656749138741e-05,
      "loss": 1.0322,
      "step": 514500
    },
    {
      "epoch": 80.65,
      "learning_rate": 5.9677419354838715e-05,
      "loss": 1.0466,
      "step": 515000
    },
    {
      "epoch": 80.72,
      "learning_rate": 5.963827121829001e-05,
      "loss": 1.0374,
      "step": 515500
    },
    {
      "epoch": 80.8,
      "learning_rate": 5.9599123081741315e-05,
      "loss": 1.0303,
      "step": 516000
    },
    {
      "epoch": 80.88,
      "learning_rate": 5.955997494519261e-05,
      "loss": 1.0223,
      "step": 516500
    },
    {
      "epoch": 80.96,
      "learning_rate": 5.9520826808643915e-05,
      "loss": 1.0442,
      "step": 517000
    },
    {
      "epoch": 81.0,
      "eval_loss": 1.0365562438964844,
      "eval_r": 0.6130882501602173,
      "eval_runtime": 27.4274,
      "eval_samples_per_second": 58.044,
      "eval_steps_per_second": 58.044,
      "step": 517266
    },
    {
      "epoch": 81.04,
      "learning_rate": 5.948167867209521e-05,
      "loss": 1.0447,
      "step": 517500
    },
    {
      "epoch": 81.11,
      "learning_rate": 5.9442530535546516e-05,
      "loss": 1.0342,
      "step": 518000
    },
    {
      "epoch": 81.19,
      "learning_rate": 5.940338239899781e-05,
      "loss": 1.0593,
      "step": 518500
    },
    {
      "epoch": 81.27,
      "learning_rate": 5.9364234262449116e-05,
      "loss": 1.0195,
      "step": 519000
    },
    {
      "epoch": 81.35,
      "learning_rate": 5.932508612590041e-05,
      "loss": 1.0233,
      "step": 519500
    },
    {
      "epoch": 81.43,
      "learning_rate": 5.928593798935172e-05,
      "loss": 1.0408,
      "step": 520000
    },
    {
      "epoch": 81.51,
      "learning_rate": 5.924678985280301e-05,
      "loss": 1.042,
      "step": 520500
    },
    {
      "epoch": 81.58,
      "learning_rate": 5.920764171625432e-05,
      "loss": 1.0334,
      "step": 521000
    },
    {
      "epoch": 81.66,
      "learning_rate": 5.916849357970561e-05,
      "loss": 1.0211,
      "step": 521500
    },
    {
      "epoch": 81.74,
      "learning_rate": 5.912934544315691e-05,
      "loss": 1.0127,
      "step": 522000
    },
    {
      "epoch": 81.82,
      "learning_rate": 5.909019730660821e-05,
      "loss": 1.0422,
      "step": 522500
    },
    {
      "epoch": 81.9,
      "learning_rate": 5.9051049170059504e-05,
      "loss": 1.0377,
      "step": 523000
    },
    {
      "epoch": 81.98,
      "learning_rate": 5.9011901033510805e-05,
      "loss": 1.0641,
      "step": 523500
    },
    {
      "epoch": 82.0,
      "eval_loss": 1.039991855621338,
      "eval_r": 0.6122026443481445,
      "eval_runtime": 27.0823,
      "eval_samples_per_second": 58.784,
      "eval_steps_per_second": 58.784,
      "step": 523652
    },
    {
      "epoch": 82.05,
      "learning_rate": 5.8972752896962105e-05,
      "loss": 1.0207,
      "step": 524000
    },
    {
      "epoch": 82.13,
      "learning_rate": 5.8933604760413405e-05,
      "loss": 1.0386,
      "step": 524500
    },
    {
      "epoch": 82.21,
      "learning_rate": 5.8894456623864705e-05,
      "loss": 1.0314,
      "step": 525000
    },
    {
      "epoch": 82.29,
      "learning_rate": 5.8855308487316006e-05,
      "loss": 1.0136,
      "step": 525500
    },
    {
      "epoch": 82.37,
      "learning_rate": 5.88161603507673e-05,
      "loss": 1.0401,
      "step": 526000
    },
    {
      "epoch": 82.45,
      "learning_rate": 5.8777012214218606e-05,
      "loss": 1.0333,
      "step": 526500
    },
    {
      "epoch": 82.52,
      "learning_rate": 5.87378640776699e-05,
      "loss": 1.0491,
      "step": 527000
    },
    {
      "epoch": 82.6,
      "learning_rate": 5.8698715941121206e-05,
      "loss": 1.0369,
      "step": 527500
    },
    {
      "epoch": 82.68,
      "learning_rate": 5.86595678045725e-05,
      "loss": 1.0323,
      "step": 528000
    },
    {
      "epoch": 82.76,
      "learning_rate": 5.862041966802381e-05,
      "loss": 1.0586,
      "step": 528500
    },
    {
      "epoch": 82.84,
      "learning_rate": 5.85812715314751e-05,
      "loss": 1.0319,
      "step": 529000
    },
    {
      "epoch": 82.92,
      "learning_rate": 5.854212339492641e-05,
      "loss": 1.0278,
      "step": 529500
    },
    {
      "epoch": 82.99,
      "learning_rate": 5.85029752583777e-05,
      "loss": 1.0369,
      "step": 530000
    },
    {
      "epoch": 83.0,
      "eval_loss": 1.0349743366241455,
      "eval_r": 0.6118155717849731,
      "eval_runtime": 27.5398,
      "eval_samples_per_second": 57.807,
      "eval_steps_per_second": 57.807,
      "step": 530038
    },
    {
      "epoch": 83.07,
      "learning_rate": 5.846382712182901e-05,
      "loss": 1.0218,
      "step": 530500
    },
    {
      "epoch": 83.15,
      "learning_rate": 5.84246789852803e-05,
      "loss": 1.0124,
      "step": 531000
    },
    {
      "epoch": 83.23,
      "learning_rate": 5.838553084873161e-05,
      "loss": 1.0583,
      "step": 531500
    },
    {
      "epoch": 83.31,
      "learning_rate": 5.83463827121829e-05,
      "loss": 1.035,
      "step": 532000
    },
    {
      "epoch": 83.39,
      "learning_rate": 5.830723457563421e-05,
      "loss": 1.0281,
      "step": 532500
    },
    {
      "epoch": 83.46,
      "learning_rate": 5.82680864390855e-05,
      "loss": 1.0385,
      "step": 533000
    },
    {
      "epoch": 83.54,
      "learning_rate": 5.822893830253681e-05,
      "loss": 1.0297,
      "step": 533500
    },
    {
      "epoch": 83.62,
      "learning_rate": 5.81897901659881e-05,
      "loss": 1.0305,
      "step": 534000
    },
    {
      "epoch": 83.7,
      "learning_rate": 5.815064202943941e-05,
      "loss": 1.0224,
      "step": 534500
    },
    {
      "epoch": 83.78,
      "learning_rate": 5.81114938928907e-05,
      "loss": 1.037,
      "step": 535000
    },
    {
      "epoch": 83.86,
      "learning_rate": 5.8072345756342e-05,
      "loss": 1.039,
      "step": 535500
    },
    {
      "epoch": 83.93,
      "learning_rate": 5.80331976197933e-05,
      "loss": 1.0374,
      "step": 536000
    },
    {
      "epoch": 84.0,
      "eval_loss": 1.0370596647262573,
      "eval_r": 0.6107139587402344,
      "eval_runtime": 27.3777,
      "eval_samples_per_second": 58.15,
      "eval_steps_per_second": 58.15,
      "step": 536424
    },
    {
      "epoch": 84.01,
      "learning_rate": 5.7994049483244604e-05,
      "loss": 1.0318,
      "step": 536500
    },
    {
      "epoch": 84.09,
      "learning_rate": 5.79549013466959e-05,
      "loss": 1.0363,
      "step": 537000
    },
    {
      "epoch": 84.17,
      "learning_rate": 5.79157532101472e-05,
      "loss": 1.0384,
      "step": 537500
    },
    {
      "epoch": 84.25,
      "learning_rate": 5.78766050735985e-05,
      "loss": 1.0352,
      "step": 538000
    },
    {
      "epoch": 84.33,
      "learning_rate": 5.78374569370498e-05,
      "loss": 1.0251,
      "step": 538500
    },
    {
      "epoch": 84.4,
      "learning_rate": 5.77983088005011e-05,
      "loss": 1.0201,
      "step": 539000
    },
    {
      "epoch": 84.48,
      "learning_rate": 5.775916066395239e-05,
      "loss": 1.0354,
      "step": 539500
    },
    {
      "epoch": 84.56,
      "learning_rate": 5.77200125274037e-05,
      "loss": 1.0251,
      "step": 540000
    },
    {
      "epoch": 84.64,
      "learning_rate": 5.768086439085499e-05,
      "loss": 1.0293,
      "step": 540500
    },
    {
      "epoch": 84.72,
      "learning_rate": 5.76417162543063e-05,
      "loss": 1.0306,
      "step": 541000
    },
    {
      "epoch": 84.79,
      "learning_rate": 5.760256811775759e-05,
      "loss": 1.0413,
      "step": 541500
    },
    {
      "epoch": 84.87,
      "learning_rate": 5.75634199812089e-05,
      "loss": 1.0343,
      "step": 542000
    },
    {
      "epoch": 84.95,
      "learning_rate": 5.752427184466019e-05,
      "loss": 1.0185,
      "step": 542500
    },
    {
      "epoch": 85.0,
      "eval_loss": 1.0340845584869385,
      "eval_r": 0.611291766166687,
      "eval_runtime": 27.4031,
      "eval_samples_per_second": 58.096,
      "eval_steps_per_second": 58.096,
      "step": 542810
    },
    {
      "epoch": 85.03,
      "learning_rate": 5.74851237081115e-05,
      "loss": 1.0579,
      "step": 543000
    },
    {
      "epoch": 85.11,
      "learning_rate": 5.744597557156279e-05,
      "loss": 1.0215,
      "step": 543500
    },
    {
      "epoch": 85.19,
      "learning_rate": 5.74068274350141e-05,
      "loss": 1.0226,
      "step": 544000
    },
    {
      "epoch": 85.26,
      "learning_rate": 5.7367679298465393e-05,
      "loss": 1.0226,
      "step": 544500
    },
    {
      "epoch": 85.34,
      "learning_rate": 5.73285311619167e-05,
      "loss": 1.0242,
      "step": 545000
    },
    {
      "epoch": 85.42,
      "learning_rate": 5.7289383025367994e-05,
      "loss": 1.0484,
      "step": 545500
    },
    {
      "epoch": 85.5,
      "learning_rate": 5.72502348888193e-05,
      "loss": 1.0358,
      "step": 546000
    },
    {
      "epoch": 85.58,
      "learning_rate": 5.7211086752270594e-05,
      "loss": 1.0318,
      "step": 546500
    },
    {
      "epoch": 85.66,
      "learning_rate": 5.71719386157219e-05,
      "loss": 1.0342,
      "step": 547000
    },
    {
      "epoch": 85.73,
      "learning_rate": 5.7132790479173195e-05,
      "loss": 1.0422,
      "step": 547500
    },
    {
      "epoch": 85.81,
      "learning_rate": 5.7093642342624495e-05,
      "loss": 1.0357,
      "step": 548000
    },
    {
      "epoch": 85.89,
      "learning_rate": 5.7054494206075795e-05,
      "loss": 1.0255,
      "step": 548500
    },
    {
      "epoch": 85.97,
      "learning_rate": 5.7015346069527095e-05,
      "loss": 1.0313,
      "step": 549000
    },
    {
      "epoch": 86.0,
      "eval_loss": 1.0414468050003052,
      "eval_r": 0.6102789640426636,
      "eval_runtime": 27.4224,
      "eval_samples_per_second": 58.055,
      "eval_steps_per_second": 58.055,
      "step": 549196
    },
    {
      "epoch": 86.05,
      "learning_rate": 5.6976197932978396e-05,
      "loss": 1.0325,
      "step": 549500
    },
    {
      "epoch": 86.13,
      "learning_rate": 5.6937049796429696e-05,
      "loss": 1.0207,
      "step": 550000
    },
    {
      "epoch": 86.2,
      "learning_rate": 5.689790165988099e-05,
      "loss": 1.0352,
      "step": 550500
    },
    {
      "epoch": 86.28,
      "learning_rate": 5.6858753523332296e-05,
      "loss": 1.0036,
      "step": 551000
    },
    {
      "epoch": 86.36,
      "learning_rate": 5.681960538678359e-05,
      "loss": 1.0461,
      "step": 551500
    },
    {
      "epoch": 86.44,
      "learning_rate": 5.678045725023488e-05,
      "loss": 1.0348,
      "step": 552000
    },
    {
      "epoch": 86.52,
      "learning_rate": 5.674130911368619e-05,
      "loss": 1.0326,
      "step": 552500
    },
    {
      "epoch": 86.6,
      "learning_rate": 5.6702160977137484e-05,
      "loss": 1.0444,
      "step": 553000
    },
    {
      "epoch": 86.67,
      "learning_rate": 5.666301284058879e-05,
      "loss": 1.0186,
      "step": 553500
    },
    {
      "epoch": 86.75,
      "learning_rate": 5.6623864704040084e-05,
      "loss": 1.0284,
      "step": 554000
    },
    {
      "epoch": 86.83,
      "learning_rate": 5.658471656749139e-05,
      "loss": 1.0194,
      "step": 554500
    },
    {
      "epoch": 86.91,
      "learning_rate": 5.6545568430942685e-05,
      "loss": 1.0513,
      "step": 555000
    },
    {
      "epoch": 86.99,
      "learning_rate": 5.650642029439399e-05,
      "loss": 1.0248,
      "step": 555500
    },
    {
      "epoch": 87.0,
      "eval_loss": 1.0350291728973389,
      "eval_r": 0.6101319789886475,
      "eval_runtime": 27.4562,
      "eval_samples_per_second": 57.983,
      "eval_steps_per_second": 57.983,
      "step": 555582
    },
    {
      "epoch": 87.07,
      "learning_rate": 5.6467272157845285e-05,
      "loss": 1.017,
      "step": 556000
    },
    {
      "epoch": 87.14,
      "learning_rate": 5.642812402129659e-05,
      "loss": 1.0251,
      "step": 556500
    },
    {
      "epoch": 87.22,
      "learning_rate": 5.6388975884747885e-05,
      "loss": 1.0235,
      "step": 557000
    },
    {
      "epoch": 87.3,
      "learning_rate": 5.634982774819919e-05,
      "loss": 1.0111,
      "step": 557500
    },
    {
      "epoch": 87.38,
      "learning_rate": 5.6310679611650486e-05,
      "loss": 1.041,
      "step": 558000
    },
    {
      "epoch": 87.46,
      "learning_rate": 5.627153147510179e-05,
      "loss": 1.0113,
      "step": 558500
    },
    {
      "epoch": 87.54,
      "learning_rate": 5.6232383338553086e-05,
      "loss": 1.0321,
      "step": 559000
    },
    {
      "epoch": 87.61,
      "learning_rate": 5.619323520200439e-05,
      "loss": 1.0372,
      "step": 559500
    },
    {
      "epoch": 87.69,
      "learning_rate": 5.615408706545569e-05,
      "loss": 1.0277,
      "step": 560000
    },
    {
      "epoch": 87.77,
      "learning_rate": 5.6114938928906994e-05,
      "loss": 1.0515,
      "step": 560500
    },
    {
      "epoch": 87.85,
      "learning_rate": 5.607579079235829e-05,
      "loss": 1.0232,
      "step": 561000
    },
    {
      "epoch": 87.93,
      "learning_rate": 5.603664265580959e-05,
      "loss": 1.0507,
      "step": 561500
    },
    {
      "epoch": 88.0,
      "eval_loss": 1.0321292877197266,
      "eval_r": 0.6116432547569275,
      "eval_runtime": 27.6867,
      "eval_samples_per_second": 57.5,
      "eval_steps_per_second": 57.5,
      "step": 561968
    },
    {
      "epoch": 88.01,
      "learning_rate": 5.599749451926089e-05,
      "loss": 1.0354,
      "step": 562000
    },
    {
      "epoch": 88.08,
      "learning_rate": 5.595834638271219e-05,
      "loss": 1.0036,
      "step": 562500
    },
    {
      "epoch": 88.16,
      "learning_rate": 5.591919824616348e-05,
      "loss": 1.0231,
      "step": 563000
    },
    {
      "epoch": 88.24,
      "learning_rate": 5.588005010961479e-05,
      "loss": 1.014,
      "step": 563500
    },
    {
      "epoch": 88.32,
      "learning_rate": 5.584090197306608e-05,
      "loss": 1.005,
      "step": 564000
    },
    {
      "epoch": 88.4,
      "learning_rate": 5.580175383651739e-05,
      "loss": 1.0404,
      "step": 564500
    },
    {
      "epoch": 88.47,
      "learning_rate": 5.576260569996868e-05,
      "loss": 1.0374,
      "step": 565000
    },
    {
      "epoch": 88.55,
      "learning_rate": 5.5723457563419976e-05,
      "loss": 1.0439,
      "step": 565500
    },
    {
      "epoch": 88.63,
      "learning_rate": 5.568430942687128e-05,
      "loss": 1.0383,
      "step": 566000
    },
    {
      "epoch": 88.71,
      "learning_rate": 5.5645161290322576e-05,
      "loss": 1.0404,
      "step": 566500
    },
    {
      "epoch": 88.79,
      "learning_rate": 5.560601315377388e-05,
      "loss": 1.0334,
      "step": 567000
    },
    {
      "epoch": 88.87,
      "learning_rate": 5.5566865017225176e-05,
      "loss": 1.0526,
      "step": 567500
    },
    {
      "epoch": 88.94,
      "learning_rate": 5.5527716880676483e-05,
      "loss": 1.039,
      "step": 568000
    },
    {
      "epoch": 89.0,
      "eval_loss": 1.0422556400299072,
      "eval_r": 0.6113349199295044,
      "eval_runtime": 27.6075,
      "eval_samples_per_second": 57.666,
      "eval_steps_per_second": 57.666,
      "step": 568354
    },
    {
      "epoch": 89.02,
      "learning_rate": 5.548856874412778e-05,
      "loss": 1.0162,
      "step": 568500
    },
    {
      "epoch": 89.1,
      "learning_rate": 5.5449420607579084e-05,
      "loss": 1.0404,
      "step": 569000
    },
    {
      "epoch": 89.18,
      "learning_rate": 5.541027247103038e-05,
      "loss": 1.0293,
      "step": 569500
    },
    {
      "epoch": 89.26,
      "learning_rate": 5.5371124334481684e-05,
      "loss": 1.0492,
      "step": 570000
    },
    {
      "epoch": 89.34,
      "learning_rate": 5.533197619793298e-05,
      "loss": 1.0206,
      "step": 570500
    },
    {
      "epoch": 89.41,
      "learning_rate": 5.5292828061384285e-05,
      "loss": 1.0266,
      "step": 571000
    },
    {
      "epoch": 89.49,
      "learning_rate": 5.525367992483558e-05,
      "loss": 1.0052,
      "step": 571500
    },
    {
      "epoch": 89.57,
      "learning_rate": 5.5214531788286885e-05,
      "loss": 1.0343,
      "step": 572000
    },
    {
      "epoch": 89.65,
      "learning_rate": 5.517538365173818e-05,
      "loss": 1.0318,
      "step": 572500
    },
    {
      "epoch": 89.73,
      "learning_rate": 5.5136235515189486e-05,
      "loss": 1.0232,
      "step": 573000
    },
    {
      "epoch": 89.81,
      "learning_rate": 5.509708737864078e-05,
      "loss": 1.0269,
      "step": 573500
    },
    {
      "epoch": 89.88,
      "learning_rate": 5.505793924209208e-05,
      "loss": 1.0381,
      "step": 574000
    },
    {
      "epoch": 89.96,
      "learning_rate": 5.501879110554338e-05,
      "loss": 1.0111,
      "step": 574500
    },
    {
      "epoch": 90.0,
      "eval_loss": 1.0367790460586548,
      "eval_r": 0.6103259325027466,
      "eval_runtime": 27.6619,
      "eval_samples_per_second": 57.552,
      "eval_steps_per_second": 57.552,
      "step": 574740
    },
    {
      "epoch": 90.04,
      "learning_rate": 5.497964296899468e-05,
      "loss": 1.0313,
      "step": 575000
    },
    {
      "epoch": 90.12,
      "learning_rate": 5.494049483244598e-05,
      "loss": 1.034,
      "step": 575500
    },
    {
      "epoch": 90.2,
      "learning_rate": 5.490134669589728e-05,
      "loss": 1.012,
      "step": 576000
    },
    {
      "epoch": 90.28,
      "learning_rate": 5.4862198559348574e-05,
      "loss": 1.0127,
      "step": 576500
    },
    {
      "epoch": 90.35,
      "learning_rate": 5.482305042279988e-05,
      "loss": 1.0152,
      "step": 577000
    },
    {
      "epoch": 90.43,
      "learning_rate": 5.4783902286251174e-05,
      "loss": 1.0219,
      "step": 577500
    },
    {
      "epoch": 90.51,
      "learning_rate": 5.474475414970248e-05,
      "loss": 1.0336,
      "step": 578000
    },
    {
      "epoch": 90.59,
      "learning_rate": 5.4705606013153774e-05,
      "loss": 1.0253,
      "step": 578500
    },
    {
      "epoch": 90.67,
      "learning_rate": 5.466645787660508e-05,
      "loss": 1.0261,
      "step": 579000
    },
    {
      "epoch": 90.75,
      "learning_rate": 5.4627309740056375e-05,
      "loss": 1.0274,
      "step": 579500
    },
    {
      "epoch": 90.82,
      "learning_rate": 5.458816160350767e-05,
      "loss": 1.0376,
      "step": 580000
    },
    {
      "epoch": 90.9,
      "learning_rate": 5.4549013466958975e-05,
      "loss": 1.0532,
      "step": 580500
    },
    {
      "epoch": 90.98,
      "learning_rate": 5.450986533041027e-05,
      "loss": 1.0259,
      "step": 581000
    },
    {
      "epoch": 91.0,
      "eval_loss": 1.0361043214797974,
      "eval_r": 0.6108999848365784,
      "eval_runtime": 27.4449,
      "eval_samples_per_second": 58.007,
      "eval_steps_per_second": 58.007,
      "step": 581126
    },
    {
      "epoch": 91.06,
      "learning_rate": 5.4470717193861576e-05,
      "loss": 1.0173,
      "step": 581500
    },
    {
      "epoch": 91.14,
      "learning_rate": 5.443156905731287e-05,
      "loss": 1.0346,
      "step": 582000
    },
    {
      "epoch": 91.22,
      "learning_rate": 5.4392420920764176e-05,
      "loss": 1.0215,
      "step": 582500
    },
    {
      "epoch": 91.29,
      "learning_rate": 5.435327278421547e-05,
      "loss": 1.0348,
      "step": 583000
    },
    {
      "epoch": 91.37,
      "learning_rate": 5.431412464766678e-05,
      "loss": 1.0206,
      "step": 583500
    },
    {
      "epoch": 91.45,
      "learning_rate": 5.427497651111807e-05,
      "loss": 1.038,
      "step": 584000
    },
    {
      "epoch": 91.53,
      "learning_rate": 5.423582837456938e-05,
      "loss": 1.0421,
      "step": 584500
    },
    {
      "epoch": 91.61,
      "learning_rate": 5.419668023802067e-05,
      "loss": 1.0309,
      "step": 585000
    },
    {
      "epoch": 91.68,
      "learning_rate": 5.415753210147198e-05,
      "loss": 1.0322,
      "step": 585500
    },
    {
      "epoch": 91.76,
      "learning_rate": 5.411838396492327e-05,
      "loss": 1.0407,
      "step": 586000
    },
    {
      "epoch": 91.84,
      "learning_rate": 5.407923582837458e-05,
      "loss": 0.9918,
      "step": 586500
    },
    {
      "epoch": 91.92,
      "learning_rate": 5.404008769182587e-05,
      "loss": 1.0316,
      "step": 587000
    },
    {
      "epoch": 92.0,
      "learning_rate": 5.400093955527717e-05,
      "loss": 1.0266,
      "step": 587500
    },
    {
      "epoch": 92.0,
      "eval_loss": 1.036760687828064,
      "eval_r": 0.6101949214935303,
      "eval_runtime": 27.3373,
      "eval_samples_per_second": 58.235,
      "eval_steps_per_second": 58.235,
      "step": 587512
    },
    {
      "epoch": 92.08,
      "learning_rate": 5.396179141872847e-05,
      "loss": 1.0362,
      "step": 588000
    },
    {
      "epoch": 92.15,
      "learning_rate": 5.392264328217977e-05,
      "loss": 1.0283,
      "step": 588500
    },
    {
      "epoch": 92.23,
      "learning_rate": 5.3883495145631065e-05,
      "loss": 1.0459,
      "step": 589000
    },
    {
      "epoch": 92.31,
      "learning_rate": 5.384434700908237e-05,
      "loss": 1.0413,
      "step": 589500
    },
    {
      "epoch": 92.39,
      "learning_rate": 5.3805198872533666e-05,
      "loss": 1.0087,
      "step": 590000
    },
    {
      "epoch": 92.47,
      "learning_rate": 5.376605073598497e-05,
      "loss": 1.0278,
      "step": 590500
    },
    {
      "epoch": 92.55,
      "learning_rate": 5.3726902599436266e-05,
      "loss": 1.0271,
      "step": 591000
    },
    {
      "epoch": 92.62,
      "learning_rate": 5.368775446288757e-05,
      "loss": 1.0326,
      "step": 591500
    },
    {
      "epoch": 92.7,
      "learning_rate": 5.364860632633887e-05,
      "loss": 1.0118,
      "step": 592000
    },
    {
      "epoch": 92.78,
      "learning_rate": 5.3609458189790174e-05,
      "loss": 1.026,
      "step": 592500
    },
    {
      "epoch": 92.86,
      "learning_rate": 5.357031005324147e-05,
      "loss": 1.0273,
      "step": 593000
    },
    {
      "epoch": 92.94,
      "learning_rate": 5.353116191669276e-05,
      "loss": 1.0218,
      "step": 593500
    },
    {
      "epoch": 93.0,
      "eval_loss": 1.0339937210083008,
      "eval_r": 0.6118013262748718,
      "eval_runtime": 27.3741,
      "eval_samples_per_second": 58.157,
      "eval_steps_per_second": 58.157,
      "step": 593898
    },
    {
      "epoch": 93.02,
      "learning_rate": 5.349201378014407e-05,
      "loss": 1.0239,
      "step": 594000
    },
    {
      "epoch": 93.09,
      "learning_rate": 5.345286564359536e-05,
      "loss": 1.0259,
      "step": 594500
    },
    {
      "epoch": 93.17,
      "learning_rate": 5.341371750704667e-05,
      "loss": 1.0039,
      "step": 595000
    },
    {
      "epoch": 93.25,
      "learning_rate": 5.337456937049796e-05,
      "loss": 1.0198,
      "step": 595500
    },
    {
      "epoch": 93.33,
      "learning_rate": 5.333542123394927e-05,
      "loss": 1.0173,
      "step": 596000
    },
    {
      "epoch": 93.41,
      "learning_rate": 5.329627309740056e-05,
      "loss": 1.031,
      "step": 596500
    },
    {
      "epoch": 93.49,
      "learning_rate": 5.325712496085187e-05,
      "loss": 1.0427,
      "step": 597000
    },
    {
      "epoch": 93.56,
      "learning_rate": 5.321797682430316e-05,
      "loss": 1.0527,
      "step": 597500
    },
    {
      "epoch": 93.64,
      "learning_rate": 5.317882868775447e-05,
      "loss": 1.0246,
      "step": 598000
    },
    {
      "epoch": 93.72,
      "learning_rate": 5.313968055120576e-05,
      "loss": 1.0158,
      "step": 598500
    },
    {
      "epoch": 93.8,
      "learning_rate": 5.310053241465707e-05,
      "loss": 1.0285,
      "step": 599000
    },
    {
      "epoch": 93.88,
      "learning_rate": 5.306138427810836e-05,
      "loss": 1.0055,
      "step": 599500
    },
    {
      "epoch": 93.96,
      "learning_rate": 5.302223614155967e-05,
      "loss": 1.0299,
      "step": 600000
    },
    {
      "epoch": 94.0,
      "eval_loss": 1.0342360734939575,
      "eval_r": 0.6105508208274841,
      "eval_runtime": 27.5044,
      "eval_samples_per_second": 57.882,
      "eval_steps_per_second": 57.882,
      "step": 600284
    },
    {
      "epoch": 94.03,
      "learning_rate": 5.2983088005010964e-05,
      "loss": 1.0218,
      "step": 600500
    },
    {
      "epoch": 94.11,
      "learning_rate": 5.2943939868462264e-05,
      "loss": 1.029,
      "step": 601000
    },
    {
      "epoch": 94.19,
      "learning_rate": 5.2904791731913564e-05,
      "loss": 1.0195,
      "step": 601500
    },
    {
      "epoch": 94.27,
      "learning_rate": 5.2865643595364864e-05,
      "loss": 1.0544,
      "step": 602000
    },
    {
      "epoch": 94.35,
      "learning_rate": 5.282649545881616e-05,
      "loss": 1.014,
      "step": 602500
    },
    {
      "epoch": 94.43,
      "learning_rate": 5.2787347322267465e-05,
      "loss": 1.0141,
      "step": 603000
    },
    {
      "epoch": 94.5,
      "learning_rate": 5.274819918571876e-05,
      "loss": 1.0364,
      "step": 603500
    },
    {
      "epoch": 94.58,
      "learning_rate": 5.2709051049170065e-05,
      "loss": 1.0291,
      "step": 604000
    },
    {
      "epoch": 94.66,
      "learning_rate": 5.266990291262136e-05,
      "loss": 1.0229,
      "step": 604500
    },
    {
      "epoch": 94.74,
      "learning_rate": 5.2630754776072666e-05,
      "loss": 1.0209,
      "step": 605000
    },
    {
      "epoch": 94.82,
      "learning_rate": 5.259160663952396e-05,
      "loss": 1.0304,
      "step": 605500
    },
    {
      "epoch": 94.9,
      "learning_rate": 5.2552458502975266e-05,
      "loss": 1.0152,
      "step": 606000
    },
    {
      "epoch": 94.97,
      "learning_rate": 5.251331036642656e-05,
      "loss": 1.0215,
      "step": 606500
    },
    {
      "epoch": 95.0,
      "eval_loss": 1.0346684455871582,
      "eval_r": 0.6115021705627441,
      "eval_runtime": 27.3931,
      "eval_samples_per_second": 58.117,
      "eval_steps_per_second": 58.117,
      "step": 606670
    },
    {
      "epoch": 95.05,
      "learning_rate": 5.2474162229877867e-05,
      "loss": 1.0497,
      "step": 607000
    },
    {
      "epoch": 95.13,
      "learning_rate": 5.243501409332916e-05,
      "loss": 1.0167,
      "step": 607500
    },
    {
      "epoch": 95.21,
      "learning_rate": 5.2395865956780453e-05,
      "loss": 1.0237,
      "step": 608000
    },
    {
      "epoch": 95.29,
      "learning_rate": 5.235671782023176e-05,
      "loss": 1.0143,
      "step": 608500
    },
    {
      "epoch": 95.36,
      "learning_rate": 5.2317569683683054e-05,
      "loss": 1.027,
      "step": 609000
    },
    {
      "epoch": 95.44,
      "learning_rate": 5.227842154713436e-05,
      "loss": 1.0144,
      "step": 609500
    },
    {
      "epoch": 95.52,
      "learning_rate": 5.2239273410585654e-05,
      "loss": 1.0391,
      "step": 610000
    },
    {
      "epoch": 95.6,
      "learning_rate": 5.220012527403696e-05,
      "loss": 1.0146,
      "step": 610500
    },
    {
      "epoch": 95.68,
      "learning_rate": 5.2160977137488255e-05,
      "loss": 1.0313,
      "step": 611000
    },
    {
      "epoch": 95.76,
      "learning_rate": 5.212182900093956e-05,
      "loss": 1.0146,
      "step": 611500
    },
    {
      "epoch": 95.83,
      "learning_rate": 5.2082680864390855e-05,
      "loss": 1.0238,
      "step": 612000
    },
    {
      "epoch": 95.91,
      "learning_rate": 5.204353272784216e-05,
      "loss": 1.0105,
      "step": 612500
    },
    {
      "epoch": 95.99,
      "learning_rate": 5.2004384591293456e-05,
      "loss": 1.0382,
      "step": 613000
    },
    {
      "epoch": 96.0,
      "eval_loss": 1.042000651359558,
      "eval_r": 0.611724317073822,
      "eval_runtime": 27.5672,
      "eval_samples_per_second": 57.75,
      "eval_steps_per_second": 57.75,
      "step": 613056
    },
    {
      "epoch": 96.07,
      "learning_rate": 5.1965236454744756e-05,
      "loss": 1.0243,
      "step": 613500
    },
    {
      "epoch": 96.15,
      "learning_rate": 5.1926088318196056e-05,
      "loss": 1.0147,
      "step": 614000
    },
    {
      "epoch": 96.23,
      "learning_rate": 5.1886940181647356e-05,
      "loss": 1.0213,
      "step": 614500
    },
    {
      "epoch": 96.3,
      "learning_rate": 5.1847792045098656e-05,
      "loss": 1.0155,
      "step": 615000
    },
    {
      "epoch": 96.38,
      "learning_rate": 5.180864390854996e-05,
      "loss": 1.05,
      "step": 615500
    },
    {
      "epoch": 96.46,
      "learning_rate": 5.176949577200125e-05,
      "loss": 1.0235,
      "step": 616000
    },
    {
      "epoch": 96.54,
      "learning_rate": 5.173034763545256e-05,
      "loss": 1.0216,
      "step": 616500
    },
    {
      "epoch": 96.62,
      "learning_rate": 5.169119949890385e-05,
      "loss": 1.05,
      "step": 617000
    },
    {
      "epoch": 96.7,
      "learning_rate": 5.165205136235516e-05,
      "loss": 1.015,
      "step": 617500
    },
    {
      "epoch": 96.77,
      "learning_rate": 5.161290322580645e-05,
      "loss": 1.015,
      "step": 618000
    },
    {
      "epoch": 96.85,
      "learning_rate": 5.157375508925776e-05,
      "loss": 1.0156,
      "step": 618500
    },
    {
      "epoch": 96.93,
      "learning_rate": 5.153460695270905e-05,
      "loss": 1.0132,
      "step": 619000
    },
    {
      "epoch": 97.0,
      "eval_loss": 1.0382752418518066,
      "eval_r": 0.6108916997909546,
      "eval_runtime": 27.7922,
      "eval_samples_per_second": 57.282,
      "eval_steps_per_second": 57.282,
      "step": 619442
    },
    {
      "epoch": 97.01,
      "learning_rate": 5.149545881616036e-05,
      "loss": 1.0315,
      "step": 619500
    },
    {
      "epoch": 97.09,
      "learning_rate": 5.145631067961165e-05,
      "loss": 1.039,
      "step": 620000
    },
    {
      "epoch": 97.17,
      "learning_rate": 5.141716254306296e-05,
      "loss": 1.0283,
      "step": 620500
    },
    {
      "epoch": 97.24,
      "learning_rate": 5.137801440651425e-05,
      "loss": 1.0228,
      "step": 621000
    },
    {
      "epoch": 97.32,
      "learning_rate": 5.133886626996556e-05,
      "loss": 1.0015,
      "step": 621500
    },
    {
      "epoch": 97.4,
      "learning_rate": 5.129971813341685e-05,
      "loss": 1.0257,
      "step": 622000
    },
    {
      "epoch": 97.48,
      "learning_rate": 5.1260569996868146e-05,
      "loss": 1.0433,
      "step": 622500
    },
    {
      "epoch": 97.56,
      "learning_rate": 5.122142186031945e-05,
      "loss": 1.0304,
      "step": 623000
    },
    {
      "epoch": 97.64,
      "learning_rate": 5.118227372377075e-05,
      "loss": 1.0129,
      "step": 623500
    },
    {
      "epoch": 97.71,
      "learning_rate": 5.1143125587222054e-05,
      "loss": 1.0171,
      "step": 624000
    },
    {
      "epoch": 97.79,
      "learning_rate": 5.110397745067335e-05,
      "loss": 1.0134,
      "step": 624500
    },
    {
      "epoch": 97.87,
      "learning_rate": 5.1064829314124654e-05,
      "loss": 1.013,
      "step": 625000
    },
    {
      "epoch": 97.95,
      "learning_rate": 5.102568117757595e-05,
      "loss": 1.0173,
      "step": 625500
    },
    {
      "epoch": 98.0,
      "eval_loss": 1.03411865234375,
      "eval_r": 0.6116108894348145,
      "eval_runtime": 27.6129,
      "eval_samples_per_second": 57.654,
      "eval_steps_per_second": 57.654,
      "step": 625828
    },
    {
      "epoch": 98.03,
      "learning_rate": 5.0986533041027255e-05,
      "loss": 1.022,
      "step": 626000
    },
    {
      "epoch": 98.11,
      "learning_rate": 5.094738490447855e-05,
      "loss": 1.0081,
      "step": 626500
    },
    {
      "epoch": 98.18,
      "learning_rate": 5.090823676792985e-05,
      "loss": 0.9954,
      "step": 627000
    },
    {
      "epoch": 98.26,
      "learning_rate": 5.086908863138115e-05,
      "loss": 1.0126,
      "step": 627500
    },
    {
      "epoch": 98.34,
      "learning_rate": 5.082994049483245e-05,
      "loss": 1.0185,
      "step": 628000
    },
    {
      "epoch": 98.42,
      "learning_rate": 5.079079235828374e-05,
      "loss": 1.0354,
      "step": 628500
    },
    {
      "epoch": 98.5,
      "learning_rate": 5.075164422173505e-05,
      "loss": 1.0409,
      "step": 629000
    },
    {
      "epoch": 98.58,
      "learning_rate": 5.071249608518634e-05,
      "loss": 1.0296,
      "step": 629500
    },
    {
      "epoch": 98.65,
      "learning_rate": 5.067334794863765e-05,
      "loss": 1.0299,
      "step": 630000
    },
    {
      "epoch": 98.73,
      "learning_rate": 5.063419981208894e-05,
      "loss": 1.0458,
      "step": 630500
    },
    {
      "epoch": 98.81,
      "learning_rate": 5.059505167554025e-05,
      "loss": 1.0218,
      "step": 631000
    },
    {
      "epoch": 98.89,
      "learning_rate": 5.055590353899154e-05,
      "loss": 1.0246,
      "step": 631500
    },
    {
      "epoch": 98.97,
      "learning_rate": 5.051675540244285e-05,
      "loss": 1.0119,
      "step": 632000
    },
    {
      "epoch": 99.0,
      "eval_loss": 1.0337090492248535,
      "eval_r": 0.6119060516357422,
      "eval_runtime": 27.6241,
      "eval_samples_per_second": 57.631,
      "eval_steps_per_second": 57.631,
      "step": 632214
    },
    {
      "epoch": 99.04,
      "learning_rate": 5.0477607265894144e-05,
      "loss": 1.0223,
      "step": 632500
    },
    {
      "epoch": 99.12,
      "learning_rate": 5.043845912934545e-05,
      "loss": 0.9955,
      "step": 633000
    },
    {
      "epoch": 99.2,
      "learning_rate": 5.0399310992796744e-05,
      "loss": 1.0372,
      "step": 633500
    },
    {
      "epoch": 99.28,
      "learning_rate": 5.036016285624805e-05,
      "loss": 1.0211,
      "step": 634000
    },
    {
      "epoch": 99.36,
      "learning_rate": 5.0321014719699345e-05,
      "loss": 1.0396,
      "step": 634500
    },
    {
      "epoch": 99.44,
      "learning_rate": 5.028186658315065e-05,
      "loss": 1.0073,
      "step": 635000
    },
    {
      "epoch": 99.51,
      "learning_rate": 5.0242718446601945e-05,
      "loss": 1.0291,
      "step": 635500
    },
    {
      "epoch": 99.59,
      "learning_rate": 5.020357031005324e-05,
      "loss": 1.0286,
      "step": 636000
    },
    {
      "epoch": 99.67,
      "learning_rate": 5.0164422173504546e-05,
      "loss": 1.0078,
      "step": 636500
    },
    {
      "epoch": 99.75,
      "learning_rate": 5.012527403695584e-05,
      "loss": 1.011,
      "step": 637000
    },
    {
      "epoch": 99.83,
      "learning_rate": 5.0086125900407146e-05,
      "loss": 1.0345,
      "step": 637500
    },
    {
      "epoch": 99.91,
      "learning_rate": 5.004697776385844e-05,
      "loss": 1.0256,
      "step": 638000
    },
    {
      "epoch": 99.98,
      "learning_rate": 5.0007829627309746e-05,
      "loss": 1.0149,
      "step": 638500
    },
    {
      "epoch": 100.0,
      "eval_loss": 1.0373525619506836,
      "eval_r": 0.6094513535499573,
      "eval_runtime": 27.4491,
      "eval_samples_per_second": 57.998,
      "eval_steps_per_second": 57.998,
      "step": 638600
    },
    {
      "epoch": 100.06,
      "learning_rate": 4.996868149076105e-05,
      "loss": 1.0152,
      "step": 639000
    },
    {
      "epoch": 100.14,
      "learning_rate": 4.992953335421234e-05,
      "loss": 1.0136,
      "step": 639500
    },
    {
      "epoch": 100.22,
      "learning_rate": 4.989038521766364e-05,
      "loss": 1.0448,
      "step": 640000
    },
    {
      "epoch": 100.3,
      "learning_rate": 4.985123708111494e-05,
      "loss": 0.9987,
      "step": 640500
    },
    {
      "epoch": 100.38,
      "learning_rate": 4.981208894456624e-05,
      "loss": 1.0034,
      "step": 641000
    },
    {
      "epoch": 100.45,
      "learning_rate": 4.977294080801754e-05,
      "loss": 1.0259,
      "step": 641500
    },
    {
      "epoch": 100.53,
      "learning_rate": 4.973379267146884e-05,
      "loss": 1.0252,
      "step": 642000
    },
    {
      "epoch": 100.61,
      "learning_rate": 4.969464453492014e-05,
      "loss": 1.0282,
      "step": 642500
    },
    {
      "epoch": 100.69,
      "learning_rate": 4.9655496398371435e-05,
      "loss": 1.0231,
      "step": 643000
    },
    {
      "epoch": 100.77,
      "learning_rate": 4.9616348261822735e-05,
      "loss": 1.0147,
      "step": 643500
    },
    {
      "epoch": 100.85,
      "learning_rate": 4.9577200125274035e-05,
      "loss": 1.0296,
      "step": 644000
    },
    {
      "epoch": 100.92,
      "learning_rate": 4.9538051988725335e-05,
      "loss": 1.0128,
      "step": 644500
    },
    {
      "epoch": 101.0,
      "eval_loss": 1.030324935913086,
      "eval_r": 0.6124493479728699,
      "eval_runtime": 27.493,
      "eval_samples_per_second": 57.906,
      "eval_steps_per_second": 57.906,
      "step": 644986
    },
    {
      "epoch": 101.0,
      "learning_rate": 4.9498903852176636e-05,
      "loss": 1.0366,
      "step": 645000
    },
    {
      "epoch": 101.08,
      "learning_rate": 4.9459755715627936e-05,
      "loss": 1.006,
      "step": 645500
    },
    {
      "epoch": 101.16,
      "learning_rate": 4.9420607579079236e-05,
      "loss": 1.0579,
      "step": 646000
    },
    {
      "epoch": 101.24,
      "learning_rate": 4.9381459442530536e-05,
      "loss": 1.0343,
      "step": 646500
    },
    {
      "epoch": 101.32,
      "learning_rate": 4.9342311305981837e-05,
      "loss": 1.0043,
      "step": 647000
    },
    {
      "epoch": 101.39,
      "learning_rate": 4.930316316943314e-05,
      "loss": 1.0013,
      "step": 647500
    },
    {
      "epoch": 101.47,
      "learning_rate": 4.926401503288444e-05,
      "loss": 1.0027,
      "step": 648000
    },
    {
      "epoch": 101.55,
      "learning_rate": 4.922486689633574e-05,
      "loss": 1.0083,
      "step": 648500
    },
    {
      "epoch": 101.63,
      "learning_rate": 4.918571875978704e-05,
      "loss": 1.0381,
      "step": 649000
    },
    {
      "epoch": 101.71,
      "learning_rate": 4.914657062323834e-05,
      "loss": 1.0153,
      "step": 649500
    },
    {
      "epoch": 101.79,
      "learning_rate": 4.910742248668964e-05,
      "loss": 1.0198,
      "step": 650000
    },
    {
      "epoch": 101.86,
      "learning_rate": 4.906827435014094e-05,
      "loss": 1.0195,
      "step": 650500
    },
    {
      "epoch": 101.94,
      "learning_rate": 4.902912621359224e-05,
      "loss": 1.0309,
      "step": 651000
    },
    {
      "epoch": 102.0,
      "eval_loss": 1.0410867929458618,
      "eval_r": 0.611443281173706,
      "eval_runtime": 27.2984,
      "eval_samples_per_second": 58.318,
      "eval_steps_per_second": 58.318,
      "step": 651372
    },
    {
      "epoch": 102.02,
      "learning_rate": 4.898997807704354e-05,
      "loss": 1.0326,
      "step": 651500
    },
    {
      "epoch": 102.1,
      "learning_rate": 4.895082994049484e-05,
      "loss": 1.0281,
      "step": 652000
    },
    {
      "epoch": 102.18,
      "learning_rate": 4.891168180394613e-05,
      "loss": 1.0211,
      "step": 652500
    },
    {
      "epoch": 102.25,
      "learning_rate": 4.887253366739743e-05,
      "loss": 1.0155,
      "step": 653000
    },
    {
      "epoch": 102.33,
      "learning_rate": 4.883338553084873e-05,
      "loss": 1.0171,
      "step": 653500
    },
    {
      "epoch": 102.41,
      "learning_rate": 4.879423739430003e-05,
      "loss": 1.0108,
      "step": 654000
    },
    {
      "epoch": 102.49,
      "learning_rate": 4.875508925775133e-05,
      "loss": 1.0193,
      "step": 654500
    },
    {
      "epoch": 102.57,
      "learning_rate": 4.871594112120263e-05,
      "loss": 1.0243,
      "step": 655000
    },
    {
      "epoch": 102.65,
      "learning_rate": 4.8676792984653934e-05,
      "loss": 1.0358,
      "step": 655500
    },
    {
      "epoch": 102.72,
      "learning_rate": 4.8637644848105234e-05,
      "loss": 1.0182,
      "step": 656000
    },
    {
      "epoch": 102.8,
      "learning_rate": 4.8598496711556534e-05,
      "loss": 1.0223,
      "step": 656500
    },
    {
      "epoch": 102.88,
      "learning_rate": 4.855934857500783e-05,
      "loss": 1.0162,
      "step": 657000
    },
    {
      "epoch": 102.96,
      "learning_rate": 4.852020043845913e-05,
      "loss": 1.0196,
      "step": 657500
    },
    {
      "epoch": 103.0,
      "eval_loss": 1.032089114189148,
      "eval_r": 0.6128045916557312,
      "eval_runtime": 27.1697,
      "eval_samples_per_second": 58.595,
      "eval_steps_per_second": 58.595,
      "step": 657758
    },
    {
      "epoch": 103.04,
      "learning_rate": 4.848105230191043e-05,
      "loss": 1.0073,
      "step": 658000
    },
    {
      "epoch": 103.12,
      "learning_rate": 4.844190416536173e-05,
      "loss": 1.0224,
      "step": 658500
    },
    {
      "epoch": 103.19,
      "learning_rate": 4.840275602881303e-05,
      "loss": 1.0189,
      "step": 659000
    },
    {
      "epoch": 103.27,
      "learning_rate": 4.836360789226433e-05,
      "loss": 1.027,
      "step": 659500
    },
    {
      "epoch": 103.35,
      "learning_rate": 4.832445975571563e-05,
      "loss": 1.0396,
      "step": 660000
    },
    {
      "epoch": 103.43,
      "learning_rate": 4.828531161916693e-05,
      "loss": 1.0301,
      "step": 660500
    },
    {
      "epoch": 103.51,
      "learning_rate": 4.824616348261823e-05,
      "loss": 1.0116,
      "step": 661000
    },
    {
      "epoch": 103.59,
      "learning_rate": 4.820701534606953e-05,
      "loss": 1.0163,
      "step": 661500
    },
    {
      "epoch": 103.66,
      "learning_rate": 4.816786720952083e-05,
      "loss": 0.9985,
      "step": 662000
    },
    {
      "epoch": 103.74,
      "learning_rate": 4.812871907297213e-05,
      "loss": 1.043,
      "step": 662500
    },
    {
      "epoch": 103.82,
      "learning_rate": 4.808957093642343e-05,
      "loss": 1.0018,
      "step": 663000
    },
    {
      "epoch": 103.9,
      "learning_rate": 4.805042279987473e-05,
      "loss": 1.0133,
      "step": 663500
    },
    {
      "epoch": 103.98,
      "learning_rate": 4.801127466332603e-05,
      "loss": 1.0227,
      "step": 664000
    },
    {
      "epoch": 104.0,
      "eval_loss": 1.0364433526992798,
      "eval_r": 0.610726535320282,
      "eval_runtime": 27.4922,
      "eval_samples_per_second": 57.907,
      "eval_steps_per_second": 57.907,
      "step": 664144
    },
    {
      "epoch": 104.06,
      "learning_rate": 4.797212652677733e-05,
      "loss": 1.0081,
      "step": 664500
    },
    {
      "epoch": 104.13,
      "learning_rate": 4.793297839022863e-05,
      "loss": 1.0262,
      "step": 665000
    },
    {
      "epoch": 104.21,
      "learning_rate": 4.789383025367993e-05,
      "loss": 1.012,
      "step": 665500
    },
    {
      "epoch": 104.29,
      "learning_rate": 4.7854682117131225e-05,
      "loss": 1.0327,
      "step": 666000
    },
    {
      "epoch": 104.37,
      "learning_rate": 4.7815533980582525e-05,
      "loss": 1.0143,
      "step": 666500
    },
    {
      "epoch": 104.45,
      "learning_rate": 4.7776385844033825e-05,
      "loss": 1.0056,
      "step": 667000
    },
    {
      "epoch": 104.53,
      "learning_rate": 4.7737237707485125e-05,
      "loss": 1.0211,
      "step": 667500
    },
    {
      "epoch": 104.6,
      "learning_rate": 4.7698089570936425e-05,
      "loss": 1.005,
      "step": 668000
    },
    {
      "epoch": 104.68,
      "learning_rate": 4.7658941434387726e-05,
      "loss": 1.0407,
      "step": 668500
    },
    {
      "epoch": 104.76,
      "learning_rate": 4.7619793297839026e-05,
      "loss": 1.0055,
      "step": 669000
    },
    {
      "epoch": 104.84,
      "learning_rate": 4.7580645161290326e-05,
      "loss": 1.0329,
      "step": 669500
    },
    {
      "epoch": 104.92,
      "learning_rate": 4.7541497024741626e-05,
      "loss": 1.0055,
      "step": 670000
    },
    {
      "epoch": 105.0,
      "learning_rate": 4.7502348888192926e-05,
      "loss": 1.0253,
      "step": 670500
    },
    {
      "epoch": 105.0,
      "eval_loss": 1.0398401021957397,
      "eval_r": 0.6094384789466858,
      "eval_runtime": 27.6042,
      "eval_samples_per_second": 57.672,
      "eval_steps_per_second": 57.672,
      "step": 670530
    },
    {
      "epoch": 105.07,
      "learning_rate": 4.746320075164423e-05,
      "loss": 1.0182,
      "step": 671000
    },
    {
      "epoch": 105.15,
      "learning_rate": 4.742405261509552e-05,
      "loss": 1.0197,
      "step": 671500
    },
    {
      "epoch": 105.23,
      "learning_rate": 4.738490447854682e-05,
      "loss": 1.0103,
      "step": 672000
    },
    {
      "epoch": 105.31,
      "learning_rate": 4.734575634199812e-05,
      "loss": 1.0296,
      "step": 672500
    },
    {
      "epoch": 105.39,
      "learning_rate": 4.730660820544942e-05,
      "loss": 1.0274,
      "step": 673000
    },
    {
      "epoch": 105.47,
      "learning_rate": 4.726746006890072e-05,
      "loss": 1.0089,
      "step": 673500
    },
    {
      "epoch": 105.54,
      "learning_rate": 4.722831193235202e-05,
      "loss": 1.0108,
      "step": 674000
    },
    {
      "epoch": 105.62,
      "learning_rate": 4.718916379580332e-05,
      "loss": 1.0075,
      "step": 674500
    },
    {
      "epoch": 105.7,
      "learning_rate": 4.715001565925462e-05,
      "loss": 1.0082,
      "step": 675000
    },
    {
      "epoch": 105.78,
      "learning_rate": 4.711086752270592e-05,
      "loss": 0.9983,
      "step": 675500
    },
    {
      "epoch": 105.86,
      "learning_rate": 4.707171938615722e-05,
      "loss": 1.0074,
      "step": 676000
    },
    {
      "epoch": 105.93,
      "learning_rate": 4.703257124960852e-05,
      "loss": 1.0517,
      "step": 676500
    },
    {
      "epoch": 106.0,
      "eval_loss": 1.0378881692886353,
      "eval_r": 0.610077440738678,
      "eval_runtime": 27.6602,
      "eval_samples_per_second": 57.556,
      "eval_steps_per_second": 57.556,
      "step": 676916
    },
    {
      "epoch": 106.01,
      "learning_rate": 4.699342311305982e-05,
      "loss": 1.0318,
      "step": 677000
    },
    {
      "epoch": 106.09,
      "learning_rate": 4.695427497651112e-05,
      "loss": 1.0048,
      "step": 677500
    },
    {
      "epoch": 106.17,
      "learning_rate": 4.691512683996242e-05,
      "loss": 1.0194,
      "step": 678000
    },
    {
      "epoch": 106.25,
      "learning_rate": 4.687597870341372e-05,
      "loss": 1.0409,
      "step": 678500
    },
    {
      "epoch": 106.33,
      "learning_rate": 4.683683056686502e-05,
      "loss": 1.0174,
      "step": 679000
    },
    {
      "epoch": 106.4,
      "learning_rate": 4.679768243031632e-05,
      "loss": 1.0136,
      "step": 679500
    },
    {
      "epoch": 106.48,
      "learning_rate": 4.675853429376762e-05,
      "loss": 1.0269,
      "step": 680000
    },
    {
      "epoch": 106.56,
      "learning_rate": 4.671938615721892e-05,
      "loss": 1.0238,
      "step": 680500
    },
    {
      "epoch": 106.64,
      "learning_rate": 4.668023802067022e-05,
      "loss": 0.9904,
      "step": 681000
    },
    {
      "epoch": 106.72,
      "learning_rate": 4.664108988412152e-05,
      "loss": 1.0285,
      "step": 681500
    },
    {
      "epoch": 106.8,
      "learning_rate": 4.660194174757282e-05,
      "loss": 1.0074,
      "step": 682000
    },
    {
      "epoch": 106.87,
      "learning_rate": 4.656279361102412e-05,
      "loss": 1.0268,
      "step": 682500
    },
    {
      "epoch": 106.95,
      "learning_rate": 4.652364547447542e-05,
      "loss": 1.0093,
      "step": 683000
    },
    {
      "epoch": 107.0,
      "eval_loss": 1.0342631340026855,
      "eval_r": 0.6113054156303406,
      "eval_runtime": 28.1685,
      "eval_samples_per_second": 56.517,
      "eval_steps_per_second": 56.517,
      "step": 683302
    },
    {
      "epoch": 107.03,
      "learning_rate": 4.648449733792672e-05,
      "loss": 1.007,
      "step": 683500
    },
    {
      "epoch": 107.11,
      "learning_rate": 4.644534920137802e-05,
      "loss": 1.0046,
      "step": 684000
    },
    {
      "epoch": 107.19,
      "learning_rate": 4.640620106482932e-05,
      "loss": 1.0145,
      "step": 684500
    },
    {
      "epoch": 107.27,
      "learning_rate": 4.636705292828062e-05,
      "loss": 1.0214,
      "step": 685000
    },
    {
      "epoch": 107.34,
      "learning_rate": 4.632790479173191e-05,
      "loss": 1.0067,
      "step": 685500
    },
    {
      "epoch": 107.42,
      "learning_rate": 4.628875665518321e-05,
      "loss": 1.0283,
      "step": 686000
    },
    {
      "epoch": 107.5,
      "learning_rate": 4.624960851863451e-05,
      "loss": 1.0122,
      "step": 686500
    },
    {
      "epoch": 107.58,
      "learning_rate": 4.621046038208581e-05,
      "loss": 0.9975,
      "step": 687000
    },
    {
      "epoch": 107.66,
      "learning_rate": 4.6171312245537114e-05,
      "loss": 1.0157,
      "step": 687500
    },
    {
      "epoch": 107.74,
      "learning_rate": 4.6132164108988414e-05,
      "loss": 1.0285,
      "step": 688000
    },
    {
      "epoch": 107.81,
      "learning_rate": 4.6093015972439714e-05,
      "loss": 1.0401,
      "step": 688500
    },
    {
      "epoch": 107.89,
      "learning_rate": 4.6053867835891014e-05,
      "loss": 1.0341,
      "step": 689000
    },
    {
      "epoch": 107.97,
      "learning_rate": 4.6014719699342314e-05,
      "loss": 0.9945,
      "step": 689500
    },
    {
      "epoch": 108.0,
      "eval_loss": 1.0372947454452515,
      "eval_r": 0.6094934940338135,
      "eval_runtime": 27.7286,
      "eval_samples_per_second": 57.414,
      "eval_steps_per_second": 57.414,
      "step": 689688
    },
    {
      "epoch": 108.05,
      "learning_rate": 4.5975571562793615e-05,
      "loss": 1.0171,
      "step": 690000
    },
    {
      "epoch": 108.13,
      "learning_rate": 4.5936423426244915e-05,
      "loss": 1.0032,
      "step": 690500
    },
    {
      "epoch": 108.21,
      "learning_rate": 4.5897275289696215e-05,
      "loss": 1.0381,
      "step": 691000
    },
    {
      "epoch": 108.28,
      "learning_rate": 4.5858127153147515e-05,
      "loss": 1.0263,
      "step": 691500
    },
    {
      "epoch": 108.36,
      "learning_rate": 4.581897901659881e-05,
      "loss": 0.9859,
      "step": 692000
    },
    {
      "epoch": 108.44,
      "learning_rate": 4.577983088005011e-05,
      "loss": 1.0346,
      "step": 692500
    },
    {
      "epoch": 108.52,
      "learning_rate": 4.574068274350141e-05,
      "loss": 1.0375,
      "step": 693000
    },
    {
      "epoch": 108.6,
      "learning_rate": 4.570153460695271e-05,
      "loss": 1.0184,
      "step": 693500
    },
    {
      "epoch": 108.68,
      "learning_rate": 4.566238647040401e-05,
      "loss": 1.0103,
      "step": 694000
    },
    {
      "epoch": 108.75,
      "learning_rate": 4.562323833385531e-05,
      "loss": 0.9997,
      "step": 694500
    },
    {
      "epoch": 108.83,
      "learning_rate": 4.558409019730661e-05,
      "loss": 1.0261,
      "step": 695000
    },
    {
      "epoch": 108.91,
      "learning_rate": 4.554494206075791e-05,
      "loss": 1.0159,
      "step": 695500
    },
    {
      "epoch": 108.99,
      "learning_rate": 4.550579392420921e-05,
      "loss": 1.0048,
      "step": 696000
    },
    {
      "epoch": 109.0,
      "eval_loss": 1.0379326343536377,
      "eval_r": 0.6093550324440002,
      "eval_runtime": 27.4453,
      "eval_samples_per_second": 58.006,
      "eval_steps_per_second": 58.006,
      "step": 696074
    },
    {
      "epoch": 109.07,
      "learning_rate": 4.546664578766051e-05,
      "loss": 1.0247,
      "step": 696500
    },
    {
      "epoch": 109.15,
      "learning_rate": 4.542749765111181e-05,
      "loss": 1.027,
      "step": 697000
    },
    {
      "epoch": 109.22,
      "learning_rate": 4.538834951456311e-05,
      "loss": 1.0094,
      "step": 697500
    },
    {
      "epoch": 109.3,
      "learning_rate": 4.534920137801441e-05,
      "loss": 1.0415,
      "step": 698000
    },
    {
      "epoch": 109.38,
      "learning_rate": 4.531005324146571e-05,
      "loss": 1.0079,
      "step": 698500
    },
    {
      "epoch": 109.46,
      "learning_rate": 4.527090510491701e-05,
      "loss": 1.0164,
      "step": 699000
    },
    {
      "epoch": 109.54,
      "learning_rate": 4.5231756968368305e-05,
      "loss": 1.0476,
      "step": 699500
    },
    {
      "epoch": 109.61,
      "learning_rate": 4.5192608831819605e-05,
      "loss": 1.0065,
      "step": 700000
    },
    {
      "epoch": 109.69,
      "learning_rate": 4.5153460695270906e-05,
      "loss": 1.0157,
      "step": 700500
    },
    {
      "epoch": 109.77,
      "learning_rate": 4.5114312558722206e-05,
      "loss": 0.9987,
      "step": 701000
    },
    {
      "epoch": 109.85,
      "learning_rate": 4.5075164422173506e-05,
      "loss": 0.9876,
      "step": 701500
    },
    {
      "epoch": 109.93,
      "learning_rate": 4.5036016285624806e-05,
      "loss": 1.0059,
      "step": 702000
    },
    {
      "epoch": 110.0,
      "eval_loss": 1.0358363389968872,
      "eval_r": 0.6102732419967651,
      "eval_runtime": 27.4443,
      "eval_samples_per_second": 58.008,
      "eval_steps_per_second": 58.008,
      "step": 702460
    },
    {
      "epoch": 110.01,
      "learning_rate": 4.4996868149076107e-05,
      "loss": 1.014,
      "step": 702500
    },
    {
      "epoch": 110.08,
      "learning_rate": 4.495772001252741e-05,
      "loss": 1.0027,
      "step": 703000
    },
    {
      "epoch": 110.16,
      "learning_rate": 4.491857187597871e-05,
      "loss": 0.9985,
      "step": 703500
    },
    {
      "epoch": 110.24,
      "learning_rate": 4.487942373943001e-05,
      "loss": 1.0097,
      "step": 704000
    },
    {
      "epoch": 110.32,
      "learning_rate": 4.484027560288131e-05,
      "loss": 1.0255,
      "step": 704500
    },
    {
      "epoch": 110.4,
      "learning_rate": 4.48011274663326e-05,
      "loss": 0.9947,
      "step": 705000
    },
    {
      "epoch": 110.48,
      "learning_rate": 4.47619793297839e-05,
      "loss": 1.0227,
      "step": 705500
    },
    {
      "epoch": 110.55,
      "learning_rate": 4.47228311932352e-05,
      "loss": 1.0121,
      "step": 706000
    },
    {
      "epoch": 110.63,
      "learning_rate": 4.46836830566865e-05,
      "loss": 1.0132,
      "step": 706500
    },
    {
      "epoch": 110.71,
      "learning_rate": 4.46445349201378e-05,
      "loss": 1.0384,
      "step": 707000
    },
    {
      "epoch": 110.79,
      "learning_rate": 4.46053867835891e-05,
      "loss": 1.0089,
      "step": 707500
    },
    {
      "epoch": 110.87,
      "learning_rate": 4.45662386470404e-05,
      "loss": 0.9873,
      "step": 708000
    },
    {
      "epoch": 110.95,
      "learning_rate": 4.45270905104917e-05,
      "loss": 1.0318,
      "step": 708500
    },
    {
      "epoch": 111.0,
      "eval_loss": 1.0394339561462402,
      "eval_r": 0.6082477569580078,
      "eval_runtime": 27.3585,
      "eval_samples_per_second": 58.19,
      "eval_steps_per_second": 58.19,
      "step": 708846
    },
    {
      "epoch": 111.02,
      "learning_rate": 4.4487942373943e-05,
      "loss": 1.0545,
      "step": 709000
    },
    {
      "epoch": 111.1,
      "learning_rate": 4.44487942373943e-05,
      "loss": 1.0341,
      "step": 709500
    },
    {
      "epoch": 111.18,
      "learning_rate": 4.44096461008456e-05,
      "loss": 1.0081,
      "step": 710000
    },
    {
      "epoch": 111.26,
      "learning_rate": 4.43704979642969e-05,
      "loss": 1.0171,
      "step": 710500
    },
    {
      "epoch": 111.34,
      "learning_rate": 4.4331349827748204e-05,
      "loss": 0.9899,
      "step": 711000
    },
    {
      "epoch": 111.42,
      "learning_rate": 4.4292201691199504e-05,
      "loss": 0.9981,
      "step": 711500
    },
    {
      "epoch": 111.49,
      "learning_rate": 4.4253053554650804e-05,
      "loss": 1.0112,
      "step": 712000
    },
    {
      "epoch": 111.57,
      "learning_rate": 4.4213905418102104e-05,
      "loss": 1.0158,
      "step": 712500
    },
    {
      "epoch": 111.65,
      "learning_rate": 4.4174757281553404e-05,
      "loss": 1.0167,
      "step": 713000
    },
    {
      "epoch": 111.73,
      "learning_rate": 4.41356091450047e-05,
      "loss": 1.027,
      "step": 713500
    },
    {
      "epoch": 111.81,
      "learning_rate": 4.4096461008456e-05,
      "loss": 1.0083,
      "step": 714000
    },
    {
      "epoch": 111.89,
      "learning_rate": 4.40573128719073e-05,
      "loss": 1.019,
      "step": 714500
    },
    {
      "epoch": 111.96,
      "learning_rate": 4.40181647353586e-05,
      "loss": 0.9993,
      "step": 715000
    },
    {
      "epoch": 112.0,
      "eval_loss": 1.0349467992782593,
      "eval_r": 0.6119052767753601,
      "eval_runtime": 27.6583,
      "eval_samples_per_second": 57.56,
      "eval_steps_per_second": 57.56,
      "step": 715232
    },
    {
      "epoch": 112.04,
      "learning_rate": 4.39790165988099e-05,
      "loss": 1.0206,
      "step": 715500
    },
    {
      "epoch": 112.12,
      "learning_rate": 4.39398684622612e-05,
      "loss": 1.0099,
      "step": 716000
    },
    {
      "epoch": 112.2,
      "learning_rate": 4.39007203257125e-05,
      "loss": 1.0103,
      "step": 716500
    },
    {
      "epoch": 112.28,
      "learning_rate": 4.38615721891638e-05,
      "loss": 0.9993,
      "step": 717000
    },
    {
      "epoch": 112.36,
      "learning_rate": 4.38224240526151e-05,
      "loss": 1.0231,
      "step": 717500
    },
    {
      "epoch": 112.43,
      "learning_rate": 4.378327591606639e-05,
      "loss": 0.9949,
      "step": 718000
    },
    {
      "epoch": 112.51,
      "learning_rate": 4.374412777951769e-05,
      "loss": 1.0198,
      "step": 718500
    },
    {
      "epoch": 112.59,
      "learning_rate": 4.3704979642968993e-05,
      "loss": 1.035,
      "step": 719000
    },
    {
      "epoch": 112.67,
      "learning_rate": 4.3665831506420294e-05,
      "loss": 1.0196,
      "step": 719500
    },
    {
      "epoch": 112.75,
      "learning_rate": 4.3626683369871594e-05,
      "loss": 1.0093,
      "step": 720000
    },
    {
      "epoch": 112.82,
      "learning_rate": 4.3587535233322894e-05,
      "loss": 1.0265,
      "step": 720500
    },
    {
      "epoch": 112.9,
      "learning_rate": 4.3548387096774194e-05,
      "loss": 0.999,
      "step": 721000
    },
    {
      "epoch": 112.98,
      "learning_rate": 4.3509238960225495e-05,
      "loss": 1.021,
      "step": 721500
    },
    {
      "epoch": 113.0,
      "eval_loss": 1.0334231853485107,
      "eval_r": 0.6116122603416443,
      "eval_runtime": 27.2825,
      "eval_samples_per_second": 58.352,
      "eval_steps_per_second": 58.352,
      "step": 721618
    },
    {
      "epoch": 113.06,
      "learning_rate": 4.3470090823676795e-05,
      "loss": 1.0189,
      "step": 722000
    },
    {
      "epoch": 113.14,
      "learning_rate": 4.3430942687128095e-05,
      "loss": 1.0164,
      "step": 722500
    },
    {
      "epoch": 113.22,
      "learning_rate": 4.3391794550579395e-05,
      "loss": 1.0239,
      "step": 723000
    },
    {
      "epoch": 113.29,
      "learning_rate": 4.3352646414030695e-05,
      "loss": 1.004,
      "step": 723500
    },
    {
      "epoch": 113.37,
      "learning_rate": 4.3313498277481996e-05,
      "loss": 1.0118,
      "step": 724000
    },
    {
      "epoch": 113.45,
      "learning_rate": 4.3274350140933296e-05,
      "loss": 1.0183,
      "step": 724500
    },
    {
      "epoch": 113.53,
      "learning_rate": 4.3235202004384596e-05,
      "loss": 0.9993,
      "step": 725000
    },
    {
      "epoch": 113.61,
      "learning_rate": 4.3196053867835896e-05,
      "loss": 1.0009,
      "step": 725500
    },
    {
      "epoch": 113.69,
      "learning_rate": 4.3156905731287197e-05,
      "loss": 1.0147,
      "step": 726000
    },
    {
      "epoch": 113.76,
      "learning_rate": 4.31177575947385e-05,
      "loss": 1.0008,
      "step": 726500
    },
    {
      "epoch": 113.84,
      "learning_rate": 4.30786094581898e-05,
      "loss": 1.0276,
      "step": 727000
    },
    {
      "epoch": 113.92,
      "learning_rate": 4.30394613216411e-05,
      "loss": 1.0335,
      "step": 727500
    },
    {
      "epoch": 114.0,
      "learning_rate": 4.300031318509239e-05,
      "loss": 1.0047,
      "step": 728000
    },
    {
      "epoch": 114.0,
      "eval_loss": 1.0380587577819824,
      "eval_r": 0.6105841398239136,
      "eval_runtime": 27.4152,
      "eval_samples_per_second": 58.07,
      "eval_steps_per_second": 58.07,
      "step": 728004
    },
    {
      "epoch": 114.08,
      "learning_rate": 4.296116504854369e-05,
      "loss": 1.0109,
      "step": 728500
    },
    {
      "epoch": 114.16,
      "learning_rate": 4.292201691199499e-05,
      "loss": 1.0053,
      "step": 729000
    },
    {
      "epoch": 114.23,
      "learning_rate": 4.288286877544629e-05,
      "loss": 0.9891,
      "step": 729500
    },
    {
      "epoch": 114.31,
      "learning_rate": 4.284372063889759e-05,
      "loss": 1.0424,
      "step": 730000
    },
    {
      "epoch": 114.39,
      "learning_rate": 4.280457250234889e-05,
      "loss": 1.0179,
      "step": 730500
    },
    {
      "epoch": 114.47,
      "learning_rate": 4.2765424365800185e-05,
      "loss": 1.0135,
      "step": 731000
    },
    {
      "epoch": 114.55,
      "learning_rate": 4.2726276229251485e-05,
      "loss": 1.0331,
      "step": 731500
    },
    {
      "epoch": 114.63,
      "learning_rate": 4.2687128092702786e-05,
      "loss": 1.0236,
      "step": 732000
    },
    {
      "epoch": 114.7,
      "learning_rate": 4.2647979956154086e-05,
      "loss": 1.0122,
      "step": 732500
    },
    {
      "epoch": 114.78,
      "learning_rate": 4.2608831819605386e-05,
      "loss": 1.0143,
      "step": 733000
    },
    {
      "epoch": 114.86,
      "learning_rate": 4.2569683683056686e-05,
      "loss": 0.9967,
      "step": 733500
    },
    {
      "epoch": 114.94,
      "learning_rate": 4.2530535546507986e-05,
      "loss": 1.0115,
      "step": 734000
    },
    {
      "epoch": 115.0,
      "eval_loss": 1.0320621728897095,
      "eval_r": 0.6120530366897583,
      "eval_runtime": 27.3815,
      "eval_samples_per_second": 58.141,
      "eval_steps_per_second": 58.141,
      "step": 734390
    },
    {
      "epoch": 115.02,
      "learning_rate": 4.249138740995929e-05,
      "loss": 1.0203,
      "step": 734500
    },
    {
      "epoch": 115.1,
      "learning_rate": 4.245223927341059e-05,
      "loss": 0.9912,
      "step": 735000
    },
    {
      "epoch": 115.17,
      "learning_rate": 4.241309113686189e-05,
      "loss": 1.0029,
      "step": 735500
    },
    {
      "epoch": 115.25,
      "learning_rate": 4.237394300031319e-05,
      "loss": 0.9907,
      "step": 736000
    },
    {
      "epoch": 115.33,
      "learning_rate": 4.233479486376449e-05,
      "loss": 0.9966,
      "step": 736500
    },
    {
      "epoch": 115.41,
      "learning_rate": 4.229564672721579e-05,
      "loss": 1.0156,
      "step": 737000
    },
    {
      "epoch": 115.49,
      "learning_rate": 4.225649859066709e-05,
      "loss": 1.0231,
      "step": 737500
    },
    {
      "epoch": 115.57,
      "learning_rate": 4.221735045411839e-05,
      "loss": 1.0143,
      "step": 738000
    },
    {
      "epoch": 115.64,
      "learning_rate": 4.217820231756969e-05,
      "loss": 1.0226,
      "step": 738500
    },
    {
      "epoch": 115.72,
      "learning_rate": 4.213905418102099e-05,
      "loss": 0.9995,
      "step": 739000
    },
    {
      "epoch": 115.8,
      "learning_rate": 4.209990604447229e-05,
      "loss": 1.0295,
      "step": 739500
    },
    {
      "epoch": 115.88,
      "learning_rate": 4.206075790792359e-05,
      "loss": 1.0129,
      "step": 740000
    },
    {
      "epoch": 115.96,
      "learning_rate": 4.202160977137489e-05,
      "loss": 1.0253,
      "step": 740500
    },
    {
      "epoch": 116.0,
      "eval_loss": 1.0403352975845337,
      "eval_r": 0.6099599599838257,
      "eval_runtime": 26.8922,
      "eval_samples_per_second": 59.199,
      "eval_steps_per_second": 59.199,
      "step": 740776
    },
    {
      "epoch": 116.04,
      "learning_rate": 4.198246163482619e-05,
      "loss": 0.9933,
      "step": 741000
    },
    {
      "epoch": 116.11,
      "learning_rate": 4.194331349827749e-05,
      "loss": 0.9922,
      "step": 741500
    },
    {
      "epoch": 116.19,
      "learning_rate": 4.190416536172878e-05,
      "loss": 1.02,
      "step": 742000
    },
    {
      "epoch": 116.27,
      "learning_rate": 4.186501722518008e-05,
      "loss": 1.0186,
      "step": 742500
    },
    {
      "epoch": 116.35,
      "learning_rate": 4.1825869088631384e-05,
      "loss": 1.0221,
      "step": 743000
    },
    {
      "epoch": 116.43,
      "learning_rate": 4.1786720952082684e-05,
      "loss": 1.0029,
      "step": 743500
    },
    {
      "epoch": 116.5,
      "learning_rate": 4.1747572815533984e-05,
      "loss": 1.0042,
      "step": 744000
    },
    {
      "epoch": 116.58,
      "learning_rate": 4.170842467898528e-05,
      "loss": 1.0188,
      "step": 744500
    },
    {
      "epoch": 116.66,
      "learning_rate": 4.166927654243658e-05,
      "loss": 1.0135,
      "step": 745000
    },
    {
      "epoch": 116.74,
      "learning_rate": 4.163012840588788e-05,
      "loss": 0.9941,
      "step": 745500
    },
    {
      "epoch": 116.82,
      "learning_rate": 4.159098026933918e-05,
      "loss": 1.0321,
      "step": 746000
    },
    {
      "epoch": 116.9,
      "learning_rate": 4.155183213279048e-05,
      "loss": 1.0174,
      "step": 746500
    },
    {
      "epoch": 116.97,
      "learning_rate": 4.151268399624178e-05,
      "loss": 1.0294,
      "step": 747000
    },
    {
      "epoch": 117.0,
      "eval_loss": 1.038923978805542,
      "eval_r": 0.6102030277252197,
      "eval_runtime": 27.5369,
      "eval_samples_per_second": 57.813,
      "eval_steps_per_second": 57.813,
      "step": 747162
    },
    {
      "epoch": 117.05,
      "learning_rate": 4.147353585969308e-05,
      "loss": 1.0144,
      "step": 747500
    },
    {
      "epoch": 117.13,
      "learning_rate": 4.143438772314438e-05,
      "loss": 1.0075,
      "step": 748000
    },
    {
      "epoch": 117.21,
      "learning_rate": 4.139523958659568e-05,
      "loss": 1.0178,
      "step": 748500
    },
    {
      "epoch": 117.29,
      "learning_rate": 4.135609145004698e-05,
      "loss": 1.0065,
      "step": 749000
    },
    {
      "epoch": 117.37,
      "learning_rate": 4.131694331349828e-05,
      "loss": 0.9998,
      "step": 749500
    },
    {
      "epoch": 117.44,
      "learning_rate": 4.127779517694958e-05,
      "loss": 1.0169,
      "step": 750000
    },
    {
      "epoch": 117.52,
      "learning_rate": 4.123864704040088e-05,
      "loss": 1.0249,
      "step": 750500
    },
    {
      "epoch": 117.6,
      "learning_rate": 4.119949890385218e-05,
      "loss": 0.9829,
      "step": 751000
    },
    {
      "epoch": 117.68,
      "learning_rate": 4.116035076730348e-05,
      "loss": 1.0124,
      "step": 751500
    },
    {
      "epoch": 117.76,
      "learning_rate": 4.112120263075478e-05,
      "loss": 1.0318,
      "step": 752000
    },
    {
      "epoch": 117.84,
      "learning_rate": 4.108205449420608e-05,
      "loss": 1.0076,
      "step": 752500
    },
    {
      "epoch": 117.91,
      "learning_rate": 4.104290635765738e-05,
      "loss": 1.028,
      "step": 753000
    },
    {
      "epoch": 117.99,
      "learning_rate": 4.100375822110868e-05,
      "loss": 0.9951,
      "step": 753500
    },
    {
      "epoch": 118.0,
      "eval_loss": 1.0349584817886353,
      "eval_r": 0.6119365692138672,
      "eval_runtime": 27.3807,
      "eval_samples_per_second": 58.143,
      "eval_steps_per_second": 58.143,
      "step": 753548
    },
    {
      "epoch": 118.07,
      "learning_rate": 4.096461008455998e-05,
      "loss": 0.9966,
      "step": 754000
    },
    {
      "epoch": 118.15,
      "learning_rate": 4.092546194801128e-05,
      "loss": 1.0019,
      "step": 754500
    },
    {
      "epoch": 118.23,
      "learning_rate": 4.088631381146258e-05,
      "loss": 1.0175,
      "step": 755000
    },
    {
      "epoch": 118.31,
      "learning_rate": 4.0847165674913875e-05,
      "loss": 1.022,
      "step": 755500
    },
    {
      "epoch": 118.38,
      "learning_rate": 4.0808017538365176e-05,
      "loss": 1.0195,
      "step": 756000
    },
    {
      "epoch": 118.46,
      "learning_rate": 4.0768869401816476e-05,
      "loss": 0.9935,
      "step": 756500
    },
    {
      "epoch": 118.54,
      "learning_rate": 4.0729721265267776e-05,
      "loss": 1.0098,
      "step": 757000
    },
    {
      "epoch": 118.62,
      "learning_rate": 4.069057312871907e-05,
      "loss": 1.0186,
      "step": 757500
    },
    {
      "epoch": 118.7,
      "learning_rate": 4.065142499217037e-05,
      "loss": 1.0081,
      "step": 758000
    },
    {
      "epoch": 118.78,
      "learning_rate": 4.061227685562167e-05,
      "loss": 1.0175,
      "step": 758500
    },
    {
      "epoch": 118.85,
      "learning_rate": 4.057312871907297e-05,
      "loss": 1.016,
      "step": 759000
    },
    {
      "epoch": 118.93,
      "learning_rate": 4.053398058252427e-05,
      "loss": 1.0003,
      "step": 759500
    },
    {
      "epoch": 119.0,
      "eval_loss": 1.0348316431045532,
      "eval_r": 0.6104177832603455,
      "eval_runtime": 28.1795,
      "eval_samples_per_second": 56.495,
      "eval_steps_per_second": 56.495,
      "step": 759934
    },
    {
      "epoch": 119.01,
      "learning_rate": 4.049483244597557e-05,
      "loss": 1.0146,
      "step": 760000
    },
    {
      "epoch": 119.09,
      "learning_rate": 4.045568430942687e-05,
      "loss": 1.0013,
      "step": 760500
    },
    {
      "epoch": 119.17,
      "learning_rate": 4.041653617287817e-05,
      "loss": 1.03,
      "step": 761000
    },
    {
      "epoch": 119.25,
      "learning_rate": 4.037738803632947e-05,
      "loss": 1.0052,
      "step": 761500
    },
    {
      "epoch": 119.32,
      "learning_rate": 4.033823989978077e-05,
      "loss": 1.0209,
      "step": 762000
    },
    {
      "epoch": 119.4,
      "learning_rate": 4.029909176323207e-05,
      "loss": 1.0132,
      "step": 762500
    },
    {
      "epoch": 119.48,
      "learning_rate": 4.025994362668337e-05,
      "loss": 0.9992,
      "step": 763000
    },
    {
      "epoch": 119.56,
      "learning_rate": 4.022079549013467e-05,
      "loss": 1.0044,
      "step": 763500
    },
    {
      "epoch": 119.64,
      "learning_rate": 4.018164735358597e-05,
      "loss": 1.0114,
      "step": 764000
    },
    {
      "epoch": 119.72,
      "learning_rate": 4.014249921703727e-05,
      "loss": 1.0188,
      "step": 764500
    },
    {
      "epoch": 119.79,
      "learning_rate": 4.010335108048857e-05,
      "loss": 0.9998,
      "step": 765000
    },
    {
      "epoch": 119.87,
      "learning_rate": 4.006420294393987e-05,
      "loss": 0.9964,
      "step": 765500
    },
    {
      "epoch": 119.95,
      "learning_rate": 4.002505480739117e-05,
      "loss": 1.0138,
      "step": 766000
    },
    {
      "epoch": 120.0,
      "eval_loss": 1.0335737466812134,
      "eval_r": 0.6103029251098633,
      "eval_runtime": 28.1169,
      "eval_samples_per_second": 56.621,
      "eval_steps_per_second": 56.621,
      "step": 766320
    },
    {
      "epoch": 120.03,
      "learning_rate": 3.9985906670842474e-05,
      "loss": 1.0083,
      "step": 766500
    },
    {
      "epoch": 120.11,
      "learning_rate": 3.9946758534293774e-05,
      "loss": 1.0108,
      "step": 767000
    },
    {
      "epoch": 120.18,
      "learning_rate": 3.9907610397745074e-05,
      "loss": 0.9998,
      "step": 767500
    },
    {
      "epoch": 120.26,
      "learning_rate": 3.9868462261196374e-05,
      "loss": 1.0257,
      "step": 768000
    },
    {
      "epoch": 120.34,
      "learning_rate": 3.982931412464767e-05,
      "loss": 1.0016,
      "step": 768500
    },
    {
      "epoch": 120.42,
      "learning_rate": 3.979016598809897e-05,
      "loss": 0.9995,
      "step": 769000
    },
    {
      "epoch": 120.5,
      "learning_rate": 3.975101785155027e-05,
      "loss": 1.0034,
      "step": 769500
    },
    {
      "epoch": 120.58,
      "learning_rate": 3.971186971500157e-05,
      "loss": 1.0054,
      "step": 770000
    },
    {
      "epoch": 120.65,
      "learning_rate": 3.967272157845286e-05,
      "loss": 0.9948,
      "step": 770500
    },
    {
      "epoch": 120.73,
      "learning_rate": 3.963357344190416e-05,
      "loss": 1.0303,
      "step": 771000
    },
    {
      "epoch": 120.81,
      "learning_rate": 3.959442530535546e-05,
      "loss": 1.0006,
      "step": 771500
    },
    {
      "epoch": 120.89,
      "learning_rate": 3.955527716880676e-05,
      "loss": 1.0264,
      "step": 772000
    },
    {
      "epoch": 120.97,
      "learning_rate": 3.951612903225806e-05,
      "loss": 1.0158,
      "step": 772500
    },
    {
      "epoch": 121.0,
      "eval_loss": 1.0334669351577759,
      "eval_r": 0.6102476119995117,
      "eval_runtime": 27.2876,
      "eval_samples_per_second": 58.341,
      "eval_steps_per_second": 58.341,
      "step": 772706
    },
    {
      "epoch": 121.05,
      "learning_rate": 3.947698089570936e-05,
      "loss": 1.0089,
      "step": 773000
    },
    {
      "epoch": 121.12,
      "learning_rate": 3.943783275916066e-05,
      "loss": 0.993,
      "step": 773500
    },
    {
      "epoch": 121.2,
      "learning_rate": 3.939868462261196e-05,
      "loss": 1.0153,
      "step": 774000
    },
    {
      "epoch": 121.28,
      "learning_rate": 3.9359536486063263e-05,
      "loss": 0.9933,
      "step": 774500
    },
    {
      "epoch": 121.36,
      "learning_rate": 3.9320388349514564e-05,
      "loss": 1.0081,
      "step": 775000
    },
    {
      "epoch": 121.44,
      "learning_rate": 3.9281240212965864e-05,
      "loss": 1.0303,
      "step": 775500
    },
    {
      "epoch": 121.52,
      "learning_rate": 3.9242092076417164e-05,
      "loss": 1.0026,
      "step": 776000
    },
    {
      "epoch": 121.59,
      "learning_rate": 3.9202943939868464e-05,
      "loss": 1.0302,
      "step": 776500
    },
    {
      "epoch": 121.67,
      "learning_rate": 3.9163795803319765e-05,
      "loss": 1.0168,
      "step": 777000
    },
    {
      "epoch": 121.75,
      "learning_rate": 3.9124647666771065e-05,
      "loss": 1.0091,
      "step": 777500
    },
    {
      "epoch": 121.83,
      "learning_rate": 3.9085499530222365e-05,
      "loss": 1.0012,
      "step": 778000
    },
    {
      "epoch": 121.91,
      "learning_rate": 3.9046351393673665e-05,
      "loss": 1.0363,
      "step": 778500
    },
    {
      "epoch": 121.99,
      "learning_rate": 3.9007203257124965e-05,
      "loss": 0.9854,
      "step": 779000
    },
    {
      "epoch": 122.0,
      "eval_loss": 1.0425379276275635,
      "eval_r": 0.6089600324630737,
      "eval_runtime": 27.265,
      "eval_samples_per_second": 58.39,
      "eval_steps_per_second": 58.39,
      "step": 779092
    },
    {
      "epoch": 122.06,
      "learning_rate": 3.8968055120576266e-05,
      "loss": 1.0051,
      "step": 779500
    },
    {
      "epoch": 122.14,
      "learning_rate": 3.8928906984027566e-05,
      "loss": 1.0455,
      "step": 780000
    },
    {
      "epoch": 122.22,
      "learning_rate": 3.8889758847478866e-05,
      "loss": 1.0162,
      "step": 780500
    },
    {
      "epoch": 122.3,
      "learning_rate": 3.8850610710930166e-05,
      "loss": 1.0148,
      "step": 781000
    },
    {
      "epoch": 122.38,
      "learning_rate": 3.881146257438146e-05,
      "loss": 0.9915,
      "step": 781500
    },
    {
      "epoch": 122.46,
      "learning_rate": 3.877231443783276e-05,
      "loss": 0.9931,
      "step": 782000
    },
    {
      "epoch": 122.53,
      "learning_rate": 3.873316630128406e-05,
      "loss": 1.028,
      "step": 782500
    },
    {
      "epoch": 122.61,
      "learning_rate": 3.869401816473536e-05,
      "loss": 1.0006,
      "step": 783000
    },
    {
      "epoch": 122.69,
      "learning_rate": 3.865487002818666e-05,
      "loss": 1.0051,
      "step": 783500
    },
    {
      "epoch": 122.77,
      "learning_rate": 3.861572189163796e-05,
      "loss": 1.0123,
      "step": 784000
    },
    {
      "epoch": 122.85,
      "learning_rate": 3.8576573755089254e-05,
      "loss": 1.0139,
      "step": 784500
    },
    {
      "epoch": 122.93,
      "learning_rate": 3.8537425618540554e-05,
      "loss": 1.0174,
      "step": 785000
    },
    {
      "epoch": 123.0,
      "eval_loss": 1.0385888814926147,
      "eval_r": 0.6100006699562073,
      "eval_runtime": 26.9548,
      "eval_samples_per_second": 59.062,
      "eval_steps_per_second": 59.062,
      "step": 785478
    },
    {
      "epoch": 123.0,
      "learning_rate": 3.8498277481991855e-05,
      "loss": 0.992,
      "step": 785500
    },
    {
      "epoch": 123.08,
      "learning_rate": 3.8459129345443155e-05,
      "loss": 1.0112,
      "step": 786000
    },
    {
      "epoch": 123.16,
      "learning_rate": 3.8419981208894455e-05,
      "loss": 0.9925,
      "step": 786500
    },
    {
      "epoch": 123.24,
      "learning_rate": 3.8380833072345755e-05,
      "loss": 1.0056,
      "step": 787000
    },
    {
      "epoch": 123.32,
      "learning_rate": 3.8341684935797056e-05,
      "loss": 1.0295,
      "step": 787500
    },
    {
      "epoch": 123.39,
      "learning_rate": 3.8302536799248356e-05,
      "loss": 1.001,
      "step": 788000
    },
    {
      "epoch": 123.47,
      "learning_rate": 3.8263388662699656e-05,
      "loss": 0.9956,
      "step": 788500
    },
    {
      "epoch": 123.55,
      "learning_rate": 3.8224240526150956e-05,
      "loss": 0.9872,
      "step": 789000
    },
    {
      "epoch": 123.63,
      "learning_rate": 3.8185092389602256e-05,
      "loss": 1.0224,
      "step": 789500
    },
    {
      "epoch": 123.71,
      "learning_rate": 3.814594425305356e-05,
      "loss": 1.0226,
      "step": 790000
    },
    {
      "epoch": 123.79,
      "learning_rate": 3.810679611650486e-05,
      "loss": 1.0116,
      "step": 790500
    },
    {
      "epoch": 123.86,
      "learning_rate": 3.806764797995616e-05,
      "loss": 1.0239,
      "step": 791000
    },
    {
      "epoch": 123.94,
      "learning_rate": 3.802849984340746e-05,
      "loss": 0.9899,
      "step": 791500
    },
    {
      "epoch": 124.0,
      "eval_loss": 1.044243574142456,
      "eval_r": 0.6077455878257751,
      "eval_runtime": 27.8725,
      "eval_samples_per_second": 57.117,
      "eval_steps_per_second": 57.117,
      "step": 791864
    },
    {
      "epoch": 124.02,
      "learning_rate": 3.798935170685876e-05,
      "loss": 1.0121,
      "step": 792000
    },
    {
      "epoch": 124.1,
      "learning_rate": 3.795020357031006e-05,
      "loss": 0.9707,
      "step": 792500
    },
    {
      "epoch": 124.18,
      "learning_rate": 3.791105543376136e-05,
      "loss": 1.0002,
      "step": 793000
    },
    {
      "epoch": 124.26,
      "learning_rate": 3.787190729721266e-05,
      "loss": 0.9874,
      "step": 793500
    },
    {
      "epoch": 124.33,
      "learning_rate": 3.783275916066396e-05,
      "loss": 1.0154,
      "step": 794000
    },
    {
      "epoch": 124.41,
      "learning_rate": 3.779361102411525e-05,
      "loss": 1.0077,
      "step": 794500
    },
    {
      "epoch": 124.49,
      "learning_rate": 3.775446288756655e-05,
      "loss": 0.9991,
      "step": 795000
    },
    {
      "epoch": 124.57,
      "learning_rate": 3.771531475101785e-05,
      "loss": 1.0351,
      "step": 795500
    },
    {
      "epoch": 124.65,
      "learning_rate": 3.767616661446915e-05,
      "loss": 1.0341,
      "step": 796000
    },
    {
      "epoch": 124.73,
      "learning_rate": 3.763701847792045e-05,
      "loss": 1.0057,
      "step": 796500
    },
    {
      "epoch": 124.8,
      "learning_rate": 3.759787034137175e-05,
      "loss": 1.0163,
      "step": 797000
    },
    {
      "epoch": 124.88,
      "learning_rate": 3.755872220482305e-05,
      "loss": 1.004,
      "step": 797500
    },
    {
      "epoch": 124.96,
      "learning_rate": 3.751957406827435e-05,
      "loss": 0.9989,
      "step": 798000
    },
    {
      "epoch": 125.0,
      "eval_loss": 1.0391528606414795,
      "eval_r": 0.6094308495521545,
      "eval_runtime": 26.8661,
      "eval_samples_per_second": 59.257,
      "eval_steps_per_second": 59.257,
      "step": 798250
    },
    {
      "epoch": 125.04,
      "learning_rate": 3.748042593172565e-05,
      "loss": 1.004,
      "step": 798500
    },
    {
      "epoch": 125.12,
      "learning_rate": 3.744127779517695e-05,
      "loss": 0.9922,
      "step": 799000
    },
    {
      "epoch": 125.2,
      "learning_rate": 3.740212965862825e-05,
      "loss": 1.0098,
      "step": 799500
    },
    {
      "epoch": 125.27,
      "learning_rate": 3.736298152207955e-05,
      "loss": 1.0152,
      "step": 800000
    },
    {
      "epoch": 125.35,
      "learning_rate": 3.732383338553085e-05,
      "loss": 1.0099,
      "step": 800500
    },
    {
      "epoch": 125.43,
      "learning_rate": 3.728468524898215e-05,
      "loss": 1.0038,
      "step": 801000
    },
    {
      "epoch": 125.51,
      "learning_rate": 3.724553711243345e-05,
      "loss": 1.0152,
      "step": 801500
    },
    {
      "epoch": 125.59,
      "learning_rate": 3.720638897588475e-05,
      "loss": 1.0175,
      "step": 802000
    },
    {
      "epoch": 125.67,
      "learning_rate": 3.716724083933605e-05,
      "loss": 1.0027,
      "step": 802500
    },
    {
      "epoch": 125.74,
      "learning_rate": 3.712809270278735e-05,
      "loss": 0.9951,
      "step": 803000
    },
    {
      "epoch": 125.82,
      "learning_rate": 3.708894456623865e-05,
      "loss": 1.0134,
      "step": 803500
    },
    {
      "epoch": 125.9,
      "learning_rate": 3.704979642968995e-05,
      "loss": 1.0234,
      "step": 804000
    },
    {
      "epoch": 125.98,
      "learning_rate": 3.701064829314125e-05,
      "loss": 0.997,
      "step": 804500
    },
    {
      "epoch": 126.0,
      "eval_loss": 1.0382726192474365,
      "eval_r": 0.6100260019302368,
      "eval_runtime": 28.1009,
      "eval_samples_per_second": 56.653,
      "eval_steps_per_second": 56.653,
      "step": 804636
    },
    {
      "epoch": 126.06,
      "learning_rate": 3.697150015659255e-05,
      "loss": 1.0196,
      "step": 805000
    },
    {
      "epoch": 126.14,
      "learning_rate": 3.693235202004385e-05,
      "loss": 1.0009,
      "step": 805500
    },
    {
      "epoch": 126.21,
      "learning_rate": 3.689320388349515e-05,
      "loss": 1.0089,
      "step": 806000
    },
    {
      "epoch": 126.29,
      "learning_rate": 3.685405574694645e-05,
      "loss": 0.9915,
      "step": 806500
    },
    {
      "epoch": 126.37,
      "learning_rate": 3.681490761039775e-05,
      "loss": 1.0317,
      "step": 807000
    },
    {
      "epoch": 126.45,
      "learning_rate": 3.677575947384905e-05,
      "loss": 1.0051,
      "step": 807500
    },
    {
      "epoch": 126.53,
      "learning_rate": 3.6736611337300344e-05,
      "loss": 1.0193,
      "step": 808000
    },
    {
      "epoch": 126.61,
      "learning_rate": 3.6697463200751644e-05,
      "loss": 0.9953,
      "step": 808500
    },
    {
      "epoch": 126.68,
      "learning_rate": 3.6658315064202945e-05,
      "loss": 0.9936,
      "step": 809000
    },
    {
      "epoch": 126.76,
      "learning_rate": 3.6619166927654245e-05,
      "loss": 0.9995,
      "step": 809500
    },
    {
      "epoch": 126.84,
      "learning_rate": 3.6580018791105545e-05,
      "loss": 1.0165,
      "step": 810000
    },
    {
      "epoch": 126.92,
      "learning_rate": 3.6540870654556845e-05,
      "loss": 1.0178,
      "step": 810500
    },
    {
      "epoch": 127.0,
      "learning_rate": 3.6501722518008146e-05,
      "loss": 0.9924,
      "step": 811000
    },
    {
      "epoch": 127.0,
      "eval_loss": 1.03621244430542,
      "eval_r": 0.6102476119995117,
      "eval_runtime": 27.2639,
      "eval_samples_per_second": 58.392,
      "eval_steps_per_second": 58.392,
      "step": 811022
    },
    {
      "epoch": 127.07,
      "learning_rate": 3.6462574381459446e-05,
      "loss": 0.986,
      "step": 811500
    },
    {
      "epoch": 127.15,
      "learning_rate": 3.6423426244910746e-05,
      "loss": 0.9959,
      "step": 812000
    },
    {
      "epoch": 127.23,
      "learning_rate": 3.638427810836204e-05,
      "loss": 1.0,
      "step": 812500
    },
    {
      "epoch": 127.31,
      "learning_rate": 3.634512997181334e-05,
      "loss": 0.9932,
      "step": 813000
    },
    {
      "epoch": 127.39,
      "learning_rate": 3.630598183526464e-05,
      "loss": 0.985,
      "step": 813500
    },
    {
      "epoch": 127.47,
      "learning_rate": 3.626683369871594e-05,
      "loss": 1.0246,
      "step": 814000
    },
    {
      "epoch": 127.54,
      "learning_rate": 3.622768556216724e-05,
      "loss": 1.0178,
      "step": 814500
    },
    {
      "epoch": 127.62,
      "learning_rate": 3.618853742561854e-05,
      "loss": 1.0251,
      "step": 815000
    },
    {
      "epoch": 127.7,
      "learning_rate": 3.614938928906984e-05,
      "loss": 0.9976,
      "step": 815500
    },
    {
      "epoch": 127.78,
      "learning_rate": 3.611024115252114e-05,
      "loss": 1.0121,
      "step": 816000
    },
    {
      "epoch": 127.86,
      "learning_rate": 3.607109301597244e-05,
      "loss": 1.0061,
      "step": 816500
    },
    {
      "epoch": 127.94,
      "learning_rate": 3.603194487942374e-05,
      "loss": 1.0146,
      "step": 817000
    },
    {
      "epoch": 128.0,
      "eval_loss": 1.0414303541183472,
      "eval_r": 0.6084017753601074,
      "eval_runtime": 27.3411,
      "eval_samples_per_second": 58.227,
      "eval_steps_per_second": 58.227,
      "step": 817408
    },
    {
      "epoch": 128.01,
      "learning_rate": 3.599279674287504e-05,
      "loss": 1.0284,
      "step": 817500
    },
    {
      "epoch": 128.09,
      "learning_rate": 3.595364860632634e-05,
      "loss": 1.0076,
      "step": 818000
    },
    {
      "epoch": 128.17,
      "learning_rate": 3.591450046977764e-05,
      "loss": 0.9898,
      "step": 818500
    },
    {
      "epoch": 128.25,
      "learning_rate": 3.587535233322894e-05,
      "loss": 1.008,
      "step": 819000
    },
    {
      "epoch": 128.33,
      "learning_rate": 3.583620419668024e-05,
      "loss": 1.0003,
      "step": 819500
    },
    {
      "epoch": 128.41,
      "learning_rate": 3.579705606013154e-05,
      "loss": 0.9971,
      "step": 820000
    },
    {
      "epoch": 128.48,
      "learning_rate": 3.575790792358284e-05,
      "loss": 1.0172,
      "step": 820500
    },
    {
      "epoch": 128.56,
      "learning_rate": 3.5718759787034136e-05,
      "loss": 1.0011,
      "step": 821000
    },
    {
      "epoch": 128.64,
      "learning_rate": 3.5679611650485437e-05,
      "loss": 1.0166,
      "step": 821500
    },
    {
      "epoch": 128.72,
      "learning_rate": 3.564046351393674e-05,
      "loss": 1.0191,
      "step": 822000
    },
    {
      "epoch": 128.8,
      "learning_rate": 3.560131537738804e-05,
      "loss": 1.0041,
      "step": 822500
    },
    {
      "epoch": 128.88,
      "learning_rate": 3.556216724083934e-05,
      "loss": 1.0048,
      "step": 823000
    },
    {
      "epoch": 128.95,
      "learning_rate": 3.552301910429064e-05,
      "loss": 1.0098,
      "step": 823500
    },
    {
      "epoch": 129.0,
      "eval_loss": 1.0374729633331299,
      "eval_r": 0.6084357500076294,
      "eval_runtime": 26.5264,
      "eval_samples_per_second": 60.016,
      "eval_steps_per_second": 60.016,
      "step": 823794
    },
    {
      "epoch": 129.03,
      "learning_rate": 3.548387096774194e-05,
      "loss": 1.0054,
      "step": 824000
    },
    {
      "epoch": 129.11,
      "learning_rate": 3.544472283119324e-05,
      "loss": 1.0104,
      "step": 824500
    },
    {
      "epoch": 129.19,
      "learning_rate": 3.540557469464454e-05,
      "loss": 1.0059,
      "step": 825000
    },
    {
      "epoch": 129.27,
      "learning_rate": 3.536642655809584e-05,
      "loss": 1.0131,
      "step": 825500
    },
    {
      "epoch": 129.35,
      "learning_rate": 3.532727842154714e-05,
      "loss": 0.9979,
      "step": 826000
    },
    {
      "epoch": 129.42,
      "learning_rate": 3.528813028499844e-05,
      "loss": 1.0096,
      "step": 826500
    },
    {
      "epoch": 129.5,
      "learning_rate": 3.524898214844973e-05,
      "loss": 0.9827,
      "step": 827000
    },
    {
      "epoch": 129.58,
      "learning_rate": 3.520983401190103e-05,
      "loss": 1.0111,
      "step": 827500
    },
    {
      "epoch": 129.66,
      "learning_rate": 3.517068587535233e-05,
      "loss": 0.9987,
      "step": 828000
    },
    {
      "epoch": 129.74,
      "learning_rate": 3.513153773880363e-05,
      "loss": 1.011,
      "step": 828500
    },
    {
      "epoch": 129.82,
      "learning_rate": 3.509238960225493e-05,
      "loss": 1.0149,
      "step": 829000
    },
    {
      "epoch": 129.89,
      "learning_rate": 3.505324146570623e-05,
      "loss": 0.9965,
      "step": 829500
    },
    {
      "epoch": 129.97,
      "learning_rate": 3.5014093329157533e-05,
      "loss": 0.9907,
      "step": 830000
    },
    {
      "epoch": 130.0,
      "eval_loss": 1.0412633419036865,
      "eval_r": 0.6091388463973999,
      "eval_runtime": 27.2061,
      "eval_samples_per_second": 58.516,
      "eval_steps_per_second": 58.516,
      "step": 830180
    },
    {
      "epoch": 130.05,
      "learning_rate": 3.4974945192608834e-05,
      "loss": 1.013,
      "step": 830500
    },
    {
      "epoch": 130.13,
      "learning_rate": 3.4935797056060134e-05,
      "loss": 0.9965,
      "step": 831000
    },
    {
      "epoch": 130.21,
      "learning_rate": 3.4896648919511434e-05,
      "loss": 1.0157,
      "step": 831500
    },
    {
      "epoch": 130.28,
      "learning_rate": 3.4857500782962734e-05,
      "loss": 1.0093,
      "step": 832000
    },
    {
      "epoch": 130.36,
      "learning_rate": 3.4818352646414035e-05,
      "loss": 1.0032,
      "step": 832500
    },
    {
      "epoch": 130.44,
      "learning_rate": 3.4779204509865335e-05,
      "loss": 0.9994,
      "step": 833000
    },
    {
      "epoch": 130.52,
      "learning_rate": 3.4740056373316635e-05,
      "loss": 0.9844,
      "step": 833500
    },
    {
      "epoch": 130.6,
      "learning_rate": 3.470090823676793e-05,
      "loss": 1.0108,
      "step": 834000
    },
    {
      "epoch": 130.68,
      "learning_rate": 3.466176010021923e-05,
      "loss": 1.0153,
      "step": 834500
    },
    {
      "epoch": 130.75,
      "learning_rate": 3.462261196367053e-05,
      "loss": 1.0201,
      "step": 835000
    },
    {
      "epoch": 130.83,
      "learning_rate": 3.458346382712183e-05,
      "loss": 0.9859,
      "step": 835500
    },
    {
      "epoch": 130.91,
      "learning_rate": 3.454431569057313e-05,
      "loss": 1.0011,
      "step": 836000
    },
    {
      "epoch": 130.99,
      "learning_rate": 3.450516755402443e-05,
      "loss": 1.0094,
      "step": 836500
    },
    {
      "epoch": 131.0,
      "eval_loss": 1.0355316400527954,
      "eval_r": 0.6096504330635071,
      "eval_runtime": 27.2678,
      "eval_samples_per_second": 58.384,
      "eval_steps_per_second": 58.384,
      "step": 836566
    },
    {
      "epoch": 131.07,
      "learning_rate": 3.446601941747573e-05,
      "loss": 1.0059,
      "step": 837000
    },
    {
      "epoch": 131.15,
      "learning_rate": 3.442687128092703e-05,
      "loss": 0.9948,
      "step": 837500
    },
    {
      "epoch": 131.22,
      "learning_rate": 3.438772314437833e-05,
      "loss": 0.9964,
      "step": 838000
    },
    {
      "epoch": 131.3,
      "learning_rate": 3.434857500782963e-05,
      "loss": 1.0271,
      "step": 838500
    },
    {
      "epoch": 131.38,
      "learning_rate": 3.430942687128093e-05,
      "loss": 0.9804,
      "step": 839000
    },
    {
      "epoch": 131.46,
      "learning_rate": 3.427027873473223e-05,
      "loss": 1.0187,
      "step": 839500
    },
    {
      "epoch": 131.54,
      "learning_rate": 3.423113059818353e-05,
      "loss": 1.0004,
      "step": 840000
    },
    {
      "epoch": 131.62,
      "learning_rate": 3.419198246163483e-05,
      "loss": 0.9939,
      "step": 840500
    },
    {
      "epoch": 131.69,
      "learning_rate": 3.4152834325086125e-05,
      "loss": 0.9924,
      "step": 841000
    },
    {
      "epoch": 131.77,
      "learning_rate": 3.4113686188537425e-05,
      "loss": 1.0106,
      "step": 841500
    },
    {
      "epoch": 131.85,
      "learning_rate": 3.4074538051988725e-05,
      "loss": 1.0074,
      "step": 842000
    },
    {
      "epoch": 131.93,
      "learning_rate": 3.4035389915440025e-05,
      "loss": 1.0091,
      "step": 842500
    },
    {
      "epoch": 132.0,
      "eval_loss": 1.0348509550094604,
      "eval_r": 0.6100207567214966,
      "eval_runtime": 27.9129,
      "eval_samples_per_second": 57.035,
      "eval_steps_per_second": 57.035,
      "step": 842952
    },
    {
      "epoch": 132.01,
      "learning_rate": 3.3996241778891326e-05,
      "loss": 1.0056,
      "step": 843000
    },
    {
      "epoch": 132.09,
      "learning_rate": 3.3957093642342626e-05,
      "loss": 0.9964,
      "step": 843500
    },
    {
      "epoch": 132.16,
      "learning_rate": 3.3917945505793926e-05,
      "loss": 1.0122,
      "step": 844000
    },
    {
      "epoch": 132.24,
      "learning_rate": 3.3878797369245226e-05,
      "loss": 1.0009,
      "step": 844500
    },
    {
      "epoch": 132.32,
      "learning_rate": 3.3839649232696526e-05,
      "loss": 1.0118,
      "step": 845000
    },
    {
      "epoch": 132.4,
      "learning_rate": 3.380050109614783e-05,
      "loss": 1.0176,
      "step": 845500
    },
    {
      "epoch": 132.48,
      "learning_rate": 3.376135295959913e-05,
      "loss": 1.0256,
      "step": 846000
    },
    {
      "epoch": 132.56,
      "learning_rate": 3.372220482305043e-05,
      "loss": 1.0034,
      "step": 846500
    },
    {
      "epoch": 132.63,
      "learning_rate": 3.368305668650172e-05,
      "loss": 1.0113,
      "step": 847000
    },
    {
      "epoch": 132.71,
      "learning_rate": 3.364390854995302e-05,
      "loss": 1.001,
      "step": 847500
    },
    {
      "epoch": 132.79,
      "learning_rate": 3.360476041340432e-05,
      "loss": 0.9694,
      "step": 848000
    },
    {
      "epoch": 132.87,
      "learning_rate": 3.356561227685562e-05,
      "loss": 0.9927,
      "step": 848500
    },
    {
      "epoch": 132.95,
      "learning_rate": 3.352646414030692e-05,
      "loss": 1.005,
      "step": 849000
    },
    {
      "epoch": 133.0,
      "eval_loss": 1.0445442199707031,
      "eval_r": 0.6076542139053345,
      "eval_runtime": 26.9109,
      "eval_samples_per_second": 59.158,
      "eval_steps_per_second": 59.158,
      "step": 849338
    },
    {
      "epoch": 133.03,
      "learning_rate": 3.348731600375822e-05,
      "loss": 0.9851,
      "step": 849500
    },
    {
      "epoch": 133.1,
      "learning_rate": 3.344816786720952e-05,
      "loss": 1.0153,
      "step": 850000
    },
    {
      "epoch": 133.18,
      "learning_rate": 3.340901973066082e-05,
      "loss": 0.9895,
      "step": 850500
    },
    {
      "epoch": 133.26,
      "learning_rate": 3.336987159411212e-05,
      "loss": 1.008,
      "step": 851000
    },
    {
      "epoch": 133.34,
      "learning_rate": 3.333072345756342e-05,
      "loss": 0.9987,
      "step": 851500
    },
    {
      "epoch": 133.42,
      "learning_rate": 3.329157532101472e-05,
      "loss": 1.0006,
      "step": 852000
    },
    {
      "epoch": 133.5,
      "learning_rate": 3.325242718446602e-05,
      "loss": 1.0042,
      "step": 852500
    },
    {
      "epoch": 133.57,
      "learning_rate": 3.321327904791732e-05,
      "loss": 1.0069,
      "step": 853000
    },
    {
      "epoch": 133.65,
      "learning_rate": 3.317413091136862e-05,
      "loss": 1.0075,
      "step": 853500
    },
    {
      "epoch": 133.73,
      "learning_rate": 3.3134982774819924e-05,
      "loss": 0.9972,
      "step": 854000
    },
    {
      "epoch": 133.81,
      "learning_rate": 3.3095834638271224e-05,
      "loss": 1.0285,
      "step": 854500
    },
    {
      "epoch": 133.89,
      "learning_rate": 3.305668650172252e-05,
      "loss": 0.9855,
      "step": 855000
    },
    {
      "epoch": 133.96,
      "learning_rate": 3.301753836517382e-05,
      "loss": 1.0157,
      "step": 855500
    },
    {
      "epoch": 134.0,
      "eval_loss": 1.0353046655654907,
      "eval_r": 0.6106526851654053,
      "eval_runtime": 27.241,
      "eval_samples_per_second": 58.441,
      "eval_steps_per_second": 58.441,
      "step": 855724
    },
    {
      "epoch": 134.04,
      "learning_rate": 3.297839022862512e-05,
      "loss": 0.9881,
      "step": 856000
    },
    {
      "epoch": 134.12,
      "learning_rate": 3.293924209207642e-05,
      "loss": 0.9817,
      "step": 856500
    },
    {
      "epoch": 134.2,
      "learning_rate": 3.290009395552772e-05,
      "loss": 0.9852,
      "step": 857000
    },
    {
      "epoch": 134.28,
      "learning_rate": 3.286094581897902e-05,
      "loss": 1.0042,
      "step": 857500
    },
    {
      "epoch": 134.36,
      "learning_rate": 3.282179768243032e-05,
      "loss": 1.0014,
      "step": 858000
    },
    {
      "epoch": 134.43,
      "learning_rate": 3.278264954588162e-05,
      "loss": 0.999,
      "step": 858500
    },
    {
      "epoch": 134.51,
      "learning_rate": 3.274350140933292e-05,
      "loss": 1.0129,
      "step": 859000
    },
    {
      "epoch": 134.59,
      "learning_rate": 3.270435327278422e-05,
      "loss": 1.0238,
      "step": 859500
    },
    {
      "epoch": 134.67,
      "learning_rate": 3.266520513623551e-05,
      "loss": 0.9934,
      "step": 860000
    },
    {
      "epoch": 134.75,
      "learning_rate": 3.262605699968681e-05,
      "loss": 0.992,
      "step": 860500
    },
    {
      "epoch": 134.83,
      "learning_rate": 3.258690886313811e-05,
      "loss": 1.0004,
      "step": 861000
    },
    {
      "epoch": 134.9,
      "learning_rate": 3.254776072658941e-05,
      "loss": 1.0383,
      "step": 861500
    },
    {
      "epoch": 134.98,
      "learning_rate": 3.2508612590040714e-05,
      "loss": 1.0045,
      "step": 862000
    },
    {
      "epoch": 135.0,
      "eval_loss": 1.0366182327270508,
      "eval_r": 0.6090549230575562,
      "eval_runtime": 27.6646,
      "eval_samples_per_second": 57.546,
      "eval_steps_per_second": 57.546,
      "step": 862110
    },
    {
      "epoch": 135.06,
      "learning_rate": 3.2469464453492014e-05,
      "loss": 0.9807,
      "step": 862500
    },
    {
      "epoch": 135.14,
      "learning_rate": 3.2430316316943314e-05,
      "loss": 1.0025,
      "step": 863000
    },
    {
      "epoch": 135.22,
      "learning_rate": 3.2391168180394614e-05,
      "loss": 1.0012,
      "step": 863500
    },
    {
      "epoch": 135.3,
      "learning_rate": 3.2352020043845914e-05,
      "loss": 1.0106,
      "step": 864000
    },
    {
      "epoch": 135.37,
      "learning_rate": 3.2312871907297215e-05,
      "loss": 1.0025,
      "step": 864500
    },
    {
      "epoch": 135.45,
      "learning_rate": 3.2273723770748515e-05,
      "loss": 1.0158,
      "step": 865000
    },
    {
      "epoch": 135.53,
      "learning_rate": 3.2234575634199815e-05,
      "loss": 1.0046,
      "step": 865500
    },
    {
      "epoch": 135.61,
      "learning_rate": 3.2195427497651115e-05,
      "loss": 0.995,
      "step": 866000
    },
    {
      "epoch": 135.69,
      "learning_rate": 3.2156279361102416e-05,
      "loss": 1.0045,
      "step": 866500
    },
    {
      "epoch": 135.77,
      "learning_rate": 3.2117131224553716e-05,
      "loss": 1.0077,
      "step": 867000
    },
    {
      "epoch": 135.84,
      "learning_rate": 3.2077983088005016e-05,
      "loss": 0.9939,
      "step": 867500
    },
    {
      "epoch": 135.92,
      "learning_rate": 3.2038834951456316e-05,
      "loss": 1.0129,
      "step": 868000
    },
    {
      "epoch": 136.0,
      "eval_loss": 1.0455080270767212,
      "eval_r": 0.607346773147583,
      "eval_runtime": 27.3276,
      "eval_samples_per_second": 58.256,
      "eval_steps_per_second": 58.256,
      "step": 868496
    },
    {
      "epoch": 136.0,
      "learning_rate": 3.1999686814907616e-05,
      "loss": 1.0039,
      "step": 868500
    },
    {
      "epoch": 136.08,
      "learning_rate": 3.196053867835891e-05,
      "loss": 0.9673,
      "step": 869000
    },
    {
      "epoch": 136.16,
      "learning_rate": 3.192139054181021e-05,
      "loss": 1.0018,
      "step": 869500
    },
    {
      "epoch": 136.24,
      "learning_rate": 3.188224240526151e-05,
      "loss": 0.9938,
      "step": 870000
    },
    {
      "epoch": 136.31,
      "learning_rate": 3.184309426871281e-05,
      "loss": 0.9989,
      "step": 870500
    },
    {
      "epoch": 136.39,
      "learning_rate": 3.180394613216411e-05,
      "loss": 1.0164,
      "step": 871000
    },
    {
      "epoch": 136.47,
      "learning_rate": 3.176479799561541e-05,
      "loss": 1.0142,
      "step": 871500
    },
    {
      "epoch": 136.55,
      "learning_rate": 3.172564985906671e-05,
      "loss": 1.0008,
      "step": 872000
    },
    {
      "epoch": 136.63,
      "learning_rate": 3.168650172251801e-05,
      "loss": 1.0032,
      "step": 872500
    },
    {
      "epoch": 136.71,
      "learning_rate": 3.164735358596931e-05,
      "loss": 0.9862,
      "step": 873000
    },
    {
      "epoch": 136.78,
      "learning_rate": 3.1608205449420605e-05,
      "loss": 1.0008,
      "step": 873500
    },
    {
      "epoch": 136.86,
      "learning_rate": 3.1569057312871905e-05,
      "loss": 1.0129,
      "step": 874000
    },
    {
      "epoch": 136.94,
      "learning_rate": 3.1529909176323205e-05,
      "loss": 1.0151,
      "step": 874500
    },
    {
      "epoch": 137.0,
      "eval_loss": 1.039490818977356,
      "eval_r": 0.6100613474845886,
      "eval_runtime": 27.1701,
      "eval_samples_per_second": 58.594,
      "eval_steps_per_second": 58.594,
      "step": 874882
    },
    {
      "epoch": 137.02,
      "learning_rate": 3.1490761039774506e-05,
      "loss": 1.0046,
      "step": 875000
    },
    {
      "epoch": 137.1,
      "learning_rate": 3.1451612903225806e-05,
      "loss": 1.0152,
      "step": 875500
    },
    {
      "epoch": 137.18,
      "learning_rate": 3.1412464766677106e-05,
      "loss": 0.9994,
      "step": 876000
    },
    {
      "epoch": 137.25,
      "learning_rate": 3.1373316630128406e-05,
      "loss": 1.0191,
      "step": 876500
    },
    {
      "epoch": 137.33,
      "learning_rate": 3.1334168493579707e-05,
      "loss": 0.9864,
      "step": 877000
    },
    {
      "epoch": 137.41,
      "learning_rate": 3.129502035703101e-05,
      "loss": 0.9965,
      "step": 877500
    },
    {
      "epoch": 137.49,
      "learning_rate": 3.125587222048231e-05,
      "loss": 0.9946,
      "step": 878000
    },
    {
      "epoch": 137.57,
      "learning_rate": 3.121672408393361e-05,
      "loss": 1.001,
      "step": 878500
    },
    {
      "epoch": 137.64,
      "learning_rate": 3.117757594738491e-05,
      "loss": 1.0223,
      "step": 879000
    },
    {
      "epoch": 137.72,
      "learning_rate": 3.113842781083621e-05,
      "loss": 0.9884,
      "step": 879500
    },
    {
      "epoch": 137.8,
      "learning_rate": 3.109927967428751e-05,
      "loss": 1.0102,
      "step": 880000
    },
    {
      "epoch": 137.88,
      "learning_rate": 3.106013153773881e-05,
      "loss": 0.9872,
      "step": 880500
    },
    {
      "epoch": 137.96,
      "learning_rate": 3.102098340119011e-05,
      "loss": 1.0032,
      "step": 881000
    },
    {
      "epoch": 138.0,
      "eval_loss": 1.038449764251709,
      "eval_r": 0.6081404089927673,
      "eval_runtime": 26.9567,
      "eval_samples_per_second": 59.058,
      "eval_steps_per_second": 59.058,
      "step": 881268
    },
    {
      "epoch": 138.04,
      "learning_rate": 3.098183526464141e-05,
      "loss": 0.9856,
      "step": 881500
    },
    {
      "epoch": 138.11,
      "learning_rate": 3.094268712809271e-05,
      "loss": 0.9798,
      "step": 882000
    },
    {
      "epoch": 138.19,
      "learning_rate": 3.090353899154401e-05,
      "loss": 1.0039,
      "step": 882500
    },
    {
      "epoch": 138.27,
      "learning_rate": 3.086439085499531e-05,
      "loss": 1.0161,
      "step": 883000
    },
    {
      "epoch": 138.35,
      "learning_rate": 3.08252427184466e-05,
      "loss": 1.0099,
      "step": 883500
    },
    {
      "epoch": 138.43,
      "learning_rate": 3.07860945818979e-05,
      "loss": 1.0374,
      "step": 884000
    },
    {
      "epoch": 138.51,
      "learning_rate": 3.07469464453492e-05,
      "loss": 1.0059,
      "step": 884500
    },
    {
      "epoch": 138.58,
      "learning_rate": 3.07077983088005e-05,
      "loss": 0.9749,
      "step": 885000
    },
    {
      "epoch": 138.66,
      "learning_rate": 3.0668650172251803e-05,
      "loss": 0.9988,
      "step": 885500
    },
    {
      "epoch": 138.74,
      "learning_rate": 3.0629502035703104e-05,
      "loss": 0.9841,
      "step": 886000
    },
    {
      "epoch": 138.82,
      "learning_rate": 3.05903538991544e-05,
      "loss": 0.9892,
      "step": 886500
    },
    {
      "epoch": 138.9,
      "learning_rate": 3.05512057626057e-05,
      "loss": 1.0048,
      "step": 887000
    },
    {
      "epoch": 138.98,
      "learning_rate": 3.0512057626057e-05,
      "loss": 1.0047,
      "step": 887500
    },
    {
      "epoch": 139.0,
      "eval_loss": 1.0373566150665283,
      "eval_r": 0.6087678074836731,
      "eval_runtime": 27.3307,
      "eval_samples_per_second": 58.25,
      "eval_steps_per_second": 58.25,
      "step": 887654
    },
    {
      "epoch": 139.05,
      "learning_rate": 3.04729094895083e-05,
      "loss": 0.981,
      "step": 888000
    },
    {
      "epoch": 139.13,
      "learning_rate": 3.04337613529596e-05,
      "loss": 0.9937,
      "step": 888500
    },
    {
      "epoch": 139.21,
      "learning_rate": 3.0394613216410898e-05,
      "loss": 1.0338,
      "step": 889000
    },
    {
      "epoch": 139.29,
      "learning_rate": 3.03554650798622e-05,
      "loss": 0.988,
      "step": 889500
    },
    {
      "epoch": 139.37,
      "learning_rate": 3.03163169433135e-05,
      "loss": 0.9948,
      "step": 890000
    },
    {
      "epoch": 139.45,
      "learning_rate": 3.02771688067648e-05,
      "loss": 1.0078,
      "step": 890500
    },
    {
      "epoch": 139.52,
      "learning_rate": 3.02380206702161e-05,
      "loss": 0.9997,
      "step": 891000
    },
    {
      "epoch": 139.6,
      "learning_rate": 3.01988725336674e-05,
      "loss": 1.0034,
      "step": 891500
    },
    {
      "epoch": 139.68,
      "learning_rate": 3.01597243971187e-05,
      "loss": 1.0038,
      "step": 892000
    },
    {
      "epoch": 139.76,
      "learning_rate": 3.012057626057e-05,
      "loss": 0.998,
      "step": 892500
    },
    {
      "epoch": 139.84,
      "learning_rate": 3.00814281240213e-05,
      "loss": 0.9961,
      "step": 893000
    },
    {
      "epoch": 139.92,
      "learning_rate": 3.00422799874726e-05,
      "loss": 1.0006,
      "step": 893500
    },
    {
      "epoch": 139.99,
      "learning_rate": 3.00031318509239e-05,
      "loss": 1.0093,
      "step": 894000
    },
    {
      "epoch": 140.0,
      "eval_loss": 1.041660189628601,
      "eval_r": 0.6087941527366638,
      "eval_runtime": 28.1573,
      "eval_samples_per_second": 56.54,
      "eval_steps_per_second": 56.54,
      "step": 894040
    },
    {
      "epoch": 140.07,
      "learning_rate": 2.9963983714375197e-05,
      "loss": 0.9883,
      "step": 894500
    },
    {
      "epoch": 140.15,
      "learning_rate": 2.9924835577826497e-05,
      "loss": 0.9989,
      "step": 895000
    },
    {
      "epoch": 140.23,
      "learning_rate": 2.9885687441277798e-05,
      "loss": 1.0023,
      "step": 895500
    },
    {
      "epoch": 140.31,
      "learning_rate": 2.9846539304729098e-05,
      "loss": 1.0017,
      "step": 896000
    },
    {
      "epoch": 140.39,
      "learning_rate": 2.9807391168180398e-05,
      "loss": 1.0085,
      "step": 896500
    },
    {
      "epoch": 140.46,
      "learning_rate": 2.97682430316317e-05,
      "loss": 0.9834,
      "step": 897000
    },
    {
      "epoch": 140.54,
      "learning_rate": 2.9729094895082992e-05,
      "loss": 0.9998,
      "step": 897500
    },
    {
      "epoch": 140.62,
      "learning_rate": 2.9689946758534292e-05,
      "loss": 1.0006,
      "step": 898000
    },
    {
      "epoch": 140.7,
      "learning_rate": 2.9650798621985592e-05,
      "loss": 1.0085,
      "step": 898500
    },
    {
      "epoch": 140.78,
      "learning_rate": 2.9611650485436892e-05,
      "loss": 1.0013,
      "step": 899000
    },
    {
      "epoch": 140.85,
      "learning_rate": 2.9572502348888193e-05,
      "loss": 1.0008,
      "step": 899500
    },
    {
      "epoch": 140.93,
      "learning_rate": 2.9533354212339493e-05,
      "loss": 1.0059,
      "step": 900000
    },
    {
      "epoch": 141.0,
      "eval_loss": 1.03554368019104,
      "eval_r": 0.6099660992622375,
      "eval_runtime": 26.7713,
      "eval_samples_per_second": 59.467,
      "eval_steps_per_second": 59.467,
      "step": 900426
    },
    {
      "epoch": 141.01,
      "learning_rate": 2.9494206075790793e-05,
      "loss": 0.9973,
      "step": 900500
    },
    {
      "epoch": 141.09,
      "learning_rate": 2.9455057939242093e-05,
      "loss": 0.9934,
      "step": 901000
    },
    {
      "epoch": 141.17,
      "learning_rate": 2.9415909802693394e-05,
      "loss": 1.0262,
      "step": 901500
    },
    {
      "epoch": 141.25,
      "learning_rate": 2.9376761666144694e-05,
      "loss": 0.9887,
      "step": 902000
    },
    {
      "epoch": 141.32,
      "learning_rate": 2.933761352959599e-05,
      "loss": 0.9922,
      "step": 902500
    },
    {
      "epoch": 141.4,
      "learning_rate": 2.929846539304729e-05,
      "loss": 1.001,
      "step": 903000
    },
    {
      "epoch": 141.48,
      "learning_rate": 2.925931725649859e-05,
      "loss": 0.9931,
      "step": 903500
    },
    {
      "epoch": 141.56,
      "learning_rate": 2.922016911994989e-05,
      "loss": 0.9996,
      "step": 904000
    },
    {
      "epoch": 141.64,
      "learning_rate": 2.918102098340119e-05,
      "loss": 0.991,
      "step": 904500
    },
    {
      "epoch": 141.72,
      "learning_rate": 2.914187284685249e-05,
      "loss": 0.9792,
      "step": 905000
    },
    {
      "epoch": 141.79,
      "learning_rate": 2.9102724710303792e-05,
      "loss": 1.0035,
      "step": 905500
    },
    {
      "epoch": 141.87,
      "learning_rate": 2.9063576573755092e-05,
      "loss": 1.0102,
      "step": 906000
    },
    {
      "epoch": 141.95,
      "learning_rate": 2.9024428437206392e-05,
      "loss": 1.0041,
      "step": 906500
    },
    {
      "epoch": 142.0,
      "eval_loss": 1.0394196510314941,
      "eval_r": 0.6087639331817627,
      "eval_runtime": 27.3313,
      "eval_samples_per_second": 58.248,
      "eval_steps_per_second": 58.248,
      "step": 906812
    },
    {
      "epoch": 142.03,
      "learning_rate": 2.8985280300657693e-05,
      "loss": 1.0091,
      "step": 907000
    },
    {
      "epoch": 142.11,
      "learning_rate": 2.8946132164108993e-05,
      "loss": 0.9847,
      "step": 907500
    },
    {
      "epoch": 142.19,
      "learning_rate": 2.890698402756029e-05,
      "loss": 0.9822,
      "step": 908000
    },
    {
      "epoch": 142.26,
      "learning_rate": 2.886783589101159e-05,
      "loss": 0.998,
      "step": 908500
    },
    {
      "epoch": 142.34,
      "learning_rate": 2.882868775446289e-05,
      "loss": 1.0164,
      "step": 909000
    },
    {
      "epoch": 142.42,
      "learning_rate": 2.878953961791419e-05,
      "loss": 1.0071,
      "step": 909500
    },
    {
      "epoch": 142.5,
      "learning_rate": 2.875039148136549e-05,
      "loss": 1.0127,
      "step": 910000
    },
    {
      "epoch": 142.58,
      "learning_rate": 2.871124334481679e-05,
      "loss": 0.9943,
      "step": 910500
    },
    {
      "epoch": 142.66,
      "learning_rate": 2.867209520826809e-05,
      "loss": 0.984,
      "step": 911000
    },
    {
      "epoch": 142.73,
      "learning_rate": 2.8632947071719384e-05,
      "loss": 1.0179,
      "step": 911500
    },
    {
      "epoch": 142.81,
      "learning_rate": 2.8593798935170685e-05,
      "loss": 0.9961,
      "step": 912000
    },
    {
      "epoch": 142.89,
      "learning_rate": 2.8554650798621985e-05,
      "loss": 0.9888,
      "step": 912500
    },
    {
      "epoch": 142.97,
      "learning_rate": 2.8515502662073285e-05,
      "loss": 1.001,
      "step": 913000
    },
    {
      "epoch": 143.0,
      "eval_loss": 1.036726474761963,
      "eval_r": 0.6090444922447205,
      "eval_runtime": 26.9283,
      "eval_samples_per_second": 59.12,
      "eval_steps_per_second": 59.12,
      "step": 913198
    },
    {
      "epoch": 143.05,
      "learning_rate": 2.8476354525524585e-05,
      "loss": 0.9991,
      "step": 913500
    },
    {
      "epoch": 143.13,
      "learning_rate": 2.8437206388975885e-05,
      "loss": 0.9822,
      "step": 914000
    },
    {
      "epoch": 143.2,
      "learning_rate": 2.8398058252427186e-05,
      "loss": 0.9895,
      "step": 914500
    },
    {
      "epoch": 143.28,
      "learning_rate": 2.8358910115878486e-05,
      "loss": 0.9873,
      "step": 915000
    },
    {
      "epoch": 143.36,
      "learning_rate": 2.8319761979329783e-05,
      "loss": 1.022,
      "step": 915500
    },
    {
      "epoch": 143.44,
      "learning_rate": 2.8280613842781083e-05,
      "loss": 1.0034,
      "step": 916000
    },
    {
      "epoch": 143.52,
      "learning_rate": 2.8241465706232383e-05,
      "loss": 1.0052,
      "step": 916500
    },
    {
      "epoch": 143.6,
      "learning_rate": 2.8202317569683683e-05,
      "loss": 0.9913,
      "step": 917000
    },
    {
      "epoch": 143.67,
      "learning_rate": 2.8163169433134984e-05,
      "loss": 1.0273,
      "step": 917500
    },
    {
      "epoch": 143.75,
      "learning_rate": 2.8124021296586284e-05,
      "loss": 1.0018,
      "step": 918000
    },
    {
      "epoch": 143.83,
      "learning_rate": 2.8084873160037584e-05,
      "loss": 0.9939,
      "step": 918500
    },
    {
      "epoch": 143.91,
      "learning_rate": 2.8045725023488884e-05,
      "loss": 0.9819,
      "step": 919000
    },
    {
      "epoch": 143.99,
      "learning_rate": 2.8006576886940184e-05,
      "loss": 0.9994,
      "step": 919500
    },
    {
      "epoch": 144.0,
      "eval_loss": 1.035719633102417,
      "eval_r": 0.6089858412742615,
      "eval_runtime": 26.7689,
      "eval_samples_per_second": 59.472,
      "eval_steps_per_second": 59.472,
      "step": 919584
    },
    {
      "epoch": 144.07,
      "learning_rate": 2.7967428750391485e-05,
      "loss": 0.999,
      "step": 920000
    },
    {
      "epoch": 144.14,
      "learning_rate": 2.7928280613842785e-05,
      "loss": 1.0137,
      "step": 920500
    },
    {
      "epoch": 144.22,
      "learning_rate": 2.788913247729408e-05,
      "loss": 1.0015,
      "step": 921000
    },
    {
      "epoch": 144.3,
      "learning_rate": 2.7849984340745382e-05,
      "loss": 1.0207,
      "step": 921500
    },
    {
      "epoch": 144.38,
      "learning_rate": 2.7810836204196682e-05,
      "loss": 0.9956,
      "step": 922000
    },
    {
      "epoch": 144.46,
      "learning_rate": 2.7771688067647982e-05,
      "loss": 0.9853,
      "step": 922500
    },
    {
      "epoch": 144.53,
      "learning_rate": 2.7732539931099283e-05,
      "loss": 0.9971,
      "step": 923000
    },
    {
      "epoch": 144.61,
      "learning_rate": 2.7693391794550583e-05,
      "loss": 1.007,
      "step": 923500
    },
    {
      "epoch": 144.69,
      "learning_rate": 2.7654243658001883e-05,
      "loss": 0.9912,
      "step": 924000
    },
    {
      "epoch": 144.77,
      "learning_rate": 2.7615095521453183e-05,
      "loss": 0.9791,
      "step": 924500
    },
    {
      "epoch": 144.85,
      "learning_rate": 2.7575947384904483e-05,
      "loss": 0.991,
      "step": 925000
    },
    {
      "epoch": 144.93,
      "learning_rate": 2.7536799248355777e-05,
      "loss": 0.9807,
      "step": 925500
    },
    {
      "epoch": 145.0,
      "eval_loss": 1.0434613227844238,
      "eval_r": 0.6069616079330444,
      "eval_runtime": 26.9115,
      "eval_samples_per_second": 59.157,
      "eval_steps_per_second": 59.157,
      "step": 925970
    },
    {
      "epoch": 145.0,
      "learning_rate": 2.7497651111807077e-05,
      "loss": 1.0115,
      "step": 926000
    },
    {
      "epoch": 145.08,
      "learning_rate": 2.7458502975258377e-05,
      "loss": 1.0035,
      "step": 926500
    },
    {
      "epoch": 145.16,
      "learning_rate": 2.7419354838709678e-05,
      "loss": 0.9963,
      "step": 927000
    },
    {
      "epoch": 145.24,
      "learning_rate": 2.7380206702160978e-05,
      "loss": 1.001,
      "step": 927500
    },
    {
      "epoch": 145.32,
      "learning_rate": 2.7341058565612278e-05,
      "loss": 1.006,
      "step": 928000
    },
    {
      "epoch": 145.4,
      "learning_rate": 2.7301910429063575e-05,
      "loss": 1.0116,
      "step": 928500
    },
    {
      "epoch": 145.47,
      "learning_rate": 2.7262762292514875e-05,
      "loss": 1.0126,
      "step": 929000
    },
    {
      "epoch": 145.55,
      "learning_rate": 2.7223614155966175e-05,
      "loss": 0.9989,
      "step": 929500
    },
    {
      "epoch": 145.63,
      "learning_rate": 2.7184466019417475e-05,
      "loss": 0.9899,
      "step": 930000
    },
    {
      "epoch": 145.71,
      "learning_rate": 2.7145317882868776e-05,
      "loss": 0.9982,
      "step": 930500
    },
    {
      "epoch": 145.79,
      "learning_rate": 2.7106169746320076e-05,
      "loss": 0.9552,
      "step": 931000
    },
    {
      "epoch": 145.87,
      "learning_rate": 2.7067021609771376e-05,
      "loss": 0.992,
      "step": 931500
    },
    {
      "epoch": 145.94,
      "learning_rate": 2.7027873473222676e-05,
      "loss": 1.0051,
      "step": 932000
    },
    {
      "epoch": 146.0,
      "eval_loss": 1.0385818481445312,
      "eval_r": 0.6094831824302673,
      "eval_runtime": 26.9463,
      "eval_samples_per_second": 59.08,
      "eval_steps_per_second": 59.08,
      "step": 932356
    },
    {
      "epoch": 146.02,
      "learning_rate": 2.6988725336673977e-05,
      "loss": 0.9908,
      "step": 932500
    },
    {
      "epoch": 146.1,
      "learning_rate": 2.6949577200125277e-05,
      "loss": 1.0041,
      "step": 933000
    },
    {
      "epoch": 146.18,
      "learning_rate": 2.6910429063576577e-05,
      "loss": 0.9966,
      "step": 933500
    },
    {
      "epoch": 146.26,
      "learning_rate": 2.6871280927027874e-05,
      "loss": 0.9958,
      "step": 934000
    },
    {
      "epoch": 146.34,
      "learning_rate": 2.6832132790479174e-05,
      "loss": 0.9984,
      "step": 934500
    },
    {
      "epoch": 146.41,
      "learning_rate": 2.6792984653930474e-05,
      "loss": 0.9946,
      "step": 935000
    },
    {
      "epoch": 146.49,
      "learning_rate": 2.6753836517381774e-05,
      "loss": 1.0005,
      "step": 935500
    },
    {
      "epoch": 146.57,
      "learning_rate": 2.6714688380833075e-05,
      "loss": 1.0054,
      "step": 936000
    },
    {
      "epoch": 146.65,
      "learning_rate": 2.6675540244284375e-05,
      "loss": 0.9731,
      "step": 936500
    },
    {
      "epoch": 146.73,
      "learning_rate": 2.6636392107735675e-05,
      "loss": 1.0094,
      "step": 937000
    },
    {
      "epoch": 146.81,
      "learning_rate": 2.6597243971186975e-05,
      "loss": 0.9773,
      "step": 937500
    },
    {
      "epoch": 146.88,
      "learning_rate": 2.6558095834638276e-05,
      "loss": 1.007,
      "step": 938000
    },
    {
      "epoch": 146.96,
      "learning_rate": 2.6518947698089576e-05,
      "loss": 0.9994,
      "step": 938500
    },
    {
      "epoch": 147.0,
      "eval_loss": 1.0376442670822144,
      "eval_r": 0.6082901954650879,
      "eval_runtime": 27.3166,
      "eval_samples_per_second": 58.28,
      "eval_steps_per_second": 58.28,
      "step": 938742
    },
    {
      "epoch": 147.04,
      "learning_rate": 2.6479799561540876e-05,
      "loss": 0.9995,
      "step": 939000
    },
    {
      "epoch": 147.12,
      "learning_rate": 2.6440651424992173e-05,
      "loss": 0.9984,
      "step": 939500
    },
    {
      "epoch": 147.2,
      "learning_rate": 2.640150328844347e-05,
      "loss": 0.9927,
      "step": 940000
    },
    {
      "epoch": 147.28,
      "learning_rate": 2.636235515189477e-05,
      "loss": 0.9888,
      "step": 940500
    },
    {
      "epoch": 147.35,
      "learning_rate": 2.632320701534607e-05,
      "loss": 0.9967,
      "step": 941000
    },
    {
      "epoch": 147.43,
      "learning_rate": 2.6284058878797367e-05,
      "loss": 1.0004,
      "step": 941500
    },
    {
      "epoch": 147.51,
      "learning_rate": 2.6244910742248667e-05,
      "loss": 0.9961,
      "step": 942000
    },
    {
      "epoch": 147.59,
      "learning_rate": 2.6205762605699967e-05,
      "loss": 0.9896,
      "step": 942500
    },
    {
      "epoch": 147.67,
      "learning_rate": 2.6166614469151268e-05,
      "loss": 1.0145,
      "step": 943000
    },
    {
      "epoch": 147.75,
      "learning_rate": 2.6127466332602568e-05,
      "loss": 1.0002,
      "step": 943500
    },
    {
      "epoch": 147.82,
      "learning_rate": 2.6088318196053868e-05,
      "loss": 1.0098,
      "step": 944000
    },
    {
      "epoch": 147.9,
      "learning_rate": 2.6049170059505168e-05,
      "loss": 0.9911,
      "step": 944500
    },
    {
      "epoch": 147.98,
      "learning_rate": 2.601002192295647e-05,
      "loss": 0.9879,
      "step": 945000
    },
    {
      "epoch": 148.0,
      "eval_loss": 1.036494493484497,
      "eval_r": 0.6097685694694519,
      "eval_runtime": 27.6606,
      "eval_samples_per_second": 57.555,
      "eval_steps_per_second": 57.555,
      "step": 945128
    },
    {
      "epoch": 148.06,
      "learning_rate": 2.597087378640777e-05,
      "loss": 0.9875,
      "step": 945500
    },
    {
      "epoch": 148.14,
      "learning_rate": 2.593172564985907e-05,
      "loss": 0.9896,
      "step": 946000
    },
    {
      "epoch": 148.21,
      "learning_rate": 2.589257751331037e-05,
      "loss": 1.0121,
      "step": 946500
    },
    {
      "epoch": 148.29,
      "learning_rate": 2.5853429376761666e-05,
      "loss": 0.9983,
      "step": 947000
    },
    {
      "epoch": 148.37,
      "learning_rate": 2.5814281240212966e-05,
      "loss": 0.9906,
      "step": 947500
    },
    {
      "epoch": 148.45,
      "learning_rate": 2.5775133103664266e-05,
      "loss": 1.0188,
      "step": 948000
    },
    {
      "epoch": 148.53,
      "learning_rate": 2.5735984967115567e-05,
      "loss": 0.999,
      "step": 948500
    },
    {
      "epoch": 148.61,
      "learning_rate": 2.5696836830566867e-05,
      "loss": 0.9872,
      "step": 949000
    },
    {
      "epoch": 148.68,
      "learning_rate": 2.5657688694018167e-05,
      "loss": 0.9806,
      "step": 949500
    },
    {
      "epoch": 148.76,
      "learning_rate": 2.5618540557469467e-05,
      "loss": 0.9949,
      "step": 950000
    },
    {
      "epoch": 148.84,
      "learning_rate": 2.5579392420920767e-05,
      "loss": 0.9893,
      "step": 950500
    },
    {
      "epoch": 148.92,
      "learning_rate": 2.5540244284372068e-05,
      "loss": 0.9964,
      "step": 951000
    },
    {
      "epoch": 149.0,
      "learning_rate": 2.5501096147823368e-05,
      "loss": 1.0046,
      "step": 951500
    },
    {
      "epoch": 149.0,
      "eval_loss": 1.0343294143676758,
      "eval_r": 0.6105303168296814,
      "eval_runtime": 26.8881,
      "eval_samples_per_second": 59.208,
      "eval_steps_per_second": 59.208,
      "step": 951514
    },
    {
      "epoch": 149.08,
      "learning_rate": 2.5461948011274668e-05,
      "loss": 0.9907,
      "step": 952000
    },
    {
      "epoch": 149.15,
      "learning_rate": 2.5422799874725965e-05,
      "loss": 0.9893,
      "step": 952500
    },
    {
      "epoch": 149.23,
      "learning_rate": 2.5383651738177265e-05,
      "loss": 0.9877,
      "step": 953000
    },
    {
      "epoch": 149.31,
      "learning_rate": 2.5344503601628565e-05,
      "loss": 0.9876,
      "step": 953500
    },
    {
      "epoch": 149.39,
      "learning_rate": 2.5305355465079862e-05,
      "loss": 1.0295,
      "step": 954000
    },
    {
      "epoch": 149.47,
      "learning_rate": 2.526620732853116e-05,
      "loss": 0.9961,
      "step": 954500
    },
    {
      "epoch": 149.55,
      "learning_rate": 2.522705919198246e-05,
      "loss": 0.9861,
      "step": 955000
    },
    {
      "epoch": 149.62,
      "learning_rate": 2.518791105543376e-05,
      "loss": 1.0134,
      "step": 955500
    },
    {
      "epoch": 149.7,
      "learning_rate": 2.514876291888506e-05,
      "loss": 1.007,
      "step": 956000
    },
    {
      "epoch": 149.78,
      "learning_rate": 2.510961478233636e-05,
      "loss": 0.9935,
      "step": 956500
    },
    {
      "epoch": 149.86,
      "learning_rate": 2.507046664578766e-05,
      "loss": 0.9843,
      "step": 957000
    },
    {
      "epoch": 149.94,
      "learning_rate": 2.503131850923896e-05,
      "loss": 0.9812,
      "step": 957500
    },
    {
      "epoch": 150.0,
      "eval_loss": 1.0406177043914795,
      "eval_r": 0.6082442402839661,
      "eval_runtime": 27.2038,
      "eval_samples_per_second": 58.521,
      "eval_steps_per_second": 58.521,
      "step": 957900
    },
    {
      "epoch": 150.02,
      "learning_rate": 2.499217037269026e-05,
      "loss": 1.0132,
      "step": 958000
    },
    {
      "epoch": 150.09,
      "learning_rate": 2.495302223614156e-05,
      "loss": 1.0214,
      "step": 958500
    },
    {
      "epoch": 150.17,
      "learning_rate": 2.491387409959286e-05,
      "loss": 0.984,
      "step": 959000
    },
    {
      "epoch": 150.25,
      "learning_rate": 2.487472596304416e-05,
      "loss": 0.9805,
      "step": 959500
    },
    {
      "epoch": 150.33,
      "learning_rate": 2.4835577826495458e-05,
      "loss": 0.9983,
      "step": 960000
    },
    {
      "epoch": 150.41,
      "learning_rate": 2.4796429689946758e-05,
      "loss": 0.9966,
      "step": 960500
    },
    {
      "epoch": 150.49,
      "learning_rate": 2.475728155339806e-05,
      "loss": 0.9943,
      "step": 961000
    },
    {
      "epoch": 150.56,
      "learning_rate": 2.471813341684936e-05,
      "loss": 1.0061,
      "step": 961500
    },
    {
      "epoch": 150.64,
      "learning_rate": 2.467898528030066e-05,
      "loss": 0.994,
      "step": 962000
    },
    {
      "epoch": 150.72,
      "learning_rate": 2.463983714375196e-05,
      "loss": 0.9842,
      "step": 962500
    },
    {
      "epoch": 150.8,
      "learning_rate": 2.460068900720326e-05,
      "loss": 0.9987,
      "step": 963000
    },
    {
      "epoch": 150.88,
      "learning_rate": 2.456154087065456e-05,
      "loss": 0.9834,
      "step": 963500
    },
    {
      "epoch": 150.96,
      "learning_rate": 2.452239273410586e-05,
      "loss": 0.9898,
      "step": 964000
    },
    {
      "epoch": 151.0,
      "eval_loss": 1.040126919746399,
      "eval_r": 0.6080723404884338,
      "eval_runtime": 26.9303,
      "eval_samples_per_second": 59.116,
      "eval_steps_per_second": 59.116,
      "step": 964286
    },
    {
      "epoch": 151.03,
      "learning_rate": 2.4483244597557157e-05,
      "loss": 1.0104,
      "step": 964500
    },
    {
      "epoch": 151.11,
      "learning_rate": 2.4444096461008457e-05,
      "loss": 0.9897,
      "step": 965000
    },
    {
      "epoch": 151.19,
      "learning_rate": 2.4404948324459757e-05,
      "loss": 0.992,
      "step": 965500
    },
    {
      "epoch": 151.27,
      "learning_rate": 2.4365800187911057e-05,
      "loss": 0.995,
      "step": 966000
    },
    {
      "epoch": 151.35,
      "learning_rate": 2.4326652051362357e-05,
      "loss": 0.9952,
      "step": 966500
    },
    {
      "epoch": 151.42,
      "learning_rate": 2.4287503914813654e-05,
      "loss": 0.9928,
      "step": 967000
    },
    {
      "epoch": 151.5,
      "learning_rate": 2.4248355778264955e-05,
      "loss": 0.9917,
      "step": 967500
    },
    {
      "epoch": 151.58,
      "learning_rate": 2.4209207641716255e-05,
      "loss": 0.9969,
      "step": 968000
    },
    {
      "epoch": 151.66,
      "learning_rate": 2.4170059505167555e-05,
      "loss": 1.0046,
      "step": 968500
    },
    {
      "epoch": 151.74,
      "learning_rate": 2.4130911368618855e-05,
      "loss": 0.992,
      "step": 969000
    },
    {
      "epoch": 151.82,
      "learning_rate": 2.4091763232070155e-05,
      "loss": 0.9914,
      "step": 969500
    },
    {
      "epoch": 151.89,
      "learning_rate": 2.4052615095521456e-05,
      "loss": 0.9894,
      "step": 970000
    },
    {
      "epoch": 151.97,
      "learning_rate": 2.4013466958972756e-05,
      "loss": 0.9991,
      "step": 970500
    },
    {
      "epoch": 152.0,
      "eval_loss": 1.0392943620681763,
      "eval_r": 0.6084945201873779,
      "eval_runtime": 27.2347,
      "eval_samples_per_second": 58.455,
      "eval_steps_per_second": 58.455,
      "step": 970672
    },
    {
      "epoch": 152.05,
      "learning_rate": 2.3974318822424056e-05,
      "loss": 0.9873,
      "step": 971000
    },
    {
      "epoch": 152.13,
      "learning_rate": 2.3935170685875353e-05,
      "loss": 1.0277,
      "step": 971500
    },
    {
      "epoch": 152.21,
      "learning_rate": 2.3896022549326653e-05,
      "loss": 1.0263,
      "step": 972000
    },
    {
      "epoch": 152.29,
      "learning_rate": 2.3856874412777953e-05,
      "loss": 0.9969,
      "step": 972500
    },
    {
      "epoch": 152.36,
      "learning_rate": 2.3817726276229254e-05,
      "loss": 0.9945,
      "step": 973000
    },
    {
      "epoch": 152.44,
      "learning_rate": 2.377857813968055e-05,
      "loss": 0.986,
      "step": 973500
    },
    {
      "epoch": 152.52,
      "learning_rate": 2.373943000313185e-05,
      "loss": 1.003,
      "step": 974000
    },
    {
      "epoch": 152.6,
      "learning_rate": 2.370028186658315e-05,
      "loss": 0.9698,
      "step": 974500
    },
    {
      "epoch": 152.68,
      "learning_rate": 2.366113373003445e-05,
      "loss": 1.0125,
      "step": 975000
    },
    {
      "epoch": 152.76,
      "learning_rate": 2.362198559348575e-05,
      "loss": 0.9911,
      "step": 975500
    },
    {
      "epoch": 152.83,
      "learning_rate": 2.358283745693705e-05,
      "loss": 0.9902,
      "step": 976000
    },
    {
      "epoch": 152.91,
      "learning_rate": 2.3543689320388352e-05,
      "loss": 0.9878,
      "step": 976500
    },
    {
      "epoch": 152.99,
      "learning_rate": 2.3504541183839652e-05,
      "loss": 0.9815,
      "step": 977000
    },
    {
      "epoch": 153.0,
      "eval_loss": 1.040090560913086,
      "eval_r": 0.6077576279640198,
      "eval_runtime": 26.995,
      "eval_samples_per_second": 58.974,
      "eval_steps_per_second": 58.974,
      "step": 977058
    },
    {
      "epoch": 153.07,
      "learning_rate": 2.3465393047290952e-05,
      "loss": 0.9862,
      "step": 977500
    },
    {
      "epoch": 153.15,
      "learning_rate": 2.3426244910742252e-05,
      "loss": 1.0178,
      "step": 978000
    },
    {
      "epoch": 153.23,
      "learning_rate": 2.338709677419355e-05,
      "loss": 0.9853,
      "step": 978500
    },
    {
      "epoch": 153.3,
      "learning_rate": 2.334794863764485e-05,
      "loss": 0.9673,
      "step": 979000
    },
    {
      "epoch": 153.38,
      "learning_rate": 2.330880050109615e-05,
      "loss": 0.9903,
      "step": 979500
    },
    {
      "epoch": 153.46,
      "learning_rate": 2.3269652364547446e-05,
      "loss": 0.9812,
      "step": 980000
    },
    {
      "epoch": 153.54,
      "learning_rate": 2.3230504227998747e-05,
      "loss": 1.0,
      "step": 980500
    },
    {
      "epoch": 153.62,
      "learning_rate": 2.3191356091450047e-05,
      "loss": 0.9997,
      "step": 981000
    },
    {
      "epoch": 153.7,
      "learning_rate": 2.3152207954901347e-05,
      "loss": 1.0057,
      "step": 981500
    },
    {
      "epoch": 153.77,
      "learning_rate": 2.3113059818352647e-05,
      "loss": 0.9906,
      "step": 982000
    },
    {
      "epoch": 153.85,
      "learning_rate": 2.3073911681803948e-05,
      "loss": 0.9943,
      "step": 982500
    },
    {
      "epoch": 153.93,
      "learning_rate": 2.3034763545255248e-05,
      "loss": 1.026,
      "step": 983000
    },
    {
      "epoch": 154.0,
      "eval_loss": 1.0438352823257446,
      "eval_r": 0.6068052649497986,
      "eval_runtime": 27.4668,
      "eval_samples_per_second": 57.961,
      "eval_steps_per_second": 57.961,
      "step": 983444
    },
    {
      "epoch": 154.01,
      "learning_rate": 2.2995615408706548e-05,
      "loss": 0.9838,
      "step": 983500
    },
    {
      "epoch": 154.09,
      "learning_rate": 2.2956467272157848e-05,
      "loss": 1.0066,
      "step": 984000
    },
    {
      "epoch": 154.17,
      "learning_rate": 2.291731913560915e-05,
      "loss": 0.9998,
      "step": 984500
    },
    {
      "epoch": 154.24,
      "learning_rate": 2.287817099906045e-05,
      "loss": 0.9941,
      "step": 985000
    },
    {
      "epoch": 154.32,
      "learning_rate": 2.2839022862511745e-05,
      "loss": 0.9792,
      "step": 985500
    },
    {
      "epoch": 154.4,
      "learning_rate": 2.2799874725963046e-05,
      "loss": 1.0078,
      "step": 986000
    },
    {
      "epoch": 154.48,
      "learning_rate": 2.2760726589414343e-05,
      "loss": 0.9788,
      "step": 986500
    },
    {
      "epoch": 154.56,
      "learning_rate": 2.2721578452865643e-05,
      "loss": 1.0015,
      "step": 987000
    },
    {
      "epoch": 154.64,
      "learning_rate": 2.2682430316316943e-05,
      "loss": 0.9693,
      "step": 987500
    },
    {
      "epoch": 154.71,
      "learning_rate": 2.2643282179768243e-05,
      "loss": 0.995,
      "step": 988000
    },
    {
      "epoch": 154.79,
      "learning_rate": 2.2604134043219543e-05,
      "loss": 1.0086,
      "step": 988500
    },
    {
      "epoch": 154.87,
      "learning_rate": 2.2564985906670844e-05,
      "loss": 0.9852,
      "step": 989000
    },
    {
      "epoch": 154.95,
      "learning_rate": 2.2525837770122144e-05,
      "loss": 1.0159,
      "step": 989500
    },
    {
      "epoch": 155.0,
      "eval_loss": 1.0379869937896729,
      "eval_r": 0.6078360676765442,
      "eval_runtime": 27.1079,
      "eval_samples_per_second": 58.728,
      "eval_steps_per_second": 58.728,
      "step": 989830
    },
    {
      "epoch": 155.03,
      "learning_rate": 2.2486689633573444e-05,
      "loss": 0.987,
      "step": 990000
    },
    {
      "epoch": 155.1,
      "learning_rate": 2.2447541497024744e-05,
      "loss": 0.9897,
      "step": 990500
    },
    {
      "epoch": 155.18,
      "learning_rate": 2.2408393360476044e-05,
      "loss": 1.0034,
      "step": 991000
    },
    {
      "epoch": 155.26,
      "learning_rate": 2.2369245223927345e-05,
      "loss": 0.9955,
      "step": 991500
    },
    {
      "epoch": 155.34,
      "learning_rate": 2.233009708737864e-05,
      "loss": 0.9963,
      "step": 992000
    },
    {
      "epoch": 155.42,
      "learning_rate": 2.2290948950829942e-05,
      "loss": 0.9733,
      "step": 992500
    },
    {
      "epoch": 155.5,
      "learning_rate": 2.225180081428124e-05,
      "loss": 0.9874,
      "step": 993000
    },
    {
      "epoch": 155.57,
      "learning_rate": 2.221265267773254e-05,
      "loss": 0.9718,
      "step": 993500
    },
    {
      "epoch": 155.65,
      "learning_rate": 2.217350454118384e-05,
      "loss": 1.0206,
      "step": 994000
    },
    {
      "epoch": 155.73,
      "learning_rate": 2.213435640463514e-05,
      "loss": 1.0,
      "step": 994500
    },
    {
      "epoch": 155.81,
      "learning_rate": 2.209520826808644e-05,
      "loss": 0.9963,
      "step": 995000
    },
    {
      "epoch": 155.89,
      "learning_rate": 2.205606013153774e-05,
      "loss": 1.0074,
      "step": 995500
    },
    {
      "epoch": 155.97,
      "learning_rate": 2.201691199498904e-05,
      "loss": 0.9938,
      "step": 996000
    },
    {
      "epoch": 156.0,
      "eval_loss": 1.0427418947219849,
      "eval_r": 0.6064701080322266,
      "eval_runtime": 26.6908,
      "eval_samples_per_second": 59.646,
      "eval_steps_per_second": 59.646,
      "step": 996216
    },
    {
      "epoch": 156.04,
      "learning_rate": 2.197776385844034e-05,
      "loss": 0.9942,
      "step": 996500
    },
    {
      "epoch": 156.12,
      "learning_rate": 2.193861572189164e-05,
      "loss": 1.0002,
      "step": 997000
    },
    {
      "epoch": 156.2,
      "learning_rate": 2.189946758534294e-05,
      "loss": 0.9885,
      "step": 997500
    },
    {
      "epoch": 156.28,
      "learning_rate": 2.186031944879424e-05,
      "loss": 1.0137,
      "step": 998000
    },
    {
      "epoch": 156.36,
      "learning_rate": 2.1821171312245538e-05,
      "loss": 0.9786,
      "step": 998500
    },
    {
      "epoch": 156.44,
      "learning_rate": 2.1782023175696838e-05,
      "loss": 0.9891,
      "step": 999000
    },
    {
      "epoch": 156.51,
      "learning_rate": 2.1742875039148138e-05,
      "loss": 0.9747,
      "step": 999500
    },
    {
      "epoch": 156.59,
      "learning_rate": 2.1703726902599435e-05,
      "loss": 0.9854,
      "step": 1000000
    },
    {
      "epoch": 156.67,
      "learning_rate": 2.1664578766050735e-05,
      "loss": 0.9842,
      "step": 1000500
    },
    {
      "epoch": 156.75,
      "learning_rate": 2.1625430629502035e-05,
      "loss": 1.0031,
      "step": 1001000
    },
    {
      "epoch": 156.83,
      "learning_rate": 2.1586282492953335e-05,
      "loss": 0.9959,
      "step": 1001500
    },
    {
      "epoch": 156.91,
      "learning_rate": 2.1547134356404636e-05,
      "loss": 0.9966,
      "step": 1002000
    },
    {
      "epoch": 156.98,
      "learning_rate": 2.1507986219855936e-05,
      "loss": 0.9896,
      "step": 1002500
    },
    {
      "epoch": 157.0,
      "eval_loss": 1.0400114059448242,
      "eval_r": 0.607755720615387,
      "eval_runtime": 27.9294,
      "eval_samples_per_second": 57.001,
      "eval_steps_per_second": 57.001,
      "step": 1002602
    },
    {
      "epoch": 157.06,
      "learning_rate": 2.1468838083307236e-05,
      "loss": 1.0001,
      "step": 1003000
    },
    {
      "epoch": 157.14,
      "learning_rate": 2.1429689946758536e-05,
      "loss": 0.9879,
      "step": 1003500
    },
    {
      "epoch": 157.22,
      "learning_rate": 2.1390541810209837e-05,
      "loss": 1.0032,
      "step": 1004000
    },
    {
      "epoch": 157.3,
      "learning_rate": 2.1351393673661137e-05,
      "loss": 1.0052,
      "step": 1004500
    },
    {
      "epoch": 157.38,
      "learning_rate": 2.1312245537112434e-05,
      "loss": 0.9722,
      "step": 1005000
    },
    {
      "epoch": 157.45,
      "learning_rate": 2.1273097400563734e-05,
      "loss": 0.9907,
      "step": 1005500
    },
    {
      "epoch": 157.53,
      "learning_rate": 2.1233949264015034e-05,
      "loss": 1.0046,
      "step": 1006000
    },
    {
      "epoch": 157.61,
      "learning_rate": 2.1194801127466334e-05,
      "loss": 0.9848,
      "step": 1006500
    },
    {
      "epoch": 157.69,
      "learning_rate": 2.115565299091763e-05,
      "loss": 0.9848,
      "step": 1007000
    },
    {
      "epoch": 157.77,
      "learning_rate": 2.111650485436893e-05,
      "loss": 0.9762,
      "step": 1007500
    },
    {
      "epoch": 157.85,
      "learning_rate": 2.107735671782023e-05,
      "loss": 1.0085,
      "step": 1008000
    },
    {
      "epoch": 157.92,
      "learning_rate": 2.1038208581271532e-05,
      "loss": 1.0018,
      "step": 1008500
    },
    {
      "epoch": 158.0,
      "eval_loss": 1.041024088859558,
      "eval_r": 0.607820451259613,
      "eval_runtime": 26.4679,
      "eval_samples_per_second": 60.148,
      "eval_steps_per_second": 60.148,
      "step": 1008988
    },
    {
      "epoch": 158.0,
      "learning_rate": 2.0999060444722832e-05,
      "loss": 0.9883,
      "step": 1009000
    },
    {
      "epoch": 158.08,
      "learning_rate": 2.0959912308174132e-05,
      "loss": 1.0079,
      "step": 1009500
    },
    {
      "epoch": 158.16,
      "learning_rate": 2.0920764171625432e-05,
      "loss": 0.9968,
      "step": 1010000
    },
    {
      "epoch": 158.24,
      "learning_rate": 2.0881616035076733e-05,
      "loss": 0.9851,
      "step": 1010500
    },
    {
      "epoch": 158.32,
      "learning_rate": 2.0842467898528033e-05,
      "loss": 0.9921,
      "step": 1011000
    },
    {
      "epoch": 158.39,
      "learning_rate": 2.080331976197933e-05,
      "loss": 1.0256,
      "step": 1011500
    },
    {
      "epoch": 158.47,
      "learning_rate": 2.076417162543063e-05,
      "loss": 0.998,
      "step": 1012000
    },
    {
      "epoch": 158.55,
      "learning_rate": 2.072502348888193e-05,
      "loss": 0.9961,
      "step": 1012500
    },
    {
      "epoch": 158.63,
      "learning_rate": 2.068587535233323e-05,
      "loss": 0.9787,
      "step": 1013000
    },
    {
      "epoch": 158.71,
      "learning_rate": 2.064672721578453e-05,
      "loss": 0.9779,
      "step": 1013500
    },
    {
      "epoch": 158.78,
      "learning_rate": 2.0607579079235827e-05,
      "loss": 1.0025,
      "step": 1014000
    },
    {
      "epoch": 158.86,
      "learning_rate": 2.0568430942687128e-05,
      "loss": 0.9828,
      "step": 1014500
    },
    {
      "epoch": 158.94,
      "learning_rate": 2.0529282806138428e-05,
      "loss": 0.9832,
      "step": 1015000
    },
    {
      "epoch": 159.0,
      "eval_loss": 1.038840889930725,
      "eval_r": 0.607840895652771,
      "eval_runtime": 27.2422,
      "eval_samples_per_second": 58.439,
      "eval_steps_per_second": 58.439,
      "step": 1015374
    },
    {
      "epoch": 159.02,
      "learning_rate": 2.0490134669589728e-05,
      "loss": 0.9978,
      "step": 1015500
    },
    {
      "epoch": 159.1,
      "learning_rate": 2.0450986533041028e-05,
      "loss": 1.0129,
      "step": 1016000
    },
    {
      "epoch": 159.18,
      "learning_rate": 2.041183839649233e-05,
      "loss": 0.9788,
      "step": 1016500
    },
    {
      "epoch": 159.25,
      "learning_rate": 2.037269025994363e-05,
      "loss": 0.9785,
      "step": 1017000
    },
    {
      "epoch": 159.33,
      "learning_rate": 2.033354212339493e-05,
      "loss": 0.9877,
      "step": 1017500
    },
    {
      "epoch": 159.41,
      "learning_rate": 2.0294393986846226e-05,
      "loss": 0.9869,
      "step": 1018000
    },
    {
      "epoch": 159.49,
      "learning_rate": 2.0255245850297526e-05,
      "loss": 0.9836,
      "step": 1018500
    },
    {
      "epoch": 159.57,
      "learning_rate": 2.0216097713748826e-05,
      "loss": 1.0018,
      "step": 1019000
    },
    {
      "epoch": 159.65,
      "learning_rate": 2.0176949577200126e-05,
      "loss": 0.9938,
      "step": 1019500
    },
    {
      "epoch": 159.72,
      "learning_rate": 2.0137801440651427e-05,
      "loss": 0.9935,
      "step": 1020000
    },
    {
      "epoch": 159.8,
      "learning_rate": 2.0098653304102727e-05,
      "loss": 1.0079,
      "step": 1020500
    },
    {
      "epoch": 159.88,
      "learning_rate": 2.0059505167554024e-05,
      "loss": 0.9765,
      "step": 1021000
    },
    {
      "epoch": 159.96,
      "learning_rate": 2.0020357031005324e-05,
      "loss": 0.9887,
      "step": 1021500
    },
    {
      "epoch": 160.0,
      "eval_loss": 1.0388363599777222,
      "eval_r": 0.6081976294517517,
      "eval_runtime": 27.4042,
      "eval_samples_per_second": 58.093,
      "eval_steps_per_second": 58.093,
      "step": 1021760
    },
    {
      "epoch": 160.04,
      "learning_rate": 1.9981208894456624e-05,
      "loss": 1.0105,
      "step": 1022000
    },
    {
      "epoch": 160.12,
      "learning_rate": 1.9942060757907924e-05,
      "loss": 0.9835,
      "step": 1022500
    },
    {
      "epoch": 160.19,
      "learning_rate": 1.9902912621359225e-05,
      "loss": 0.9991,
      "step": 1023000
    },
    {
      "epoch": 160.27,
      "learning_rate": 1.9863764484810525e-05,
      "loss": 1.0181,
      "step": 1023500
    },
    {
      "epoch": 160.35,
      "learning_rate": 1.9824616348261825e-05,
      "loss": 0.9921,
      "step": 1024000
    },
    {
      "epoch": 160.43,
      "learning_rate": 1.9785468211713122e-05,
      "loss": 1.004,
      "step": 1024500
    },
    {
      "epoch": 160.51,
      "learning_rate": 1.9746320075164422e-05,
      "loss": 1.0013,
      "step": 1025000
    },
    {
      "epoch": 160.59,
      "learning_rate": 1.9707171938615722e-05,
      "loss": 0.9819,
      "step": 1025500
    },
    {
      "epoch": 160.66,
      "learning_rate": 1.9668023802067022e-05,
      "loss": 0.9718,
      "step": 1026000
    },
    {
      "epoch": 160.74,
      "learning_rate": 1.9628875665518323e-05,
      "loss": 0.9903,
      "step": 1026500
    },
    {
      "epoch": 160.82,
      "learning_rate": 1.9589727528969623e-05,
      "loss": 0.9788,
      "step": 1027000
    },
    {
      "epoch": 160.9,
      "learning_rate": 1.9550579392420923e-05,
      "loss": 0.9896,
      "step": 1027500
    },
    {
      "epoch": 160.98,
      "learning_rate": 1.951143125587222e-05,
      "loss": 0.9736,
      "step": 1028000
    },
    {
      "epoch": 161.0,
      "eval_loss": 1.0396925210952759,
      "eval_r": 0.6088196039199829,
      "eval_runtime": 26.9667,
      "eval_samples_per_second": 59.036,
      "eval_steps_per_second": 59.036,
      "step": 1028146
    },
    {
      "epoch": 161.06,
      "learning_rate": 1.947228311932352e-05,
      "loss": 0.9869,
      "step": 1028500
    },
    {
      "epoch": 161.13,
      "learning_rate": 1.943313498277482e-05,
      "loss": 1.0041,
      "step": 1029000
    },
    {
      "epoch": 161.21,
      "learning_rate": 1.939398684622612e-05,
      "loss": 0.9957,
      "step": 1029500
    },
    {
      "epoch": 161.29,
      "learning_rate": 1.935483870967742e-05,
      "loss": 0.9837,
      "step": 1030000
    },
    {
      "epoch": 161.37,
      "learning_rate": 1.931569057312872e-05,
      "loss": 0.9834,
      "step": 1030500
    },
    {
      "epoch": 161.45,
      "learning_rate": 1.9276542436580018e-05,
      "loss": 0.9848,
      "step": 1031000
    },
    {
      "epoch": 161.53,
      "learning_rate": 1.9237394300031318e-05,
      "loss": 0.9996,
      "step": 1031500
    },
    {
      "epoch": 161.6,
      "learning_rate": 1.919824616348262e-05,
      "loss": 0.9925,
      "step": 1032000
    },
    {
      "epoch": 161.68,
      "learning_rate": 1.915909802693392e-05,
      "loss": 0.9895,
      "step": 1032500
    },
    {
      "epoch": 161.76,
      "learning_rate": 1.911994989038522e-05,
      "loss": 0.9896,
      "step": 1033000
    },
    {
      "epoch": 161.84,
      "learning_rate": 1.908080175383652e-05,
      "loss": 0.9865,
      "step": 1033500
    },
    {
      "epoch": 161.92,
      "learning_rate": 1.904165361728782e-05,
      "loss": 1.0024,
      "step": 1034000
    },
    {
      "epoch": 161.99,
      "learning_rate": 1.900250548073912e-05,
      "loss": 1.0048,
      "step": 1034500
    },
    {
      "epoch": 162.0,
      "eval_loss": 1.04384183883667,
      "eval_r": 0.6065804362297058,
      "eval_runtime": 27.3713,
      "eval_samples_per_second": 58.163,
      "eval_steps_per_second": 58.163,
      "step": 1034532
    },
    {
      "epoch": 162.07,
      "learning_rate": 1.8963357344190416e-05,
      "loss": 0.9951,
      "step": 1035000
    },
    {
      "epoch": 162.15,
      "learning_rate": 1.8924209207641716e-05,
      "loss": 0.9863,
      "step": 1035500
    },
    {
      "epoch": 162.23,
      "learning_rate": 1.8885061071093017e-05,
      "loss": 0.9733,
      "step": 1036000
    },
    {
      "epoch": 162.31,
      "learning_rate": 1.8845912934544317e-05,
      "loss": 1.0029,
      "step": 1036500
    },
    {
      "epoch": 162.39,
      "learning_rate": 1.8806764797995617e-05,
      "loss": 0.9706,
      "step": 1037000
    },
    {
      "epoch": 162.46,
      "learning_rate": 1.8767616661446917e-05,
      "loss": 1.0011,
      "step": 1037500
    },
    {
      "epoch": 162.54,
      "learning_rate": 1.8728468524898214e-05,
      "loss": 0.9995,
      "step": 1038000
    },
    {
      "epoch": 162.62,
      "learning_rate": 1.8689320388349514e-05,
      "loss": 1.0153,
      "step": 1038500
    },
    {
      "epoch": 162.7,
      "learning_rate": 1.8650172251800815e-05,
      "loss": 0.9836,
      "step": 1039000
    },
    {
      "epoch": 162.78,
      "learning_rate": 1.8611024115252115e-05,
      "loss": 0.9815,
      "step": 1039500
    },
    {
      "epoch": 162.86,
      "learning_rate": 1.8571875978703415e-05,
      "loss": 0.9916,
      "step": 1040000
    },
    {
      "epoch": 162.93,
      "learning_rate": 1.8532727842154715e-05,
      "loss": 0.9912,
      "step": 1040500
    },
    {
      "epoch": 163.0,
      "eval_loss": 1.0420650243759155,
      "eval_r": 0.6078974008560181,
      "eval_runtime": 26.8855,
      "eval_samples_per_second": 59.214,
      "eval_steps_per_second": 59.214,
      "step": 1040918
    },
    {
      "epoch": 163.01,
      "learning_rate": 1.8493579705606015e-05,
      "loss": 0.9908,
      "step": 1041000
    },
    {
      "epoch": 163.09,
      "learning_rate": 1.8454431569057316e-05,
      "loss": 0.9949,
      "step": 1041500
    },
    {
      "epoch": 163.17,
      "learning_rate": 1.8415283432508613e-05,
      "loss": 0.9819,
      "step": 1042000
    },
    {
      "epoch": 163.25,
      "learning_rate": 1.8376135295959913e-05,
      "loss": 1.0144,
      "step": 1042500
    },
    {
      "epoch": 163.33,
      "learning_rate": 1.8336987159411213e-05,
      "loss": 0.9705,
      "step": 1043000
    },
    {
      "epoch": 163.4,
      "learning_rate": 1.8297839022862513e-05,
      "loss": 0.9938,
      "step": 1043500
    },
    {
      "epoch": 163.48,
      "learning_rate": 1.8258690886313813e-05,
      "loss": 0.9873,
      "step": 1044000
    },
    {
      "epoch": 163.56,
      "learning_rate": 1.821954274976511e-05,
      "loss": 0.9781,
      "step": 1044500
    },
    {
      "epoch": 163.64,
      "learning_rate": 1.818039461321641e-05,
      "loss": 1.0022,
      "step": 1045000
    },
    {
      "epoch": 163.72,
      "learning_rate": 1.814124647666771e-05,
      "loss": 0.9968,
      "step": 1045500
    },
    {
      "epoch": 163.8,
      "learning_rate": 1.810209834011901e-05,
      "loss": 0.9997,
      "step": 1046000
    },
    {
      "epoch": 163.87,
      "learning_rate": 1.806295020357031e-05,
      "loss": 1.0084,
      "step": 1046500
    },
    {
      "epoch": 163.95,
      "learning_rate": 1.802380206702161e-05,
      "loss": 0.9699,
      "step": 1047000
    },
    {
      "epoch": 164.0,
      "eval_loss": 1.0410853624343872,
      "eval_r": 0.6068255305290222,
      "eval_runtime": 27.1147,
      "eval_samples_per_second": 58.713,
      "eval_steps_per_second": 58.713,
      "step": 1047304
    },
    {
      "epoch": 164.03,
      "learning_rate": 1.798465393047291e-05,
      "loss": 0.9787,
      "step": 1047500
    },
    {
      "epoch": 164.11,
      "learning_rate": 1.7945505793924212e-05,
      "loss": 0.9822,
      "step": 1048000
    },
    {
      "epoch": 164.19,
      "learning_rate": 1.7906357657375512e-05,
      "loss": 0.9961,
      "step": 1048500
    },
    {
      "epoch": 164.27,
      "learning_rate": 1.7867209520826812e-05,
      "loss": 0.9903,
      "step": 1049000
    },
    {
      "epoch": 164.34,
      "learning_rate": 1.782806138427811e-05,
      "loss": 0.9778,
      "step": 1049500
    },
    {
      "epoch": 164.42,
      "learning_rate": 1.778891324772941e-05,
      "loss": 0.989,
      "step": 1050000
    },
    {
      "epoch": 164.5,
      "learning_rate": 1.774976511118071e-05,
      "loss": 0.9634,
      "step": 1050500
    },
    {
      "epoch": 164.58,
      "learning_rate": 1.7710616974632006e-05,
      "loss": 1.0076,
      "step": 1051000
    },
    {
      "epoch": 164.66,
      "learning_rate": 1.7671468838083306e-05,
      "loss": 0.9974,
      "step": 1051500
    },
    {
      "epoch": 164.74,
      "learning_rate": 1.7632320701534607e-05,
      "loss": 1.0071,
      "step": 1052000
    },
    {
      "epoch": 164.81,
      "learning_rate": 1.7593172564985907e-05,
      "loss": 0.9875,
      "step": 1052500
    },
    {
      "epoch": 164.89,
      "learning_rate": 1.7554024428437207e-05,
      "loss": 0.9956,
      "step": 1053000
    },
    {
      "epoch": 164.97,
      "learning_rate": 1.7514876291888507e-05,
      "loss": 0.9828,
      "step": 1053500
    },
    {
      "epoch": 165.0,
      "eval_loss": 1.0372930765151978,
      "eval_r": 0.6082699298858643,
      "eval_runtime": 27.5085,
      "eval_samples_per_second": 57.873,
      "eval_steps_per_second": 57.873,
      "step": 1053690
    },
    {
      "epoch": 165.05,
      "learning_rate": 1.7475728155339808e-05,
      "loss": 0.9777,
      "step": 1054000
    },
    {
      "epoch": 165.13,
      "learning_rate": 1.7436580018791108e-05,
      "loss": 0.9855,
      "step": 1054500
    },
    {
      "epoch": 165.21,
      "learning_rate": 1.7397431882242408e-05,
      "loss": 0.9866,
      "step": 1055000
    },
    {
      "epoch": 165.28,
      "learning_rate": 1.7358283745693708e-05,
      "loss": 0.9782,
      "step": 1055500
    },
    {
      "epoch": 165.36,
      "learning_rate": 1.731913560914501e-05,
      "loss": 0.9846,
      "step": 1056000
    },
    {
      "epoch": 165.44,
      "learning_rate": 1.7279987472596305e-05,
      "loss": 0.9761,
      "step": 1056500
    },
    {
      "epoch": 165.52,
      "learning_rate": 1.7240839336047606e-05,
      "loss": 0.9994,
      "step": 1057000
    },
    {
      "epoch": 165.6,
      "learning_rate": 1.7201691199498902e-05,
      "loss": 0.9868,
      "step": 1057500
    },
    {
      "epoch": 165.67,
      "learning_rate": 1.7162543062950203e-05,
      "loss": 1.0062,
      "step": 1058000
    },
    {
      "epoch": 165.75,
      "learning_rate": 1.7123394926401503e-05,
      "loss": 1.0008,
      "step": 1058500
    },
    {
      "epoch": 165.83,
      "learning_rate": 1.7084246789852803e-05,
      "loss": 0.9878,
      "step": 1059000
    },
    {
      "epoch": 165.91,
      "learning_rate": 1.7045098653304103e-05,
      "loss": 1.0072,
      "step": 1059500
    },
    {
      "epoch": 165.99,
      "learning_rate": 1.7005950516755403e-05,
      "loss": 0.9794,
      "step": 1060000
    },
    {
      "epoch": 166.0,
      "eval_loss": 1.0395843982696533,
      "eval_r": 0.6083398461341858,
      "eval_runtime": 27.1309,
      "eval_samples_per_second": 58.679,
      "eval_steps_per_second": 58.679,
      "step": 1060076
    },
    {
      "epoch": 166.07,
      "learning_rate": 1.6966802380206704e-05,
      "loss": 0.9806,
      "step": 1060500
    },
    {
      "epoch": 166.14,
      "learning_rate": 1.6927654243658004e-05,
      "loss": 0.9707,
      "step": 1061000
    },
    {
      "epoch": 166.22,
      "learning_rate": 1.6888506107109304e-05,
      "loss": 1.0087,
      "step": 1061500
    },
    {
      "epoch": 166.3,
      "learning_rate": 1.6849357970560604e-05,
      "loss": 0.9987,
      "step": 1062000
    },
    {
      "epoch": 166.38,
      "learning_rate": 1.6810209834011905e-05,
      "loss": 0.9715,
      "step": 1062500
    },
    {
      "epoch": 166.46,
      "learning_rate": 1.67710616974632e-05,
      "loss": 0.9712,
      "step": 1063000
    },
    {
      "epoch": 166.54,
      "learning_rate": 1.67319135609145e-05,
      "loss": 0.9989,
      "step": 1063500
    },
    {
      "epoch": 166.61,
      "learning_rate": 1.66927654243658e-05,
      "loss": 1.0003,
      "step": 1064000
    },
    {
      "epoch": 166.69,
      "learning_rate": 1.66536172878171e-05,
      "loss": 0.9873,
      "step": 1064500
    },
    {
      "epoch": 166.77,
      "learning_rate": 1.66144691512684e-05,
      "loss": 0.995,
      "step": 1065000
    },
    {
      "epoch": 166.85,
      "learning_rate": 1.65753210147197e-05,
      "loss": 0.9906,
      "step": 1065500
    },
    {
      "epoch": 166.93,
      "learning_rate": 1.6536172878171e-05,
      "loss": 0.9957,
      "step": 1066000
    },
    {
      "epoch": 167.0,
      "eval_loss": 1.037211298942566,
      "eval_r": 0.607583224773407,
      "eval_runtime": 27.4329,
      "eval_samples_per_second": 58.033,
      "eval_steps_per_second": 58.033,
      "step": 1066462
    },
    {
      "epoch": 167.01,
      "learning_rate": 1.64970247416223e-05,
      "loss": 0.987,
      "step": 1066500
    },
    {
      "epoch": 167.08,
      "learning_rate": 1.64578766050736e-05,
      "loss": 0.9806,
      "step": 1067000
    },
    {
      "epoch": 167.16,
      "learning_rate": 1.64187284685249e-05,
      "loss": 0.9855,
      "step": 1067500
    },
    {
      "epoch": 167.24,
      "learning_rate": 1.63795803319762e-05,
      "loss": 1.0089,
      "step": 1068000
    },
    {
      "epoch": 167.32,
      "learning_rate": 1.63404321954275e-05,
      "loss": 0.9549,
      "step": 1068500
    },
    {
      "epoch": 167.4,
      "learning_rate": 1.63012840588788e-05,
      "loss": 0.9741,
      "step": 1069000
    },
    {
      "epoch": 167.48,
      "learning_rate": 1.6262135922330097e-05,
      "loss": 1.0072,
      "step": 1069500
    },
    {
      "epoch": 167.55,
      "learning_rate": 1.6222987785781398e-05,
      "loss": 0.9789,
      "step": 1070000
    },
    {
      "epoch": 167.63,
      "learning_rate": 1.6183839649232694e-05,
      "loss": 0.9957,
      "step": 1070500
    },
    {
      "epoch": 167.71,
      "learning_rate": 1.6144691512683995e-05,
      "loss": 0.9873,
      "step": 1071000
    },
    {
      "epoch": 167.79,
      "learning_rate": 1.6105543376135295e-05,
      "loss": 1.0058,
      "step": 1071500
    },
    {
      "epoch": 167.87,
      "learning_rate": 1.6066395239586595e-05,
      "loss": 0.9873,
      "step": 1072000
    },
    {
      "epoch": 167.95,
      "learning_rate": 1.6027247103037895e-05,
      "loss": 0.9826,
      "step": 1072500
    },
    {
      "epoch": 168.0,
      "eval_loss": 1.043716549873352,
      "eval_r": 0.6065624952316284,
      "eval_runtime": 27.3055,
      "eval_samples_per_second": 58.303,
      "eval_steps_per_second": 58.303,
      "step": 1072848
    },
    {
      "epoch": 168.02,
      "learning_rate": 1.5988098966489196e-05,
      "loss": 1.0105,
      "step": 1073000
    },
    {
      "epoch": 168.1,
      "learning_rate": 1.5948950829940496e-05,
      "loss": 0.9977,
      "step": 1073500
    },
    {
      "epoch": 168.18,
      "learning_rate": 1.5909802693391796e-05,
      "loss": 0.9755,
      "step": 1074000
    },
    {
      "epoch": 168.26,
      "learning_rate": 1.5870654556843096e-05,
      "loss": 0.9799,
      "step": 1074500
    },
    {
      "epoch": 168.34,
      "learning_rate": 1.5831506420294396e-05,
      "loss": 0.9904,
      "step": 1075000
    },
    {
      "epoch": 168.42,
      "learning_rate": 1.5792358283745697e-05,
      "loss": 0.9917,
      "step": 1075500
    },
    {
      "epoch": 168.49,
      "learning_rate": 1.5753210147196993e-05,
      "loss": 0.9745,
      "step": 1076000
    },
    {
      "epoch": 168.57,
      "learning_rate": 1.5714062010648294e-05,
      "loss": 0.9981,
      "step": 1076500
    },
    {
      "epoch": 168.65,
      "learning_rate": 1.5674913874099594e-05,
      "loss": 0.9917,
      "step": 1077000
    },
    {
      "epoch": 168.73,
      "learning_rate": 1.563576573755089e-05,
      "loss": 0.9728,
      "step": 1077500
    },
    {
      "epoch": 168.81,
      "learning_rate": 1.559661760100219e-05,
      "loss": 0.9912,
      "step": 1078000
    },
    {
      "epoch": 168.89,
      "learning_rate": 1.555746946445349e-05,
      "loss": 0.9917,
      "step": 1078500
    },
    {
      "epoch": 168.96,
      "learning_rate": 1.551832132790479e-05,
      "loss": 0.9718,
      "step": 1079000
    },
    {
      "epoch": 169.0,
      "eval_loss": 1.0358389616012573,
      "eval_r": 0.6090768575668335,
      "eval_runtime": 27.0952,
      "eval_samples_per_second": 58.756,
      "eval_steps_per_second": 58.756,
      "step": 1079234
    },
    {
      "epoch": 169.04,
      "learning_rate": 1.547917319135609e-05,
      "loss": 1.0245,
      "step": 1079500
    },
    {
      "epoch": 169.12,
      "learning_rate": 1.5440025054807392e-05,
      "loss": 0.9863,
      "step": 1080000
    },
    {
      "epoch": 169.2,
      "learning_rate": 1.5400876918258692e-05,
      "loss": 0.9965,
      "step": 1080500
    },
    {
      "epoch": 169.28,
      "learning_rate": 1.5361728781709992e-05,
      "loss": 0.9651,
      "step": 1081000
    },
    {
      "epoch": 169.35,
      "learning_rate": 1.5322580645161292e-05,
      "loss": 0.9879,
      "step": 1081500
    },
    {
      "epoch": 169.43,
      "learning_rate": 1.5283432508612593e-05,
      "loss": 0.9987,
      "step": 1082000
    },
    {
      "epoch": 169.51,
      "learning_rate": 1.5244284372063891e-05,
      "loss": 0.9912,
      "step": 1082500
    },
    {
      "epoch": 169.59,
      "learning_rate": 1.5205136235515191e-05,
      "loss": 0.9837,
      "step": 1083000
    },
    {
      "epoch": 169.67,
      "learning_rate": 1.5165988098966492e-05,
      "loss": 0.9729,
      "step": 1083500
    },
    {
      "epoch": 169.75,
      "learning_rate": 1.512683996241779e-05,
      "loss": 1.0032,
      "step": 1084000
    },
    {
      "epoch": 169.82,
      "learning_rate": 1.5087691825869089e-05,
      "loss": 0.99,
      "step": 1084500
    },
    {
      "epoch": 169.9,
      "learning_rate": 1.5048543689320387e-05,
      "loss": 0.9939,
      "step": 1085000
    },
    {
      "epoch": 169.98,
      "learning_rate": 1.5009395552771687e-05,
      "loss": 0.9886,
      "step": 1085500
    },
    {
      "epoch": 170.0,
      "eval_loss": 1.0369000434875488,
      "eval_r": 0.6088594794273376,
      "eval_runtime": 27.6456,
      "eval_samples_per_second": 57.586,
      "eval_steps_per_second": 57.586,
      "step": 1085620
    },
    {
      "epoch": 170.06,
      "learning_rate": 1.4970247416222988e-05,
      "loss": 0.9781,
      "step": 1086000
    },
    {
      "epoch": 170.14,
      "learning_rate": 1.4931099279674288e-05,
      "loss": 0.9853,
      "step": 1086500
    },
    {
      "epoch": 170.22,
      "learning_rate": 1.4891951143125588e-05,
      "loss": 1.0023,
      "step": 1087000
    },
    {
      "epoch": 170.29,
      "learning_rate": 1.4852803006576888e-05,
      "loss": 0.9861,
      "step": 1087500
    },
    {
      "epoch": 170.37,
      "learning_rate": 1.4813654870028187e-05,
      "loss": 0.981,
      "step": 1088000
    },
    {
      "epoch": 170.45,
      "learning_rate": 1.4774506733479487e-05,
      "loss": 0.9797,
      "step": 1088500
    },
    {
      "epoch": 170.53,
      "learning_rate": 1.4735358596930787e-05,
      "loss": 0.9933,
      "step": 1089000
    },
    {
      "epoch": 170.61,
      "learning_rate": 1.4696210460382087e-05,
      "loss": 0.9865,
      "step": 1089500
    },
    {
      "epoch": 170.69,
      "learning_rate": 1.4657062323833388e-05,
      "loss": 0.9859,
      "step": 1090000
    },
    {
      "epoch": 170.76,
      "learning_rate": 1.4617914187284686e-05,
      "loss": 0.9862,
      "step": 1090500
    },
    {
      "epoch": 170.84,
      "learning_rate": 1.4578766050735986e-05,
      "loss": 0.9943,
      "step": 1091000
    },
    {
      "epoch": 170.92,
      "learning_rate": 1.4539617914187283e-05,
      "loss": 0.9923,
      "step": 1091500
    },
    {
      "epoch": 171.0,
      "learning_rate": 1.4500469777638584e-05,
      "loss": 0.9787,
      "step": 1092000
    },
    {
      "epoch": 171.0,
      "eval_loss": 1.0450092554092407,
      "eval_r": 0.606172502040863,
      "eval_runtime": 27.6036,
      "eval_samples_per_second": 57.674,
      "eval_steps_per_second": 57.674,
      "step": 1092006
    },
    {
      "epoch": 171.08,
      "learning_rate": 1.4461321641089884e-05,
      "loss": 0.9696,
      "step": 1092500
    },
    {
      "epoch": 171.16,
      "learning_rate": 1.4422173504541184e-05,
      "loss": 0.9928,
      "step": 1093000
    },
    {
      "epoch": 171.23,
      "learning_rate": 1.4383025367992484e-05,
      "loss": 0.9732,
      "step": 1093500
    },
    {
      "epoch": 171.31,
      "learning_rate": 1.4343877231443784e-05,
      "loss": 0.984,
      "step": 1094000
    },
    {
      "epoch": 171.39,
      "learning_rate": 1.4304729094895083e-05,
      "loss": 1.0153,
      "step": 1094500
    },
    {
      "epoch": 171.47,
      "learning_rate": 1.4265580958346383e-05,
      "loss": 0.9854,
      "step": 1095000
    },
    {
      "epoch": 171.55,
      "learning_rate": 1.4226432821797683e-05,
      "loss": 0.9987,
      "step": 1095500
    },
    {
      "epoch": 171.63,
      "learning_rate": 1.4187284685248984e-05,
      "loss": 0.9985,
      "step": 1096000
    },
    {
      "epoch": 171.7,
      "learning_rate": 1.4148136548700284e-05,
      "loss": 0.9921,
      "step": 1096500
    },
    {
      "epoch": 171.78,
      "learning_rate": 1.4108988412151582e-05,
      "loss": 0.982,
      "step": 1097000
    },
    {
      "epoch": 171.86,
      "learning_rate": 1.4069840275602883e-05,
      "loss": 1.0011,
      "step": 1097500
    },
    {
      "epoch": 171.94,
      "learning_rate": 1.4030692139054183e-05,
      "loss": 0.9769,
      "step": 1098000
    },
    {
      "epoch": 172.0,
      "eval_loss": 1.0379581451416016,
      "eval_r": 0.6077378988265991,
      "eval_runtime": 28.5297,
      "eval_samples_per_second": 55.801,
      "eval_steps_per_second": 55.801,
      "step": 1098392
    },
    {
      "epoch": 172.02,
      "learning_rate": 1.399154400250548e-05,
      "loss": 0.9695,
      "step": 1098500
    },
    {
      "epoch": 172.1,
      "learning_rate": 1.395239586595678e-05,
      "loss": 1.0076,
      "step": 1099000
    },
    {
      "epoch": 172.17,
      "learning_rate": 1.391324772940808e-05,
      "loss": 0.9957,
      "step": 1099500
    },
    {
      "epoch": 172.25,
      "learning_rate": 1.387409959285938e-05,
      "loss": 0.9834,
      "step": 1100000
    },
    {
      "epoch": 172.33,
      "learning_rate": 1.383495145631068e-05,
      "loss": 1.0083,
      "step": 1100500
    },
    {
      "epoch": 172.41,
      "learning_rate": 1.3795803319761979e-05,
      "loss": 0.9784,
      "step": 1101000
    },
    {
      "epoch": 172.49,
      "learning_rate": 1.375665518321328e-05,
      "loss": 0.9719,
      "step": 1101500
    },
    {
      "epoch": 172.56,
      "learning_rate": 1.371750704666458e-05,
      "loss": 0.9796,
      "step": 1102000
    },
    {
      "epoch": 172.64,
      "learning_rate": 1.367835891011588e-05,
      "loss": 0.9827,
      "step": 1102500
    },
    {
      "epoch": 172.72,
      "learning_rate": 1.363921077356718e-05,
      "loss": 0.9933,
      "step": 1103000
    },
    {
      "epoch": 172.8,
      "learning_rate": 1.3600062637018478e-05,
      "loss": 1.0031,
      "step": 1103500
    },
    {
      "epoch": 172.88,
      "learning_rate": 1.3560914500469779e-05,
      "loss": 0.9861,
      "step": 1104000
    },
    {
      "epoch": 172.96,
      "learning_rate": 1.3521766363921079e-05,
      "loss": 0.9866,
      "step": 1104500
    },
    {
      "epoch": 173.0,
      "eval_loss": 1.0394936800003052,
      "eval_r": 0.6078914999961853,
      "eval_runtime": 27.7989,
      "eval_samples_per_second": 57.269,
      "eval_steps_per_second": 57.269,
      "step": 1104778
    },
    {
      "epoch": 173.03,
      "learning_rate": 1.3482618227372379e-05,
      "loss": 0.9814,
      "step": 1105000
    },
    {
      "epoch": 173.11,
      "learning_rate": 1.344347009082368e-05,
      "loss": 1.0073,
      "step": 1105500
    },
    {
      "epoch": 173.19,
      "learning_rate": 1.3404321954274976e-05,
      "loss": 0.9849,
      "step": 1106000
    },
    {
      "epoch": 173.27,
      "learning_rate": 1.3365173817726276e-05,
      "loss": 0.9729,
      "step": 1106500
    },
    {
      "epoch": 173.35,
      "learning_rate": 1.3326025681177576e-05,
      "loss": 0.9985,
      "step": 1107000
    },
    {
      "epoch": 173.43,
      "learning_rate": 1.3286877544628875e-05,
      "loss": 0.9693,
      "step": 1107500
    },
    {
      "epoch": 173.5,
      "learning_rate": 1.3247729408080175e-05,
      "loss": 0.984,
      "step": 1108000
    },
    {
      "epoch": 173.58,
      "learning_rate": 1.3208581271531475e-05,
      "loss": 0.9778,
      "step": 1108500
    },
    {
      "epoch": 173.66,
      "learning_rate": 1.3169433134982776e-05,
      "loss": 0.9809,
      "step": 1109000
    },
    {
      "epoch": 173.74,
      "learning_rate": 1.3130284998434076e-05,
      "loss": 0.9839,
      "step": 1109500
    },
    {
      "epoch": 173.82,
      "learning_rate": 1.3091136861885374e-05,
      "loss": 0.9959,
      "step": 1110000
    },
    {
      "epoch": 173.9,
      "learning_rate": 1.3051988725336675e-05,
      "loss": 0.9754,
      "step": 1110500
    },
    {
      "epoch": 173.97,
      "learning_rate": 1.3012840588787975e-05,
      "loss": 1.0044,
      "step": 1111000
    },
    {
      "epoch": 174.0,
      "eval_loss": 1.0395066738128662,
      "eval_r": 0.6072101593017578,
      "eval_runtime": 27.5619,
      "eval_samples_per_second": 57.761,
      "eval_steps_per_second": 57.761,
      "step": 1111164
    },
    {
      "epoch": 174.05,
      "learning_rate": 1.2973692452239275e-05,
      "loss": 0.9787,
      "step": 1111500
    },
    {
      "epoch": 174.13,
      "learning_rate": 1.2934544315690575e-05,
      "loss": 0.996,
      "step": 1112000
    },
    {
      "epoch": 174.21,
      "learning_rate": 1.2895396179141876e-05,
      "loss": 0.9808,
      "step": 1112500
    },
    {
      "epoch": 174.29,
      "learning_rate": 1.2856248042593172e-05,
      "loss": 0.9918,
      "step": 1113000
    },
    {
      "epoch": 174.37,
      "learning_rate": 1.2817099906044473e-05,
      "loss": 0.9546,
      "step": 1113500
    },
    {
      "epoch": 174.44,
      "learning_rate": 1.2777951769495771e-05,
      "loss": 0.9685,
      "step": 1114000
    },
    {
      "epoch": 174.52,
      "learning_rate": 1.2738803632947071e-05,
      "loss": 0.9767,
      "step": 1114500
    },
    {
      "epoch": 174.6,
      "learning_rate": 1.2699655496398372e-05,
      "loss": 0.9874,
      "step": 1115000
    },
    {
      "epoch": 174.68,
      "learning_rate": 1.2660507359849672e-05,
      "loss": 1.0091,
      "step": 1115500
    },
    {
      "epoch": 174.76,
      "learning_rate": 1.2621359223300972e-05,
      "loss": 1.001,
      "step": 1116000
    },
    {
      "epoch": 174.84,
      "learning_rate": 1.2582211086752272e-05,
      "loss": 0.9868,
      "step": 1116500
    },
    {
      "epoch": 174.91,
      "learning_rate": 1.254306295020357e-05,
      "loss": 0.9996,
      "step": 1117000
    },
    {
      "epoch": 174.99,
      "learning_rate": 1.2503914813654871e-05,
      "loss": 1.0056,
      "step": 1117500
    },
    {
      "epoch": 175.0,
      "eval_loss": 1.03757905960083,
      "eval_r": 0.6074495315551758,
      "eval_runtime": 27.0701,
      "eval_samples_per_second": 58.81,
      "eval_steps_per_second": 58.81,
      "step": 1117550
    },
    {
      "epoch": 175.07,
      "learning_rate": 1.246476667710617e-05,
      "loss": 0.9915,
      "step": 1118000
    },
    {
      "epoch": 175.15,
      "learning_rate": 1.242561854055747e-05,
      "loss": 0.9977,
      "step": 1118500
    },
    {
      "epoch": 175.23,
      "learning_rate": 1.238647040400877e-05,
      "loss": 0.9779,
      "step": 1119000
    },
    {
      "epoch": 175.31,
      "learning_rate": 1.234732226746007e-05,
      "loss": 0.9776,
      "step": 1119500
    },
    {
      "epoch": 175.38,
      "learning_rate": 1.2308174130911369e-05,
      "loss": 0.9974,
      "step": 1120000
    },
    {
      "epoch": 175.46,
      "learning_rate": 1.2269025994362669e-05,
      "loss": 0.9795,
      "step": 1120500
    },
    {
      "epoch": 175.54,
      "learning_rate": 1.2229877857813969e-05,
      "loss": 0.9826,
      "step": 1121000
    },
    {
      "epoch": 175.62,
      "learning_rate": 1.2190729721265268e-05,
      "loss": 0.983,
      "step": 1121500
    },
    {
      "epoch": 175.7,
      "learning_rate": 1.2151581584716568e-05,
      "loss": 0.9847,
      "step": 1122000
    },
    {
      "epoch": 175.78,
      "learning_rate": 1.2112433448167868e-05,
      "loss": 1.0085,
      "step": 1122500
    },
    {
      "epoch": 175.85,
      "learning_rate": 1.2073285311619168e-05,
      "loss": 0.9746,
      "step": 1123000
    },
    {
      "epoch": 175.93,
      "learning_rate": 1.2034137175070467e-05,
      "loss": 0.9998,
      "step": 1123500
    },
    {
      "epoch": 176.0,
      "eval_loss": 1.0376768112182617,
      "eval_r": 0.6077938675880432,
      "eval_runtime": 27.2466,
      "eval_samples_per_second": 58.429,
      "eval_steps_per_second": 58.429,
      "step": 1123936
    },
    {
      "epoch": 176.01,
      "learning_rate": 1.1994989038521767e-05,
      "loss": 0.98,
      "step": 1124000
    },
    {
      "epoch": 176.09,
      "learning_rate": 1.1955840901973067e-05,
      "loss": 0.9695,
      "step": 1124500
    },
    {
      "epoch": 176.17,
      "learning_rate": 1.1916692765424366e-05,
      "loss": 0.987,
      "step": 1125000
    },
    {
      "epoch": 176.24,
      "learning_rate": 1.1877544628875666e-05,
      "loss": 0.998,
      "step": 1125500
    },
    {
      "epoch": 176.32,
      "learning_rate": 1.1838396492326966e-05,
      "loss": 1.0059,
      "step": 1126000
    },
    {
      "epoch": 176.4,
      "learning_rate": 1.1799248355778265e-05,
      "loss": 0.9968,
      "step": 1126500
    },
    {
      "epoch": 176.48,
      "learning_rate": 1.1760100219229565e-05,
      "loss": 0.9884,
      "step": 1127000
    },
    {
      "epoch": 176.56,
      "learning_rate": 1.1720952082680865e-05,
      "loss": 0.9678,
      "step": 1127500
    },
    {
      "epoch": 176.64,
      "learning_rate": 1.1681803946132165e-05,
      "loss": 0.9768,
      "step": 1128000
    },
    {
      "epoch": 176.71,
      "learning_rate": 1.1642655809583464e-05,
      "loss": 0.9912,
      "step": 1128500
    },
    {
      "epoch": 176.79,
      "learning_rate": 1.1603507673034764e-05,
      "loss": 0.9925,
      "step": 1129000
    },
    {
      "epoch": 176.87,
      "learning_rate": 1.1564359536486064e-05,
      "loss": 0.9649,
      "step": 1129500
    },
    {
      "epoch": 176.95,
      "learning_rate": 1.1525211399937363e-05,
      "loss": 0.9907,
      "step": 1130000
    },
    {
      "epoch": 177.0,
      "eval_loss": 1.0416210889816284,
      "eval_r": 0.6072333455085754,
      "eval_runtime": 27.1313,
      "eval_samples_per_second": 58.678,
      "eval_steps_per_second": 58.678,
      "step": 1130322
    },
    {
      "epoch": 177.03,
      "learning_rate": 1.1486063263388663e-05,
      "loss": 0.9945,
      "step": 1130500
    },
    {
      "epoch": 177.11,
      "learning_rate": 1.1446915126839963e-05,
      "loss": 0.9897,
      "step": 1131000
    },
    {
      "epoch": 177.18,
      "learning_rate": 1.1407766990291263e-05,
      "loss": 0.9724,
      "step": 1131500
    },
    {
      "epoch": 177.26,
      "learning_rate": 1.1368618853742564e-05,
      "loss": 0.9677,
      "step": 1132000
    },
    {
      "epoch": 177.34,
      "learning_rate": 1.1329470717193862e-05,
      "loss": 0.9833,
      "step": 1132500
    },
    {
      "epoch": 177.42,
      "learning_rate": 1.129032258064516e-05,
      "loss": 0.9799,
      "step": 1133000
    },
    {
      "epoch": 177.5,
      "learning_rate": 1.1251174444096461e-05,
      "loss": 0.9794,
      "step": 1133500
    },
    {
      "epoch": 177.58,
      "learning_rate": 1.1212026307547761e-05,
      "loss": 0.9756,
      "step": 1134000
    },
    {
      "epoch": 177.65,
      "learning_rate": 1.1172878170999061e-05,
      "loss": 0.9966,
      "step": 1134500
    },
    {
      "epoch": 177.73,
      "learning_rate": 1.1133730034450362e-05,
      "loss": 0.9703,
      "step": 1135000
    },
    {
      "epoch": 177.81,
      "learning_rate": 1.1094581897901662e-05,
      "loss": 0.9941,
      "step": 1135500
    },
    {
      "epoch": 177.89,
      "learning_rate": 1.105543376135296e-05,
      "loss": 0.9938,
      "step": 1136000
    },
    {
      "epoch": 177.97,
      "learning_rate": 1.1016285624804259e-05,
      "loss": 1.0122,
      "step": 1136500
    },
    {
      "epoch": 178.0,
      "eval_loss": 1.039286732673645,
      "eval_r": 0.6076995730400085,
      "eval_runtime": 27.3098,
      "eval_samples_per_second": 58.294,
      "eval_steps_per_second": 58.294,
      "step": 1136708
    },
    {
      "epoch": 178.05,
      "learning_rate": 1.0977137488255559e-05,
      "loss": 0.9921,
      "step": 1137000
    },
    {
      "epoch": 178.12,
      "learning_rate": 1.093798935170686e-05,
      "loss": 0.9649,
      "step": 1137500
    },
    {
      "epoch": 178.2,
      "learning_rate": 1.089884121515816e-05,
      "loss": 0.9633,
      "step": 1138000
    },
    {
      "epoch": 178.28,
      "learning_rate": 1.085969307860946e-05,
      "loss": 0.9916,
      "step": 1138500
    },
    {
      "epoch": 178.36,
      "learning_rate": 1.0820544942060758e-05,
      "loss": 1.0057,
      "step": 1139000
    },
    {
      "epoch": 178.44,
      "learning_rate": 1.0781396805512057e-05,
      "loss": 0.9856,
      "step": 1139500
    },
    {
      "epoch": 178.52,
      "learning_rate": 1.0742248668963357e-05,
      "loss": 0.9858,
      "step": 1140000
    },
    {
      "epoch": 178.59,
      "learning_rate": 1.0703100532414657e-05,
      "loss": 0.9904,
      "step": 1140500
    },
    {
      "epoch": 178.67,
      "learning_rate": 1.0663952395865957e-05,
      "loss": 1.0033,
      "step": 1141000
    },
    {
      "epoch": 178.75,
      "learning_rate": 1.0624804259317258e-05,
      "loss": 0.9799,
      "step": 1141500
    },
    {
      "epoch": 178.83,
      "learning_rate": 1.0585656122768558e-05,
      "loss": 0.9922,
      "step": 1142000
    },
    {
      "epoch": 178.91,
      "learning_rate": 1.0546507986219856e-05,
      "loss": 0.9804,
      "step": 1142500
    },
    {
      "epoch": 178.99,
      "learning_rate": 1.0507359849671155e-05,
      "loss": 0.9851,
      "step": 1143000
    },
    {
      "epoch": 179.0,
      "eval_loss": 1.039201259613037,
      "eval_r": 0.6071129441261292,
      "eval_runtime": 28.338,
      "eval_samples_per_second": 56.179,
      "eval_steps_per_second": 56.179,
      "step": 1143094
    },
    {
      "epoch": 179.06,
      "learning_rate": 1.0468211713122455e-05,
      "loss": 1.0017,
      "step": 1143500
    },
    {
      "epoch": 179.14,
      "learning_rate": 1.0429063576573755e-05,
      "loss": 0.9857,
      "step": 1144000
    },
    {
      "epoch": 179.22,
      "learning_rate": 1.0389915440025056e-05,
      "loss": 0.9867,
      "step": 1144500
    },
    {
      "epoch": 179.3,
      "learning_rate": 1.0350767303476356e-05,
      "loss": 0.9848,
      "step": 1145000
    },
    {
      "epoch": 179.38,
      "learning_rate": 1.0311619166927654e-05,
      "loss": 0.9814,
      "step": 1145500
    },
    {
      "epoch": 179.46,
      "learning_rate": 1.0272471030378955e-05,
      "loss": 0.9949,
      "step": 1146000
    },
    {
      "epoch": 179.53,
      "learning_rate": 1.0233322893830253e-05,
      "loss": 0.989,
      "step": 1146500
    },
    {
      "epoch": 179.61,
      "learning_rate": 1.0194174757281553e-05,
      "loss": 0.9778,
      "step": 1147000
    },
    {
      "epoch": 179.69,
      "learning_rate": 1.0155026620732854e-05,
      "loss": 0.9928,
      "step": 1147500
    },
    {
      "epoch": 179.77,
      "learning_rate": 1.0115878484184154e-05,
      "loss": 0.963,
      "step": 1148000
    },
    {
      "epoch": 179.85,
      "learning_rate": 1.0076730347635454e-05,
      "loss": 0.9917,
      "step": 1148500
    },
    {
      "epoch": 179.92,
      "learning_rate": 1.0037582211086752e-05,
      "loss": 0.9855,
      "step": 1149000
    },
    {
      "epoch": 180.0,
      "eval_loss": 1.0408254861831665,
      "eval_r": 0.6071550846099854,
      "eval_runtime": 27.5006,
      "eval_samples_per_second": 57.89,
      "eval_steps_per_second": 57.89,
      "step": 1149480
    },
    {
      "epoch": 180.0,
      "learning_rate": 9.998434074538053e-06,
      "loss": 0.9778,
      "step": 1149500
    },
    {
      "epoch": 180.08,
      "learning_rate": 9.959285937989351e-06,
      "loss": 0.972,
      "step": 1150000
    },
    {
      "epoch": 180.16,
      "learning_rate": 9.920137801440651e-06,
      "loss": 0.9721,
      "step": 1150500
    },
    {
      "epoch": 180.24,
      "learning_rate": 9.880989664891952e-06,
      "loss": 0.9669,
      "step": 1151000
    },
    {
      "epoch": 180.32,
      "learning_rate": 9.841841528343252e-06,
      "loss": 0.9853,
      "step": 1151500
    },
    {
      "epoch": 180.39,
      "learning_rate": 9.802693391794552e-06,
      "loss": 0.9862,
      "step": 1152000
    },
    {
      "epoch": 180.47,
      "learning_rate": 9.76354525524585e-06,
      "loss": 0.9912,
      "step": 1152500
    },
    {
      "epoch": 180.55,
      "learning_rate": 9.72439711869715e-06,
      "loss": 0.9841,
      "step": 1153000
    },
    {
      "epoch": 180.63,
      "learning_rate": 9.68524898214845e-06,
      "loss": 0.97,
      "step": 1153500
    },
    {
      "epoch": 180.71,
      "learning_rate": 9.64610084559975e-06,
      "loss": 0.9957,
      "step": 1154000
    },
    {
      "epoch": 180.79,
      "learning_rate": 9.60695270905105e-06,
      "loss": 0.9888,
      "step": 1154500
    },
    {
      "epoch": 180.86,
      "learning_rate": 9.56780457250235e-06,
      "loss": 0.9896,
      "step": 1155000
    },
    {
      "epoch": 180.94,
      "learning_rate": 9.528656435953649e-06,
      "loss": 0.9949,
      "step": 1155500
    },
    {
      "epoch": 181.0,
      "eval_loss": 1.0417587757110596,
      "eval_r": 0.6070864796638489,
      "eval_runtime": 27.6113,
      "eval_samples_per_second": 57.658,
      "eval_steps_per_second": 57.658,
      "step": 1155866
    },
    {
      "epoch": 181.02,
      "learning_rate": 9.489508299404949e-06,
      "loss": 1.0045,
      "step": 1156000
    },
    {
      "epoch": 181.1,
      "learning_rate": 9.450360162856249e-06,
      "loss": 0.978,
      "step": 1156500
    },
    {
      "epoch": 181.18,
      "learning_rate": 9.411212026307547e-06,
      "loss": 0.9797,
      "step": 1157000
    },
    {
      "epoch": 181.26,
      "learning_rate": 9.372063889758848e-06,
      "loss": 0.9807,
      "step": 1157500
    },
    {
      "epoch": 181.33,
      "learning_rate": 9.332915753210148e-06,
      "loss": 0.9808,
      "step": 1158000
    },
    {
      "epoch": 181.41,
      "learning_rate": 9.293767616661448e-06,
      "loss": 1.0097,
      "step": 1158500
    },
    {
      "epoch": 181.49,
      "learning_rate": 9.254619480112747e-06,
      "loss": 0.9813,
      "step": 1159000
    },
    {
      "epoch": 181.57,
      "learning_rate": 9.215471343564047e-06,
      "loss": 0.9791,
      "step": 1159500
    },
    {
      "epoch": 181.65,
      "learning_rate": 9.176323207015347e-06,
      "loss": 0.9721,
      "step": 1160000
    },
    {
      "epoch": 181.73,
      "learning_rate": 9.137175070466646e-06,
      "loss": 0.9869,
      "step": 1160500
    },
    {
      "epoch": 181.8,
      "learning_rate": 9.098026933917946e-06,
      "loss": 0.9985,
      "step": 1161000
    },
    {
      "epoch": 181.88,
      "learning_rate": 9.058878797369246e-06,
      "loss": 0.9939,
      "step": 1161500
    },
    {
      "epoch": 181.96,
      "learning_rate": 9.019730660820545e-06,
      "loss": 0.9801,
      "step": 1162000
    },
    {
      "epoch": 182.0,
      "eval_loss": 1.038251280784607,
      "eval_r": 0.6076430678367615,
      "eval_runtime": 28.0949,
      "eval_samples_per_second": 56.665,
      "eval_steps_per_second": 56.665,
      "step": 1162252
    },
    {
      "epoch": 182.04,
      "learning_rate": 8.980582524271845e-06,
      "loss": 0.9812,
      "step": 1162500
    },
    {
      "epoch": 182.12,
      "learning_rate": 8.941434387723145e-06,
      "loss": 0.9685,
      "step": 1163000
    },
    {
      "epoch": 182.2,
      "learning_rate": 8.902286251174445e-06,
      "loss": 0.9871,
      "step": 1163500
    },
    {
      "epoch": 182.27,
      "learning_rate": 8.863138114625744e-06,
      "loss": 0.9577,
      "step": 1164000
    },
    {
      "epoch": 182.35,
      "learning_rate": 8.823989978077044e-06,
      "loss": 0.9834,
      "step": 1164500
    },
    {
      "epoch": 182.43,
      "learning_rate": 8.784841841528344e-06,
      "loss": 0.9881,
      "step": 1165000
    },
    {
      "epoch": 182.51,
      "learning_rate": 8.745693704979643e-06,
      "loss": 0.9977,
      "step": 1165500
    },
    {
      "epoch": 182.59,
      "learning_rate": 8.706545568430943e-06,
      "loss": 1.0042,
      "step": 1166000
    },
    {
      "epoch": 182.67,
      "learning_rate": 8.667397431882243e-06,
      "loss": 0.9796,
      "step": 1166500
    },
    {
      "epoch": 182.74,
      "learning_rate": 8.628249295333543e-06,
      "loss": 0.9948,
      "step": 1167000
    },
    {
      "epoch": 182.82,
      "learning_rate": 8.589101158784842e-06,
      "loss": 0.9893,
      "step": 1167500
    },
    {
      "epoch": 182.9,
      "learning_rate": 8.549953022236142e-06,
      "loss": 0.9856,
      "step": 1168000
    },
    {
      "epoch": 182.98,
      "learning_rate": 8.51080488568744e-06,
      "loss": 0.9853,
      "step": 1168500
    },
    {
      "epoch": 183.0,
      "eval_loss": 1.0385377407073975,
      "eval_r": 0.6077635884284973,
      "eval_runtime": 27.2227,
      "eval_samples_per_second": 58.481,
      "eval_steps_per_second": 58.481,
      "step": 1168638
    },
    {
      "epoch": 183.06,
      "learning_rate": 8.471656749138741e-06,
      "loss": 0.9953,
      "step": 1169000
    },
    {
      "epoch": 183.13,
      "learning_rate": 8.432508612590041e-06,
      "loss": 0.9961,
      "step": 1169500
    },
    {
      "epoch": 183.21,
      "learning_rate": 8.393360476041341e-06,
      "loss": 0.9833,
      "step": 1170000
    },
    {
      "epoch": 183.29,
      "learning_rate": 8.354212339492642e-06,
      "loss": 0.9878,
      "step": 1170500
    },
    {
      "epoch": 183.37,
      "learning_rate": 8.31506420294394e-06,
      "loss": 0.9888,
      "step": 1171000
    },
    {
      "epoch": 183.45,
      "learning_rate": 8.27591606639524e-06,
      "loss": 0.9905,
      "step": 1171500
    },
    {
      "epoch": 183.53,
      "learning_rate": 8.236767929846539e-06,
      "loss": 0.9794,
      "step": 1172000
    },
    {
      "epoch": 183.6,
      "learning_rate": 8.197619793297839e-06,
      "loss": 0.9702,
      "step": 1172500
    },
    {
      "epoch": 183.68,
      "learning_rate": 8.15847165674914e-06,
      "loss": 0.9854,
      "step": 1173000
    },
    {
      "epoch": 183.76,
      "learning_rate": 8.11932352020044e-06,
      "loss": 0.9821,
      "step": 1173500
    },
    {
      "epoch": 183.84,
      "learning_rate": 8.08017538365174e-06,
      "loss": 0.9558,
      "step": 1174000
    },
    {
      "epoch": 183.92,
      "learning_rate": 8.041027247103038e-06,
      "loss": 0.9767,
      "step": 1174500
    },
    {
      "epoch": 184.0,
      "learning_rate": 8.001879110554337e-06,
      "loss": 1.0017,
      "step": 1175000
    },
    {
      "epoch": 184.0,
      "eval_loss": 1.0387470722198486,
      "eval_r": 0.6076940894126892,
      "eval_runtime": 27.0493,
      "eval_samples_per_second": 58.856,
      "eval_steps_per_second": 58.856,
      "step": 1175024
    },
    {
      "epoch": 184.07,
      "learning_rate": 7.962730974005637e-06,
      "loss": 0.9703,
      "step": 1175500
    },
    {
      "epoch": 184.15,
      "learning_rate": 7.923582837456937e-06,
      "loss": 0.9966,
      "step": 1176000
    },
    {
      "epoch": 184.23,
      "learning_rate": 7.884434700908237e-06,
      "loss": 0.9885,
      "step": 1176500
    },
    {
      "epoch": 184.31,
      "learning_rate": 7.845286564359538e-06,
      "loss": 1.0035,
      "step": 1177000
    },
    {
      "epoch": 184.39,
      "learning_rate": 7.806138427810838e-06,
      "loss": 0.9708,
      "step": 1177500
    },
    {
      "epoch": 184.47,
      "learning_rate": 7.766990291262136e-06,
      "loss": 0.9963,
      "step": 1178000
    },
    {
      "epoch": 184.54,
      "learning_rate": 7.727842154713435e-06,
      "loss": 0.9597,
      "step": 1178500
    },
    {
      "epoch": 184.62,
      "learning_rate": 7.688694018164735e-06,
      "loss": 0.9953,
      "step": 1179000
    },
    {
      "epoch": 184.7,
      "learning_rate": 7.649545881616035e-06,
      "loss": 0.9813,
      "step": 1179500
    },
    {
      "epoch": 184.78,
      "learning_rate": 7.6103977450673355e-06,
      "loss": 0.98,
      "step": 1180000
    },
    {
      "epoch": 184.86,
      "learning_rate": 7.571249608518635e-06,
      "loss": 0.9791,
      "step": 1180500
    },
    {
      "epoch": 184.94,
      "learning_rate": 7.532101471969935e-06,
      "loss": 0.9724,
      "step": 1181000
    },
    {
      "epoch": 185.0,
      "eval_loss": 1.038488745689392,
      "eval_r": 0.6072854399681091,
      "eval_runtime": 27.581,
      "eval_samples_per_second": 57.721,
      "eval_steps_per_second": 57.721,
      "step": 1181410
    },
    {
      "epoch": 185.01,
      "learning_rate": 7.492953335421234e-06,
      "loss": 0.9943,
      "step": 1181500
    },
    {
      "epoch": 185.09,
      "learning_rate": 7.453805198872534e-06,
      "loss": 0.9969,
      "step": 1182000
    },
    {
      "epoch": 185.17,
      "learning_rate": 7.414657062323833e-06,
      "loss": 0.9736,
      "step": 1182500
    },
    {
      "epoch": 185.25,
      "learning_rate": 7.3755089257751334e-06,
      "loss": 0.9747,
      "step": 1183000
    },
    {
      "epoch": 185.33,
      "learning_rate": 7.336360789226434e-06,
      "loss": 0.9897,
      "step": 1183500
    },
    {
      "epoch": 185.41,
      "learning_rate": 7.297212652677733e-06,
      "loss": 0.9758,
      "step": 1184000
    },
    {
      "epoch": 185.48,
      "learning_rate": 7.258064516129033e-06,
      "loss": 0.9528,
      "step": 1184500
    },
    {
      "epoch": 185.56,
      "learning_rate": 7.218916379580333e-06,
      "loss": 0.9708,
      "step": 1185000
    },
    {
      "epoch": 185.64,
      "learning_rate": 7.179768243031631e-06,
      "loss": 0.9941,
      "step": 1185500
    },
    {
      "epoch": 185.72,
      "learning_rate": 7.140620106482931e-06,
      "loss": 1.004,
      "step": 1186000
    },
    {
      "epoch": 185.8,
      "learning_rate": 7.1014719699342316e-06,
      "loss": 0.9863,
      "step": 1186500
    },
    {
      "epoch": 185.88,
      "learning_rate": 7.062323833385531e-06,
      "loss": 0.9922,
      "step": 1187000
    },
    {
      "epoch": 185.95,
      "learning_rate": 7.023175696836831e-06,
      "loss": 0.9773,
      "step": 1187500
    },
    {
      "epoch": 186.0,
      "eval_loss": 1.0409153699874878,
      "eval_r": 0.607656717300415,
      "eval_runtime": 28.2384,
      "eval_samples_per_second": 56.377,
      "eval_steps_per_second": 56.377,
      "step": 1187796
    },
    {
      "epoch": 186.03,
      "learning_rate": 6.984027560288131e-06,
      "loss": 0.9855,
      "step": 1188000
    },
    {
      "epoch": 186.11,
      "learning_rate": 6.944879423739431e-06,
      "loss": 0.9751,
      "step": 1188500
    },
    {
      "epoch": 186.19,
      "learning_rate": 6.905731287190729e-06,
      "loss": 0.9704,
      "step": 1189000
    },
    {
      "epoch": 186.27,
      "learning_rate": 6.8665831506420295e-06,
      "loss": 0.9688,
      "step": 1189500
    },
    {
      "epoch": 186.35,
      "learning_rate": 6.82743501409333e-06,
      "loss": 0.9818,
      "step": 1190000
    },
    {
      "epoch": 186.42,
      "learning_rate": 6.788286877544629e-06,
      "loss": 0.9958,
      "step": 1190500
    },
    {
      "epoch": 186.5,
      "learning_rate": 6.749138740995929e-06,
      "loss": 0.9906,
      "step": 1191000
    },
    {
      "epoch": 186.58,
      "learning_rate": 6.7099906044472295e-06,
      "loss": 0.9947,
      "step": 1191500
    },
    {
      "epoch": 186.66,
      "learning_rate": 6.670842467898529e-06,
      "loss": 1.0176,
      "step": 1192000
    },
    {
      "epoch": 186.74,
      "learning_rate": 6.631694331349827e-06,
      "loss": 0.9777,
      "step": 1192500
    },
    {
      "epoch": 186.81,
      "learning_rate": 6.592546194801128e-06,
      "loss": 0.9775,
      "step": 1193000
    },
    {
      "epoch": 186.89,
      "learning_rate": 6.553398058252427e-06,
      "loss": 0.9772,
      "step": 1193500
    },
    {
      "epoch": 186.97,
      "learning_rate": 6.514249921703727e-06,
      "loss": 0.9928,
      "step": 1194000
    },
    {
      "epoch": 187.0,
      "eval_loss": 1.038632869720459,
      "eval_r": 0.6067777872085571,
      "eval_runtime": 27.8872,
      "eval_samples_per_second": 57.087,
      "eval_steps_per_second": 57.087,
      "step": 1194182
    },
    {
      "epoch": 187.05,
      "learning_rate": 6.4751017851550274e-06,
      "loss": 0.9849,
      "step": 1194500
    },
    {
      "epoch": 187.13,
      "learning_rate": 6.435953648606327e-06,
      "loss": 0.9842,
      "step": 1195000
    },
    {
      "epoch": 187.21,
      "learning_rate": 6.396805512057627e-06,
      "loss": 0.9913,
      "step": 1195500
    },
    {
      "epoch": 187.28,
      "learning_rate": 6.3576573755089255e-06,
      "loss": 0.9791,
      "step": 1196000
    },
    {
      "epoch": 187.36,
      "learning_rate": 6.318509238960226e-06,
      "loss": 0.9978,
      "step": 1196500
    },
    {
      "epoch": 187.44,
      "learning_rate": 6.279361102411525e-06,
      "loss": 1.0048,
      "step": 1197000
    },
    {
      "epoch": 187.52,
      "learning_rate": 6.240212965862825e-06,
      "loss": 0.9844,
      "step": 1197500
    },
    {
      "epoch": 187.6,
      "learning_rate": 6.2010648293141256e-06,
      "loss": 0.9772,
      "step": 1198000
    },
    {
      "epoch": 187.68,
      "learning_rate": 6.161916692765424e-06,
      "loss": 0.9949,
      "step": 1198500
    },
    {
      "epoch": 187.75,
      "learning_rate": 6.122768556216724e-06,
      "loss": 0.9715,
      "step": 1199000
    },
    {
      "epoch": 187.83,
      "learning_rate": 6.0836204196680245e-06,
      "loss": 0.9725,
      "step": 1199500
    },
    {
      "epoch": 187.91,
      "learning_rate": 6.044472283119324e-06,
      "loss": 0.9597,
      "step": 1200000
    },
    {
      "epoch": 187.99,
      "learning_rate": 6.005324146570623e-06,
      "loss": 0.9645,
      "step": 1200500
    },
    {
      "epoch": 188.0,
      "eval_loss": 1.0401583909988403,
      "eval_r": 0.606756329536438,
      "eval_runtime": 29.3941,
      "eval_samples_per_second": 54.16,
      "eval_steps_per_second": 54.16,
      "step": 1200568
    },
    {
      "epoch": 188.07,
      "learning_rate": 5.9661760100219235e-06,
      "loss": 0.9794,
      "step": 1201000
    },
    {
      "epoch": 188.15,
      "learning_rate": 5.927027873473223e-06,
      "loss": 0.9946,
      "step": 1201500
    },
    {
      "epoch": 188.22,
      "learning_rate": 5.887879736924522e-06,
      "loss": 0.9881,
      "step": 1202000
    },
    {
      "epoch": 188.3,
      "learning_rate": 5.8487316003758225e-06,
      "loss": 0.9744,
      "step": 1202500
    },
    {
      "epoch": 188.38,
      "learning_rate": 5.809583463827122e-06,
      "loss": 1.0071,
      "step": 1203000
    },
    {
      "epoch": 188.46,
      "learning_rate": 5.770435327278422e-06,
      "loss": 0.9802,
      "step": 1203500
    },
    {
      "epoch": 188.54,
      "learning_rate": 5.731287190729721e-06,
      "loss": 0.9902,
      "step": 1204000
    },
    {
      "epoch": 188.62,
      "learning_rate": 5.692139054181022e-06,
      "loss": 0.9754,
      "step": 1204500
    },
    {
      "epoch": 188.69,
      "learning_rate": 5.652990917632321e-06,
      "loss": 0.9827,
      "step": 1205000
    },
    {
      "epoch": 188.77,
      "learning_rate": 5.61384278108362e-06,
      "loss": 1.009,
      "step": 1205500
    },
    {
      "epoch": 188.85,
      "learning_rate": 5.574694644534921e-06,
      "loss": 0.9528,
      "step": 1206000
    },
    {
      "epoch": 188.93,
      "learning_rate": 5.53554650798622e-06,
      "loss": 0.9652,
      "step": 1206500
    },
    {
      "epoch": 189.0,
      "eval_loss": 1.03836989402771,
      "eval_r": 0.6072761416435242,
      "eval_runtime": 27.7715,
      "eval_samples_per_second": 57.325,
      "eval_steps_per_second": 57.325,
      "step": 1206954
    },
    {
      "epoch": 189.01,
      "learning_rate": 5.49639837143752e-06,
      "loss": 0.9711,
      "step": 1207000
    },
    {
      "epoch": 189.09,
      "learning_rate": 5.4572502348888196e-06,
      "loss": 0.9797,
      "step": 1207500
    },
    {
      "epoch": 189.16,
      "learning_rate": 5.418102098340119e-06,
      "loss": 0.9705,
      "step": 1208000
    },
    {
      "epoch": 189.24,
      "learning_rate": 5.378953961791419e-06,
      "loss": 0.984,
      "step": 1208500
    },
    {
      "epoch": 189.32,
      "learning_rate": 5.3398058252427185e-06,
      "loss": 0.9871,
      "step": 1209000
    },
    {
      "epoch": 189.4,
      "learning_rate": 5.300657688694019e-06,
      "loss": 0.9643,
      "step": 1209500
    },
    {
      "epoch": 189.48,
      "learning_rate": 5.261509552145318e-06,
      "loss": 0.9995,
      "step": 1210000
    },
    {
      "epoch": 189.56,
      "learning_rate": 5.222361415596618e-06,
      "loss": 0.9966,
      "step": 1210500
    },
    {
      "epoch": 189.63,
      "learning_rate": 5.183213279047918e-06,
      "loss": 0.9726,
      "step": 1211000
    },
    {
      "epoch": 189.71,
      "learning_rate": 5.144065142499217e-06,
      "loss": 0.9824,
      "step": 1211500
    },
    {
      "epoch": 189.79,
      "learning_rate": 5.104917005950517e-06,
      "loss": 0.9843,
      "step": 1212000
    },
    {
      "epoch": 189.87,
      "learning_rate": 5.065768869401817e-06,
      "loss": 0.9756,
      "step": 1212500
    },
    {
      "epoch": 189.95,
      "learning_rate": 5.026620732853116e-06,
      "loss": 0.9905,
      "step": 1213000
    },
    {
      "epoch": 190.0,
      "eval_loss": 1.0394847393035889,
      "eval_r": 0.6066765785217285,
      "eval_runtime": 27.3217,
      "eval_samples_per_second": 58.269,
      "eval_steps_per_second": 58.269,
      "step": 1213340
    },
    {
      "epoch": 190.03,
      "learning_rate": 4.987472596304416e-06,
      "loss": 0.9729,
      "step": 1213500
    },
    {
      "epoch": 190.1,
      "learning_rate": 4.9483244597557165e-06,
      "loss": 0.9979,
      "step": 1214000
    },
    {
      "epoch": 190.18,
      "learning_rate": 4.909176323207015e-06,
      "loss": 0.9722,
      "step": 1214500
    },
    {
      "epoch": 190.26,
      "learning_rate": 4.870028186658315e-06,
      "loss": 0.9627,
      "step": 1215000
    },
    {
      "epoch": 190.34,
      "learning_rate": 4.830880050109615e-06,
      "loss": 0.9765,
      "step": 1215500
    },
    {
      "epoch": 190.42,
      "learning_rate": 4.791731913560915e-06,
      "loss": 0.9692,
      "step": 1216000
    },
    {
      "epoch": 190.49,
      "learning_rate": 4.752583777012214e-06,
      "loss": 0.9822,
      "step": 1216500
    },
    {
      "epoch": 190.57,
      "learning_rate": 4.713435640463514e-06,
      "loss": 1.0031,
      "step": 1217000
    },
    {
      "epoch": 190.65,
      "learning_rate": 4.674287503914814e-06,
      "loss": 0.9733,
      "step": 1217500
    },
    {
      "epoch": 190.73,
      "learning_rate": 4.635139367366113e-06,
      "loss": 0.9846,
      "step": 1218000
    },
    {
      "epoch": 190.81,
      "learning_rate": 4.595991230817413e-06,
      "loss": 0.9796,
      "step": 1218500
    },
    {
      "epoch": 190.89,
      "learning_rate": 4.5568430942687136e-06,
      "loss": 0.9964,
      "step": 1219000
    },
    {
      "epoch": 190.96,
      "learning_rate": 4.517694957720012e-06,
      "loss": 0.9781,
      "step": 1219500
    },
    {
      "epoch": 191.0,
      "eval_loss": 1.0401979684829712,
      "eval_r": 0.6063860654830933,
      "eval_runtime": 27.2251,
      "eval_samples_per_second": 58.475,
      "eval_steps_per_second": 58.475,
      "step": 1219726
    },
    {
      "epoch": 191.04,
      "learning_rate": 4.478546821171312e-06,
      "loss": 0.9887,
      "step": 1220000
    },
    {
      "epoch": 191.12,
      "learning_rate": 4.4393986846226125e-06,
      "loss": 0.9763,
      "step": 1220500
    },
    {
      "epoch": 191.2,
      "learning_rate": 4.400250548073912e-06,
      "loss": 0.9767,
      "step": 1221000
    },
    {
      "epoch": 191.28,
      "learning_rate": 4.361102411525211e-06,
      "loss": 0.973,
      "step": 1221500
    },
    {
      "epoch": 191.36,
      "learning_rate": 4.3219542749765115e-06,
      "loss": 0.9691,
      "step": 1222000
    },
    {
      "epoch": 191.43,
      "learning_rate": 4.282806138427811e-06,
      "loss": 0.974,
      "step": 1222500
    },
    {
      "epoch": 191.51,
      "learning_rate": 4.24365800187911e-06,
      "loss": 0.9938,
      "step": 1223000
    },
    {
      "epoch": 191.59,
      "learning_rate": 4.2045098653304104e-06,
      "loss": 1.0206,
      "step": 1223500
    },
    {
      "epoch": 191.67,
      "learning_rate": 4.165361728781711e-06,
      "loss": 0.975,
      "step": 1224000
    },
    {
      "epoch": 191.75,
      "learning_rate": 4.12621359223301e-06,
      "loss": 0.9758,
      "step": 1224500
    },
    {
      "epoch": 191.83,
      "learning_rate": 4.087065455684309e-06,
      "loss": 0.9727,
      "step": 1225000
    },
    {
      "epoch": 191.9,
      "learning_rate": 4.04791731913561e-06,
      "loss": 0.9775,
      "step": 1225500
    },
    {
      "epoch": 191.98,
      "learning_rate": 4.008769182586909e-06,
      "loss": 0.9924,
      "step": 1226000
    },
    {
      "epoch": 192.0,
      "eval_loss": 1.0382325649261475,
      "eval_r": 0.6077627539634705,
      "eval_runtime": 26.9736,
      "eval_samples_per_second": 59.021,
      "eval_steps_per_second": 59.021,
      "step": 1226112
    },
    {
      "epoch": 192.06,
      "learning_rate": 3.969621046038209e-06,
      "loss": 0.9899,
      "step": 1226500
    },
    {
      "epoch": 192.14,
      "learning_rate": 3.930472909489509e-06,
      "loss": 0.9793,
      "step": 1227000
    },
    {
      "epoch": 192.22,
      "learning_rate": 3.891324772940808e-06,
      "loss": 0.971,
      "step": 1227500
    },
    {
      "epoch": 192.3,
      "learning_rate": 3.852176636392108e-06,
      "loss": 0.983,
      "step": 1228000
    },
    {
      "epoch": 192.37,
      "learning_rate": 3.8130284998434075e-06,
      "loss": 0.9705,
      "step": 1228500
    },
    {
      "epoch": 192.45,
      "learning_rate": 3.7738803632947073e-06,
      "loss": 0.9613,
      "step": 1229000
    },
    {
      "epoch": 192.53,
      "learning_rate": 3.734732226746007e-06,
      "loss": 0.9979,
      "step": 1229500
    },
    {
      "epoch": 192.61,
      "learning_rate": 3.695584090197307e-06,
      "loss": 0.9863,
      "step": 1230000
    },
    {
      "epoch": 192.69,
      "learning_rate": 3.6564359536486063e-06,
      "loss": 0.9957,
      "step": 1230500
    },
    {
      "epoch": 192.77,
      "learning_rate": 3.617287817099906e-06,
      "loss": 0.9723,
      "step": 1231000
    },
    {
      "epoch": 192.84,
      "learning_rate": 3.5781396805512063e-06,
      "loss": 0.9713,
      "step": 1231500
    },
    {
      "epoch": 192.92,
      "learning_rate": 3.5389915440025053e-06,
      "loss": 0.9971,
      "step": 1232000
    },
    {
      "epoch": 193.0,
      "eval_loss": 1.0392942428588867,
      "eval_r": 0.6068901419639587,
      "eval_runtime": 28.4274,
      "eval_samples_per_second": 56.002,
      "eval_steps_per_second": 56.002,
      "step": 1232498
    },
    {
      "epoch": 193.0,
      "learning_rate": 3.4998434074538055e-06,
      "loss": 0.9966,
      "step": 1232500
    },
    {
      "epoch": 193.08,
      "learning_rate": 3.4606952709051053e-06,
      "loss": 0.9937,
      "step": 1233000
    },
    {
      "epoch": 193.16,
      "learning_rate": 3.421547134356405e-06,
      "loss": 0.9821,
      "step": 1233500
    },
    {
      "epoch": 193.24,
      "learning_rate": 3.3823989978077044e-06,
      "loss": 0.9856,
      "step": 1234000
    },
    {
      "epoch": 193.31,
      "learning_rate": 3.3432508612590042e-06,
      "loss": 0.9638,
      "step": 1234500
    },
    {
      "epoch": 193.39,
      "learning_rate": 3.304102724710304e-06,
      "loss": 0.9992,
      "step": 1235000
    },
    {
      "epoch": 193.47,
      "learning_rate": 3.2649545881616034e-06,
      "loss": 0.9568,
      "step": 1235500
    },
    {
      "epoch": 193.55,
      "learning_rate": 3.225806451612903e-06,
      "loss": 0.9716,
      "step": 1236000
    },
    {
      "epoch": 193.63,
      "learning_rate": 3.1866583150642034e-06,
      "loss": 1.0003,
      "step": 1236500
    },
    {
      "epoch": 193.7,
      "learning_rate": 3.147510178515503e-06,
      "loss": 0.9879,
      "step": 1237000
    },
    {
      "epoch": 193.78,
      "learning_rate": 3.1083620419668026e-06,
      "loss": 0.993,
      "step": 1237500
    },
    {
      "epoch": 193.86,
      "learning_rate": 3.0692139054181024e-06,
      "loss": 0.9758,
      "step": 1238000
    },
    {
      "epoch": 193.94,
      "learning_rate": 3.0300657688694017e-06,
      "loss": 0.9731,
      "step": 1238500
    },
    {
      "epoch": 194.0,
      "eval_loss": 1.0379679203033447,
      "eval_r": 0.6068664789199829,
      "eval_runtime": 27.1124,
      "eval_samples_per_second": 58.719,
      "eval_steps_per_second": 58.719,
      "step": 1238884
    },
    {
      "epoch": 194.02,
      "learning_rate": 2.9909176323207015e-06,
      "loss": 0.9766,
      "step": 1239000
    },
    {
      "epoch": 194.1,
      "learning_rate": 2.9517694957720013e-06,
      "loss": 0.9726,
      "step": 1239500
    },
    {
      "epoch": 194.17,
      "learning_rate": 2.912621359223301e-06,
      "loss": 0.9814,
      "step": 1240000
    },
    {
      "epoch": 194.25,
      "learning_rate": 2.873473222674601e-06,
      "loss": 0.9723,
      "step": 1240500
    },
    {
      "epoch": 194.33,
      "learning_rate": 2.8343250861259007e-06,
      "loss": 0.9709,
      "step": 1241000
    },
    {
      "epoch": 194.41,
      "learning_rate": 2.7951769495772e-06,
      "loss": 0.9791,
      "step": 1241500
    },
    {
      "epoch": 194.49,
      "learning_rate": 2.7560288130285e-06,
      "loss": 0.975,
      "step": 1242000
    },
    {
      "epoch": 194.57,
      "learning_rate": 2.7168806764797997e-06,
      "loss": 0.9853,
      "step": 1242500
    },
    {
      "epoch": 194.64,
      "learning_rate": 2.6777325399310995e-06,
      "loss": 0.962,
      "step": 1243000
    },
    {
      "epoch": 194.72,
      "learning_rate": 2.6385844033823993e-06,
      "loss": 0.9914,
      "step": 1243500
    },
    {
      "epoch": 194.8,
      "learning_rate": 2.5994362668336986e-06,
      "loss": 0.9846,
      "step": 1244000
    },
    {
      "epoch": 194.88,
      "learning_rate": 2.560288130284999e-06,
      "loss": 0.9834,
      "step": 1244500
    },
    {
      "epoch": 194.96,
      "learning_rate": 2.5211399937362982e-06,
      "loss": 0.9761,
      "step": 1245000
    },
    {
      "epoch": 195.0,
      "eval_loss": 1.0387539863586426,
      "eval_r": 0.607110321521759,
      "eval_runtime": 27.1439,
      "eval_samples_per_second": 58.65,
      "eval_steps_per_second": 58.65,
      "step": 1245270
    },
    {
      "epoch": 195.04,
      "learning_rate": 2.481991857187598e-06,
      "loss": 0.9886,
      "step": 1245500
    },
    {
      "epoch": 195.11,
      "learning_rate": 2.442843720638898e-06,
      "loss": 0.9847,
      "step": 1246000
    },
    {
      "epoch": 195.19,
      "learning_rate": 2.403695584090197e-06,
      "loss": 0.9945,
      "step": 1246500
    },
    {
      "epoch": 195.27,
      "learning_rate": 2.3645474475414974e-06,
      "loss": 0.9718,
      "step": 1247000
    },
    {
      "epoch": 195.35,
      "learning_rate": 2.3253993109927968e-06,
      "loss": 0.9715,
      "step": 1247500
    },
    {
      "epoch": 195.43,
      "learning_rate": 2.2862511744440966e-06,
      "loss": 0.9767,
      "step": 1248000
    },
    {
      "epoch": 195.51,
      "learning_rate": 2.2471030378953964e-06,
      "loss": 0.9844,
      "step": 1248500
    },
    {
      "epoch": 195.58,
      "learning_rate": 2.207954901346696e-06,
      "loss": 0.9974,
      "step": 1249000
    },
    {
      "epoch": 195.66,
      "learning_rate": 2.1688067647979955e-06,
      "loss": 0.9827,
      "step": 1249500
    },
    {
      "epoch": 195.74,
      "learning_rate": 2.1296586282492953e-06,
      "loss": 0.994,
      "step": 1250000
    },
    {
      "epoch": 195.82,
      "learning_rate": 2.090510491700595e-06,
      "loss": 0.9599,
      "step": 1250500
    },
    {
      "epoch": 195.9,
      "learning_rate": 2.051362355151895e-06,
      "loss": 0.9663,
      "step": 1251000
    },
    {
      "epoch": 195.98,
      "learning_rate": 2.0122142186031947e-06,
      "loss": 0.9798,
      "step": 1251500
    },
    {
      "epoch": 196.0,
      "eval_loss": 1.0394569635391235,
      "eval_r": 0.6066092848777771,
      "eval_runtime": 27.4246,
      "eval_samples_per_second": 58.05,
      "eval_steps_per_second": 58.05,
      "step": 1251656
    },
    {
      "epoch": 196.05,
      "learning_rate": 1.973066082054494e-06,
      "loss": 0.9707,
      "step": 1252000
    },
    {
      "epoch": 196.13,
      "learning_rate": 1.9339179455057943e-06,
      "loss": 0.9949,
      "step": 1252500
    },
    {
      "epoch": 196.21,
      "learning_rate": 1.8947698089570937e-06,
      "loss": 0.9963,
      "step": 1253000
    },
    {
      "epoch": 196.29,
      "learning_rate": 1.8556216724083932e-06,
      "loss": 0.9765,
      "step": 1253500
    },
    {
      "epoch": 196.37,
      "learning_rate": 1.8164735358596933e-06,
      "loss": 0.9782,
      "step": 1254000
    },
    {
      "epoch": 196.45,
      "learning_rate": 1.7773253993109928e-06,
      "loss": 0.9686,
      "step": 1254500
    },
    {
      "epoch": 196.52,
      "learning_rate": 1.7381772627622926e-06,
      "loss": 0.9927,
      "step": 1255000
    },
    {
      "epoch": 196.6,
      "learning_rate": 1.6990291262135922e-06,
      "loss": 0.9712,
      "step": 1255500
    },
    {
      "epoch": 196.68,
      "learning_rate": 1.6598809896648922e-06,
      "loss": 0.9632,
      "step": 1256000
    },
    {
      "epoch": 196.76,
      "learning_rate": 1.6207328531161918e-06,
      "loss": 0.9867,
      "step": 1256500
    },
    {
      "epoch": 196.84,
      "learning_rate": 1.5815847165674914e-06,
      "loss": 0.9818,
      "step": 1257000
    },
    {
      "epoch": 196.92,
      "learning_rate": 1.5424365800187912e-06,
      "loss": 0.9879,
      "step": 1257500
    },
    {
      "epoch": 196.99,
      "learning_rate": 1.503288443470091e-06,
      "loss": 0.9747,
      "step": 1258000
    },
    {
      "epoch": 197.0,
      "eval_loss": 1.0383063554763794,
      "eval_r": 0.6069133281707764,
      "eval_runtime": 27.2662,
      "eval_samples_per_second": 58.387,
      "eval_steps_per_second": 58.387,
      "step": 1258042
    }
  ],
  "max_steps": 1277200,
  "num_train_epochs": 200,
  "total_flos": 4986202598207556.0,
  "trial_name": null,
  "trial_params": null
}
